from fastapi import APIRouter, HTTPException, UploadFile, File, Form
from fastapi.responses import JSONResponse
from typing import Optional, Dict, List
import os
from dotenv import load_dotenv
import tempfile
import asyncio
import aiofiles
from datetime import datetime
import google.generativeai as genai
from pydantic import BaseModel

# .env íŒŒì¼ ë¡œë“œ (í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ)
print(f"ğŸ” upload.py í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
print(f"ğŸ” upload.py .env íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists('.env')}")
load_dotenv('.env')
print(f"ğŸ” upload.py GOOGLE_API_KEY ë¡œë“œ í›„: {os.getenv('GOOGLE_API_KEY')}")

# Gemini API ì„¤ì •
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)
    model = genai.GenerativeModel('gemini-1.5-flash')

router = APIRouter(tags=["upload"])

class SummaryRequest(BaseModel):
    content: str
    summary_type: str = "general"  # general, technical, experience

class SummaryResponse(BaseModel):
    summary: str
    keywords: list[str]
    confidence_score: float
    processing_time: float

# ìƒˆë¡œìš´ ìƒì„¸ ë¶„ì„ ëª¨ë¸ë“¤
class AnalysisScore(BaseModel):
    score: int  # 0-10
    feedback: str

class DocumentValidationRequest(BaseModel):
    content: str
    expected_type: str  # "ì´ë ¥ì„œ", "ìê¸°ì†Œê°œì„œ", "í¬íŠ¸í´ë¦¬ì˜¤"

class DocumentValidationResponse(BaseModel):
    is_valid: bool
    confidence: float
    reason: str
    suggested_type: str

class ResumeAnalysis(BaseModel):
    basic_info_completeness: AnalysisScore
    job_relevance: AnalysisScore
    experience_clarity: AnalysisScore
    tech_stack_clarity: AnalysisScore
    project_recency: AnalysisScore
    achievement_metrics: AnalysisScore
    readability: AnalysisScore
    typos_and_errors: AnalysisScore
    update_freshness: AnalysisScore

class CoverLetterAnalysis(BaseModel):
    motivation_relevance: AnalysisScore
    problem_solving_STAR: AnalysisScore
    quantitative_impact: AnalysisScore
    job_understanding: AnalysisScore
    unique_experience: AnalysisScore
    logical_flow: AnalysisScore
    keyword_diversity: AnalysisScore
    sentence_readability: AnalysisScore
    typos_and_errors: AnalysisScore

class PortfolioAnalysis(BaseModel):
    project_overview: AnalysisScore
    tech_stack: AnalysisScore
    personal_contribution: AnalysisScore
    achievement_metrics: AnalysisScore
    visual_quality: AnalysisScore
    documentation_quality: AnalysisScore
    job_relevance: AnalysisScore
    unique_features: AnalysisScore
    maintainability: AnalysisScore

class OverallSummary(BaseModel):
    total_score: int
    recommendation: str

class DetailedAnalysisResponse(BaseModel):
    resume_analysis: ResumeAnalysis
    cover_letter_analysis: CoverLetterAnalysis
    portfolio_analysis: PortfolioAnalysis
    overall_summary: OverallSummary

# í—ˆìš©ëœ íŒŒì¼ íƒ€ì…
ALLOWED_EXTENSIONS = {
    '.pdf': 'application/pdf',
    '.doc': 'application/msword',
    '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    '.txt': 'text/plain'
}

# íŒŒì¼ í¬ê¸° ì œí•œ (10MB)
MAX_FILE_SIZE = 10 * 1024 * 1024

def validate_file(file: UploadFile) -> bool:
    """íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬"""
    if not file.filename:
        return False
    
    # íŒŒì¼ í™•ì¥ì í™•ì¸
    file_ext = os.path.splitext(file.filename.lower())[1]
    if file_ext not in ALLOWED_EXTENSIONS:
        return False
    
    return True

async def extract_text_from_file(file_path: str, file_ext: str) -> str:
    """íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        if file_ext == '.txt':
            async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                return await f.read()
        elif file_ext == '.pdf':
            # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ (PyPDF2 ë˜ëŠ” pdfplumber ì‚¬ìš©)
            try:
                import PyPDF2
                text = ""
                with open(file_path, 'rb') as pdf_file:
                    pdf_reader = PyPDF2.PdfReader(pdf_file)
                    for page in pdf_reader.pages:
                        text += page.extract_text() + "\n"
                return text
            except ImportError:
                # PyPDF2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
                return "PDF íŒŒì¼ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ìœ„í•´ PyPDF2ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
        elif file_ext in ['.doc', '.docx']:
            # Word ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (python-docx ì‚¬ìš©)
            try:
                from docx import Document
                doc = Document(file_path)
                text = ""
                for paragraph in doc.paragraphs:
                    text += paragraph.text + "\n"
                return text
            except ImportError:
                return "Word ë¬¸ì„œì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ìœ„í•´ python-docxë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
        else:
            return "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."
    except Exception as e:
        return f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}"

async def generate_summary_with_gemini(content: str, summary_type: str = "general") -> SummaryResponse:
    """Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìš”ì•½ ìƒì„±"""
    if not GOOGLE_API_KEY:
        raise HTTPException(status_code=500, detail="Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    start_time = datetime.now()
    
    try:
        # ìš”ì•½ íƒ€ì…ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        prompts = {
            "general": f"""
            ë‹¤ìŒ ì´ë ¥ì„œ/ìê¸°ì†Œê°œì„œ ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:
            
            {content}
            
            ìš”ì•½ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ í¬í•¨í•´ì£¼ì„¸ìš”:
            1. ì£¼ìš” ê²½ë ¥ ë° ê²½í—˜
            2. í•µì‹¬ ê¸°ìˆ  ìŠ¤íƒ
            3. ì£¼ìš” ì„±ê³¼ë‚˜ í”„ë¡œì íŠ¸
            4. ì§€ì› ì§ë¬´ì™€ì˜ ì—°ê´€ì„±
            
            ìš”ì•½ì€ 200ì ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """,
            "technical": f"""
            ë‹¤ìŒ ë‚´ìš©ì—ì„œ ê¸°ìˆ ì  ì—­ëŸ‰ì„ ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:
            
            {content}
            
            ë‹¤ìŒ í•­ëª©ë“¤ì„ í¬í•¨í•´ì£¼ì„¸ìš”:
            1. í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ë° í”„ë ˆì„ì›Œí¬
            2. ê°œë°œ ë„êµ¬ ë° í”Œë«í¼
            3. í”„ë¡œì íŠ¸ ê²½í—˜
            4. ê¸°ìˆ ì  ì„±ê³¼
            
            ìš”ì•½ì€ 150ì ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """,
            "experience": f"""
            ë‹¤ìŒ ë‚´ìš©ì—ì„œ ê²½ë ¥ê³¼ ê²½í—˜ì„ ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:
            
            {content}
            
            ë‹¤ìŒ í•­ëª©ë“¤ì„ í¬í•¨í•´ì£¼ì„¸ìš”:
            1. ì´ ê²½ë ¥ ê¸°ê°„
            2. ì£¼ìš” íšŒì‚¬ ë° ì§ë¬´
            3. í•µì‹¬ í”„ë¡œì íŠ¸ ê²½í—˜
            4. ì£¼ìš” ì„±ê³¼ ë° ì—…ì 
            
            ìš”ì•½ì€ 150ì ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """
        }
        
        prompt = prompts.get(summary_type, prompts["general"])
        
        # Gemini API í˜¸ì¶œ
        response = await asyncio.to_thread(
            model.generate_content,
            prompt
        )
        
        summary = response.text.strip()
        
        # í‚¤ì›Œë“œ ì¶”ì¶œì„ ìœ„í•œ ì¶”ê°€ ìš”ì²­
        keyword_prompt = f"""
        ë‹¤ìŒ ìš”ì•½ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ 5ê°œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
        
        {summary}
        
        í‚¤ì›Œë“œëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´í•´ì£¼ì„¸ìš”.
        """
        
        keyword_response = await asyncio.to_thread(
            model.generate_content,
            keyword_prompt
        )
        
        keywords = [kw.strip() for kw in keyword_response.text.split(',')]
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        return SummaryResponse(
            summary=summary,
            keywords=keywords[:5],  # ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œ
            confidence_score=0.85,  # ê¸°ë³¸ ì‹ ë¢°ë„ ì ìˆ˜
            processing_time=processing_time
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}")

async def generate_detailed_analysis_with_gemini(content: str, document_type: str = "resume") -> DetailedAnalysisResponse:
    """Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„¸ ë¶„ì„ ìƒì„±"""
    if not GOOGLE_API_KEY:
        raise HTTPException(status_code=500, detail="Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    start_time = datetime.now()
    
    try:
        # ë¬¸ì„œ íƒ€ì…ì— ë”°ë¥¸ ë§ì¶¤í˜• í”„ë¡¬í”„íŠ¸ ìƒì„±
        if document_type == "resume":
            analysis_prompt = f"""
[ROLE] ì±„ìš©ë‹´ë‹¹ìë¡œì„œ ì´ë ¥ì„œë¥¼ ë¶„ì„í•˜ê³  ì ìˆ˜í™”í•˜ì„¸ìš”.

[ë¶„ì„ ê¸°ì¤€] 0~10ì  í‰ê°€, ê°„ë‹¨í•œ í”¼ë“œë°± ì‘ì„±

[ì´ë ¥ì„œ ë¶„ì„ í•­ëª©]
1. basic_info_completeness (ê¸°ë³¸ì •ë³´ ì™„ì„±ë„): ì´ë¦„, ì—°ë½ì²˜, ì´ë©”ì¼, GitHub/LinkedIn ë“±ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€
2. job_relevance (ì§ë¬´ ì í•©ì„±): ì§€ì› ì§ë¬´ì™€ ê²½í—˜/ê¸°ìˆ ì´ ì¼ì¹˜í•˜ëŠ”ì§€
3. experience_clarity (ê²½ë ¥ ëª…í™•ì„±): ê²½ë ¥ ì‚¬í•­ì´ ëª…í™•í•˜ê²Œ ê¸°ìˆ ë˜ì–´ ìˆëŠ”ì§€
4. tech_stack_clarity (ê¸°ìˆ ìŠ¤íƒ ëª…í™•ì„±): ì‚¬ìš© ê¸°ìˆ ì´ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œë˜ì–´ ìˆëŠ”ì§€
5. project_recency (í”„ë¡œì íŠ¸ ìµœì‹ ì„±): ìµœê·¼ í”„ë¡œì íŠ¸ ê²½í—˜ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€
6. achievement_metrics (ì„±ê³¼ ì§€í‘œ): ì •ëŸ‰ì  ì„±ê³¼ë‚˜ ì„±ê³¼ ì§€í‘œê°€ ëª…ì‹œë˜ì–´ ìˆëŠ”ì§€
7. readability (ê°€ë…ì„±): ì „ì²´ì ìœ¼ë¡œ ì½ê¸° ì‰½ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ì§€
8. typos_and_errors (ì˜¤íƒˆì): ì˜¤íƒˆìë‚˜ ë¬¸ë²• ì˜¤ë¥˜ê°€ ì ì€ì§€
9. update_freshness (ìµœì‹ ì„±): ìµœê·¼ ì •ë³´ë¡œ ì—…ë°ì´íŠ¸ë˜ì–´ ìˆëŠ”ì§€

[ì¶œë ¥] JSONë§Œ:
{{
  "resume_analysis": {{
    "basic_info_completeness": {{"score": 0, "feedback": ""}},
    "job_relevance": {{"score": 0, "feedback": ""}},
    "experience_clarity": {{"score": 0, "feedback": ""}},
    "tech_stack_clarity": {{"score": 0, "feedback": ""}},
    "project_recency": {{"score": 0, "feedback": ""}},
    "achievement_metrics": {{"score": 0, "feedback": ""}},
    "readability": {{"score": 0, "feedback": ""}},
    "typos_and_errors": {{"score": 0, "feedback": ""}},
    "update_freshness": {{"score": 0, "feedback": ""}}
  }},
  "overall_summary": {{"total_score": 0, "recommendation": ""}}
}}

[ë¬¸ì„œ] {content}

[ìš”êµ¬ì‚¬í•­]
- ê° í•­ëª©ì„ ì‹¤ì œ ë¶„ì„í•˜ì—¬ 0~10ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš” (0ì  = ì „í˜€ ì¶©ì¡±í•˜ì§€ ì•ŠìŒ, 10ì  = ë§¤ìš° ìš°ìˆ˜)
- ì ìˆ˜ëŠ” ë°˜ë“œì‹œ 0~10 ì •ìˆ˜ë¡œ ì…ë ¥í•˜ì„¸ìš”
- feedbackì€ ê°„ë‹¨í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
- JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”
"""
        elif document_type == "cover_letter":
            analysis_prompt = f"""
[ROLE] ë‹¹ì‹ ì€ ITê¸°ì—… ì±„ìš©ë‹´ë‹¹ìì…ë‹ˆë‹¤. ì…ë ¥ëœ ìê¸°ì†Œê°œì„œë¥¼ ì•„ë˜ í˜„ì—… ITê¸°ì—… ê¸°ì¤€ì— ë”°ë¼ ë¶„ì„í•˜ê³  ì ìˆ˜í™”í•´ì•¼ í•©ë‹ˆë‹¤.

[ë¶„ì„ ê¸°ì¤€]
- ê° í•­ëª©ì€ 0~10ì ìœ¼ë¡œ í‰ê°€ (10ì  = ë§¤ìš° ìš°ìˆ˜, 0ì  = ì „í˜€ ì¶©ì¡±í•˜ì§€ ì•ŠìŒ)
- ê° í•­ëª©ë³„ë¡œ ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì„ ê°„ë‹¨íˆ í”¼ë“œë°±ìœ¼ë¡œ ì‘ì„±
- ì ìˆ˜ì™€ í”¼ë“œë°±ì€ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥

[í˜„ì—… ITê¸°ì—… ìì†Œì„œ ë¶„ì„ ê¸°ì¤€]
1. tech_fit (ê¸°ìˆ  ì í•©ì„±): ì‚¬ìš© ê¸°ìˆ  ìŠ¤íƒ, í”„ë¡œì íŠ¸ ê²½í—˜, ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì´ ëª…ì‹œë˜ì–´ ìˆëŠ”ì§€
2. job_understanding (ì§ë¬´ ì´í•´ë„): í•´ë‹¹ í¬ì§€ì…˜ì˜ ì—­í• Â·ì±…ì„ì— ëŒ€í•œ ëª…í™•í•œ ì´í•´ê°€ ë“œëŸ¬ë‚˜ëŠ”ì§€
3. growth_potential (ì„±ì¥ ê°€ëŠ¥ì„±): í•™ìŠµ íƒœë„, ìƒˆë¡œìš´ ê¸°ìˆ  ìŠµë“ ê²½í—˜ì´ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œë˜ì–´ ìˆëŠ”ì§€
4. teamwork_communication (íŒ€ì›Œí¬/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜): í˜‘ì—… ê²½í—˜, ê°ˆë“± í•´ê²° ì‚¬ë¡€ê°€ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ ë˜ì–´ ìˆëŠ”ì§€
5. motivation_company_fit (ë™ê¸°/íšŒì‚¬ ì´í•´ë„): ì§€ì› ë™ê¸°, íšŒì‚¬ì™€ì˜ ê°€ì¹˜ê´€ ì¼ì¹˜ ì—¬ë¶€ê°€ ëª…í™•í•œì§€
6. problem_solving (ë¬¸ì œ í•´ê²° ëŠ¥ë ¥): STAR ê¸°ë²• ì ìš©, êµ¬ì²´ì  ì‚¬ë¡€ê°€ ì œì‹œë˜ì–´ ìˆëŠ”ì§€
7. performance_orientation (ì„±ê³¼ ì§€í–¥ì„±): ì •ëŸ‰ì  ì„±ê³¼, ì„íŒ©íŠ¸ ìˆëŠ” ê²°ê³¼ê°€ ëª…ì‹œë˜ì–´ ìˆëŠ”ì§€
8. grammar_expression (ë¬¸ë²• ë° í‘œí˜„): ë¬¸ì¥ êµ¬ì¡°, ì „ë¬¸ì„±, ì˜¤ë¥˜ ì •ë„ê°€ ì ì ˆí•œì§€

[ì¶œë ¥ í˜•ì‹]
ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆì— ë§ì¶° ì¶œë ¥:
{{
  "cover_letter_analysis": {{
    "tech_fit": {{"score": 0, "feedback": ""}},
    "job_understanding": {{"score": 0, "feedback": ""}},
    "growth_potential": {{"score": 0, "feedback": ""}},
    "teamwork_communication": {{"score": 0, "feedback": ""}},
    "motivation_company_fit": {{"score": 0, "feedback": ""}},
    "problem_solving": {{"score": 0, "feedback": ""}},
    "performance_orientation": {{"score": 0, "feedback": ""}},
    "grammar_expression": {{"score": 0, "feedback": ""}}
  }},
  "overall_summary": {{
    "total_score": 0,
    "recommendation": ""
  }}
}}

[ì…ë ¥ ë¬¸ì„œ]
{content}

[ìš”êµ¬ì‚¬í•­]
- ê° í•­ëª©ì„ ì‹¤ì œ ë¶„ì„í•˜ì—¬ 0~10ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš” (0ì  = ì „í˜€ ì¶©ì¡±í•˜ì§€ ì•ŠìŒ, 10ì  = ë§¤ìš° ìš°ìˆ˜)
- ì ìˆ˜ëŠ” ë°˜ë“œì‹œ 0~10 ì •ìˆ˜ë¡œ ì…ë ¥í•˜ì„¸ìš”
- feedbackì€ ê°„ë‹¨í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
- JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”
"""
        elif document_type == "portfolio":
            analysis_prompt = f"""
[ROLE] ë‹¹ì‹ ì€ ì±„ìš©ë‹´ë‹¹ìì…ë‹ˆë‹¤. ì…ë ¥ëœ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì•„ë˜ ê¸°ì¤€ì— ë”°ë¼ ë¶„ì„í•˜ê³  ì ìˆ˜í™”í•´ì•¼ í•©ë‹ˆë‹¤.

[ë¶„ì„ ê¸°ì¤€]
- ê° í•­ëª©ì€ 0~10ì ìœ¼ë¡œ í‰ê°€ (10ì  = ë§¤ìš° ìš°ìˆ˜, 0ì  = ì „í˜€ ì¶©ì¡±í•˜ì§€ ì•ŠìŒ)
- ê° í•­ëª©ë³„ë¡œ ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì„ ê°„ë‹¨íˆ í”¼ë“œë°±ìœ¼ë¡œ ì‘ì„±
- ì ìˆ˜ì™€ í”¼ë“œë°±ì€ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥

[í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ê¸°ì¤€]
1. project_overview (í”„ë¡œì íŠ¸ ê°œìš” ëª…í™•ì„±): í”„ë¡œì íŠ¸ ëª©ì ê³¼ ê°œìš”ê°€ ëª…í™•í•˜ê²Œ ì„¤ëª…ë˜ì–´ ìˆëŠ”ì§€
2. tech_stack (ì‚¬ìš© ê¸°ìˆ  ìŠ¤íƒ): ì‚¬ìš©ëœ ê¸°ìˆ ì´ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œë˜ì–´ ìˆëŠ”ì§€
3. personal_contribution (ê°œì¸ ê¸°ì—¬ë„ ëª…í™•ì„±): ë³¸ì¸ì˜ ê¸°ì—¬ë„ê°€ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ ë˜ì–´ ìˆëŠ”ì§€
4. achievement_metrics (ì •ëŸ‰ì  ì„±ê³¼ ì—¬ë¶€): í”„ë¡œì íŠ¸ ì„±ê³¼ê°€ ì •ëŸ‰ì ìœ¼ë¡œ ì œì‹œë˜ì–´ ìˆëŠ”ì§€
5. visual_quality (ì‹œê° ìë£Œ í’ˆì§ˆ): ìŠ¤í¬ë¦°ìƒ·, ë‹¤ì´ì–´ê·¸ë¨ ë“±ì´ ì ì ˆí•˜ê²Œ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€
6. documentation_quality (ë¬¸ì„œí™” ìˆ˜ì¤€): ì½”ë“œ ì„¤ëª…, README ë“±ì´ ì˜ ì‘ì„±ë˜ì–´ ìˆëŠ”ì§€
7. job_relevance (ì§ë¬´ ê´€ë ¨ì„±): ì§€ì› ì§ë¬´ì™€ ê´€ë ¨ëœ í”„ë¡œì íŠ¸ì¸ì§€
8. unique_features (ë…ì°½ì  ê¸°ëŠ¥/ì•„ì´ë””ì–´): ì°¨ë³„í™”ëœ ê¸°ëŠ¥ì´ë‚˜ ì•„ì´ë””ì–´ê°€ ìˆëŠ”ì§€
9. maintainability (ìœ ì§€ë³´ìˆ˜ì„±): ì½”ë“œ êµ¬ì¡°ì™€ ë¬¸ì„œí™”ê°€ ìœ ì§€ë³´ìˆ˜í•˜ê¸° ì¢‹ì€ì§€

[ì¶œë ¥ í˜•ì‹]
ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆì— ë§ì¶° ì¶œë ¥:
{{
  "portfolio_analysis": {{
    "project_overview": {{"score": 0, "feedback": ""}},
    "tech_stack": {{"score": 0, "feedback": ""}},
    "personal_contribution": {{"score": 0, "feedback": ""}},
    "achievement_metrics": {{"score": 0, "feedback": ""}},
    "visual_quality": {{"score": 0, "feedback": ""}},
    "documentation_quality": {{"score": 0, "feedback": ""}},
    "job_relevance": {{"score": 0, "feedback": ""}},
    "unique_features": {{"score": 0, "feedback": ""}},
    "maintainability": {{"score": 0, "feedback": ""}}
  }},
  "overall_summary": {{
    "total_score": 0,
    "recommendation": ""
  }}
}}

[ì…ë ¥ ë¬¸ì„œ]
{content}

[ìš”êµ¬ì‚¬í•­]
- ê° í•­ëª©ì„ ì‹¤ì œ ë¶„ì„í•˜ì—¬ 0~10ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš” (0ì  = ì „í˜€ ì¶©ì¡±í•˜ì§€ ì•ŠìŒ, 10ì  = ë§¤ìš° ìš°ìˆ˜)
- ì ìˆ˜ëŠ” ë°˜ë“œì‹œ 0~10 ì •ìˆ˜ë¡œ ì…ë ¥í•˜ì„¸ìš”
- feedbackì€ ê°„ë‹¨í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
- JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”
"""
        else:
            # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (ê¸°ì¡´ê³¼ ë™ì¼)
            analysis_prompt = f"""
[ROLE] ë‹¹ì‹ ì€ ì±„ìš©ë‹´ë‹¹ìì…ë‹ˆë‹¤. ì…ë ¥ëœ ë¬¸ì„œ({document_type})ë¥¼ ì•„ë˜ ê¸°ì¤€ì— ë”°ë¼ ë¶„ì„í•˜ê³  ì ìˆ˜í™”í•´ì•¼ í•©ë‹ˆë‹¤.

[ë¶„ì„ ê¸°ì¤€]
- ê° í•­ëª©ì€ 0~10ì ìœ¼ë¡œ í‰ê°€ (10ì  = ë§¤ìš° ìš°ìˆ˜, 0ì  = ì „í˜€ ì¶©ì¡±í•˜ì§€ ì•ŠìŒ)
- ê° í•­ëª©ë³„ë¡œ ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì„ ê°„ë‹¨íˆ í”¼ë“œë°±ìœ¼ë¡œ ì‘ì„±
- ì ìˆ˜ì™€ í”¼ë“œë°±ì€ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥

[ì´ë ¥ì„œ ë¶„ì„ ê¸°ì¤€]
1. basic_info_completeness (ì´ë¦„, ì—°ë½ì²˜, ì´ë©”ì¼, GitHub/LinkedIn ì—¬ë¶€)
2. job_relevance (ì§ë¬´ ì í•©ì„±)
3. experience_clarity (ê²½ë ¥ ì„¤ëª… ëª…í™•ì„±)
4. tech_stack_clarity (ê¸°ìˆ  ìŠ¤íƒ ëª…í™•ì„±)
5. project_recency (í”„ë¡œì íŠ¸ ìµœì‹ ì„±)
6. achievement_metrics (ì •ëŸ‰ì  ì„±ê³¼ ì§€í‘œ ì—¬ë¶€)
7. readability (ê°€ë…ì„±)
8. typos_and_errors (ì˜¤íƒˆì ì—¬ë¶€)
9. update_freshness (ìµœì‹  ìˆ˜ì • ì—¬ë¶€)

[ìê¸°ì†Œê°œì„œ ë¶„ì„ ê¸°ì¤€]
1. motivation_relevance (ì§€ì› ë™ê¸° ì§ë¬´/íšŒì‚¬ì™€ì˜ ì—°ê²°ì„±)
2. problem_solving_STAR (STAR ê¸°ë²• ì ìš© ì—¬ë¶€)
3. quantitative_impact (ì •ëŸ‰ì  ì„±ê³¼ ì–¸ê¸‰ ì—¬ë¶€)
4. job_understanding (ì§ë¬´ ì´í•´ë„)
5. unique_experience (ì°¨ë³„í™”ëœ ê²½í—˜)
6. logical_flow (ë…¼ë¦¬ êµ¬ì¡°)
7. keyword_diversity (ì „ë¬¸ ìš©ì–´ ë‹¤ì–‘ì„±)
8. sentence_readability (ë¬¸ì¥ ê°€ë…ì„±)
9. typos_and_errors (ì˜¤íƒˆì ì—¬ë¶€)

[í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ê¸°ì¤€]
1. project_overview (í”„ë¡œì íŠ¸ ê°œìš” ëª…í™•ì„±)
2. tech_stack (ì‚¬ìš© ê¸°ìˆ  ìŠ¤íƒ)
3. personal_contribution (ê°œì¸ ê¸°ì—¬ë„ ëª…í™•ì„±)
4. achievement_metrics (ì •ëŸ‰ì  ì„±ê³¼ ì—¬ë¶€)
5. visual_quality (ì‹œê° ìë£Œ í’ˆì§ˆ)
6. documentation_quality (ë¬¸ì„œí™” ìˆ˜ì¤€)
7. job_relevance (ì§ë¬´ ê´€ë ¨ì„±)
8. unique_features (ë…ì°½ì  ê¸°ëŠ¥/ì•„ì´ë””ì–´)
9. maintainability (ìœ ì§€ë³´ìˆ˜ì„±)

[ì¶œë ¥ í˜•ì‹]
ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆì— ë§ì¶° ì¶œë ¥:
{{
  "resume_analysis": {{
    "basic_info_completeness": {{"score": 0, "feedback": ""}},
    "job_relevance": {{"score": 0, "feedback": ""}},
    "experience_clarity": {{"score": 0, "feedback": ""}},
    "tech_stack_clarity": {{"score": 0, "feedback": ""}},
    "project_recency": {{"score": 0, "feedback": ""}},
    "achievement_metrics": {{"score": 0, "feedback": ""}},
    "readability": {{"score": 0, "feedback": ""}},
    "typos_and_errors": {{"score": 0, "feedback": ""}},
    "update_freshness": {{"score": 0, "feedback": ""}}
  }},
  "cover_letter_analysis": {{
    "motivation_relevance": {{"score": 0, "feedback": ""}},
    "problem_solving_STAR": {{"score": 0, "feedback": ""}},
    "quantitative_impact": {{"score": 0, "feedback": ""}},
    "job_understanding": {{"score": 0, "feedback": ""}},
    "unique_experience": {{"score": 0, "feedback": ""}},
    "logical_flow": {{"score": 0, "feedback": ""}},
    "keyword_diversity": {{"score": 0, "feedback": ""}},
    "sentence_readability": {{"score": 0, "feedback": ""}},
    "typos_and_errors": {{"score": 0, "feedback": ""}}
  }},
  "portfolio_analysis": {{
    "project_overview": {{"score": 0, "feedback": ""}},
    "tech_stack": {{"score": 0, "feedback": ""}},
    "personal_contribution": {{"score": 0, "feedback": ""}},
    "achievement_metrics": {{"score": 0, "feedback": ""}},
    "visual_quality": {{"score": 0, "feedback": ""}},
    "documentation_quality": {{"score": 0, "feedback": ""}},
    "job_relevance": {{"score": 0, "feedback": ""}},
    "unique_features": {{"score": 0, "feedback": ""}},
    "maintainability": {{"score": 0, "feedback": ""}}
  }},
  "overall_summary": {{
    "total_score": 0,
    "recommendation": ""
  }}
}}

[ì…ë ¥ ë¬¸ì„œ]
{content}

[ìš”êµ¬ì‚¬í•­]
- ì ìˆ˜ëŠ” ë°˜ë“œì‹œ 0~10 ì •ìˆ˜
- feedbackì€ ê°„ë‹¨í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±
- JSONë§Œ ì¶œë ¥
"""
        
        # Gemini API í˜¸ì¶œ (JSON ê°•ì œ)
        json_model = genai.GenerativeModel(
            'gemini-1.5-flash',
            generation_config={
                'response_mime_type': 'application/json'
            }
        )
        response = await asyncio.to_thread(
            json_model.generate_content,
            analysis_prompt
        )
        
        # ì‘ë‹µ ê²€ì¦
        if not response or not response.text or response.text.strip() == "":
            raise HTTPException(status_code=500, detail="Gemini APIì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
        
        # ì¼ë¶€ ë“œë¼ì´ë²„ëŠ” .textê°€ ì—†ì„ ìˆ˜ ìˆì–´ ì•ˆì „ ì ‘ê·¼
        response_text = getattr(response, 'text', '')
        if hasattr(response, 'candidates') and not response_text:
            try:
                # application/jsonë¡œ ë‚´ë ¤ì˜¤ë©´ first candidateì˜ contentë¥¼ í•©ì„±
                parts = []
                for c in response.candidates or []:
                    for p in getattr(c, 'content', {}).get('parts', []):
                        parts.append(str(getattr(p, 'text', '')))
                response_text = ''.join(parts).strip()
            except Exception:
                response_text = ''
        response_text = (response_text or '').strip()
        print(f"Gemini API ì‘ë‹µ: {response_text[:200]}...")  # ë””ë²„ê¹…ìš© ë¡œê·¸
        
        # Markdown ì½”ë“œ ë¸”ë¡ ì œê±° (ì •ê·œì‹ ì‚¬ìš©ìœ¼ë¡œ ì†ë„ í–¥ìƒ)
        import re
        response_text = re.sub(r'^```json\s*|\s*```$', '', response_text, flags=re.MULTILINE)
        response_text = response_text.strip()
        print(f"ì •ë¦¬ëœ ì‘ë‹µ: {response_text[:200]}...")  # ë””ë²„ê¹…ìš© ë¡œê·¸
        
        # JSON íŒŒì‹± (ìµœì í™”)
        import json
        try:
            analysis_result = json.loads(response_text)
            
            # ì‘ë‹µ êµ¬ì¡° ê²€ì¦ (ë¹ ë¥¸ ê²€ì¦)
            if not isinstance(analysis_result, dict):
                raise ValueError("ì‘ë‹µì´ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
            
            # ë¬¸ì„œ íƒ€ì…ë³„ë¡œë§Œ í•„ìš”í•œ í‚¤ í™•ì¸ (ì†ë„ í–¥ìƒ)
            if document_type == "resume":
                if "resume_analysis" not in analysis_result:
                    raise ValueError("ì´ë ¥ì„œ ë¶„ì„ ê²°ê³¼ê°€ ì‘ë‹µì— ì—†ìŠµë‹ˆë‹¤.")
            elif document_type == "cover_letter":
                if "cover_letter_analysis" not in analysis_result:
                    raise ValueError("ìê¸°ì†Œê°œì„œ ë¶„ì„ ê²°ê³¼ê°€ ì‘ë‹µì— ì—†ìŠµë‹ˆë‹¤.")
            elif document_type == "portfolio":
                if "portfolio_analysis" not in analysis_result:
                    raise ValueError("í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ê²°ê³¼ê°€ ì‘ë‹µì— ì—†ìŠµë‹ˆë‹¤.")
            
            if "overall_summary" not in analysis_result:
                raise ValueError("ì „ì²´ ìš”ì•½ì´ ì‘ë‹µì— ì—†ìŠµë‹ˆë‹¤.")
            
            # ì „ì²´ ì ìˆ˜ ê³„ì‚° (ë¬¸ì„œ íƒ€ì…ë³„ë¡œë§Œ ê³„ì‚°í•˜ì—¬ ì†ë„ í–¥ìƒ)
            total_score = 0
            count = 0
            
            print(f"ğŸ” ë¬¸ì„œ íƒ€ì…: {document_type}")
            print(f"ğŸ” ë¶„ì„ ê²°ê³¼ êµ¬ì¡°: {list(analysis_result.keys())}")
            
            if document_type == "resume" and "resume_analysis" in analysis_result:
                print(f"ğŸ” ì´ë ¥ì„œ ë¶„ì„ í•­ëª©: {list(analysis_result['resume_analysis'].keys())}")
                for key, value in analysis_result["resume_analysis"].items():
                    print(f"ğŸ” {key}: {value}")
                    if isinstance(value, dict) and "score" in value:
                        total_score += value["score"]
                        count += 1
                        print(f"ğŸ” {key} ì ìˆ˜: {value['score']}")
            elif document_type == "cover_letter" and "cover_letter_analysis" in analysis_result:
                print(f"ğŸ” ìê¸°ì†Œê°œì„œ ë¶„ì„ í•­ëª©: {list(analysis_result['cover_letter_analysis'].keys())}")
                for key, value in analysis_result["cover_letter_analysis"].items():
                    print(f"ğŸ” {key}: {value}")
                    if isinstance(value, dict) and "score" in value:
                        total_score += value["score"]
                        count += 1
                        print(f"ğŸ” {key} ì ìˆ˜: {value['score']}")
            elif document_type == "portfolio" and "portfolio_analysis" in analysis_result:
                print(f"ğŸ” í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ í•­ëª©: {list(analysis_result['portfolio_analysis'].keys())}")
                for key, value in analysis_result["portfolio_analysis"].items():
                    print(f"ğŸ” {key}: {value}")
                    if isinstance(value, dict) and "score" in value:
                        total_score += value["score"]
                        count += 1
                        print(f"ğŸ” {key} ì ìˆ˜: {value['score']}")
            
            print(f"ğŸ” ì´ ì ìˆ˜: {total_score}, í•­ëª© ìˆ˜: {count}")
            
            # í‰ê·  ì ìˆ˜ ê³„ì‚° (ì†Œìˆ˜ì  í¬í•¨)
            if count > 0:
                average_score = round(total_score / count, 1)
            else:
                average_score = 0
            
            print(f"ğŸ” í‰ê·  ì ìˆ˜: {average_score}")
            
            # ì¶”ì²œì‚¬í•­ ìƒì„±
            if document_type == "resume":
                if average_score >= 8:
                    recommendation = "ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ì´ë ¥ì„œì…ë‹ˆë‹¤. í˜„ì¬ ìƒíƒœë¥¼ ìœ ì§€í•˜ì„¸ìš”."
                elif average_score >= 6:
                    recommendation = "ì–‘í˜¸í•œ ìˆ˜ì¤€ì´ì§€ë§Œ ëª‡ ê°€ì§€ ê°œì„ ì ì´ ìˆìŠµë‹ˆë‹¤. í”¼ë“œë°±ì„ ì°¸ê³ í•˜ì—¬ ìˆ˜ì •í•˜ì„¸ìš”."
                else:
                    recommendation = "ì „ë°˜ì ì¸ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. ê° í•­ëª©ë³„ í”¼ë“œë°±ì„ ì°¸ê³ í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”."
            elif document_type == "cover_letter":
                if average_score >= 8:
                    recommendation = "ë§¤ìš° ìš°ìˆ˜í•œ ìê¸°ì†Œê°œì„œì…ë‹ˆë‹¤. í˜„ì¬ ìƒíƒœë¥¼ ìœ ì§€í•˜ì„¸ìš”."
                elif average_score >= 6:
                    recommendation = "ì–‘í˜¸í•œ ìˆ˜ì¤€ì´ì§€ë§Œ ëª‡ ê°€ì§€ ê°œì„ ì ì´ ìˆìŠµë‹ˆë‹¤. í”¼ë“œë°±ì„ ì°¸ê³ í•˜ì—¬ ìˆ˜ì •í•˜ì„¸ìš”."
                else:
                    recommendation = "ì „ë°˜ì ì¸ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. ê° í•­ëª©ë³„ í”¼ë“œë°±ì„ ì°¸ê³ í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”."
            elif document_type == "portfolio":
                if average_score >= 8:
                    recommendation = "ë§¤ìš° ìš°ìˆ˜í•œ í¬íŠ¸í´ë¦¬ì˜¤ì…ë‹ˆë‹¤. í˜„ì¬ ìƒíƒœë¥¼ ìœ ì§€í•˜ì„¸ìš”."
                elif average_score >= 6:
                    recommendation = "ì–‘í˜¸í•œ ìˆ˜ì¤€ì´ì§€ë§Œ ëª‡ ê°€ì§€ ê°œì„ ì ì´ ìˆìŠµë‹ˆë‹¤. í”¼ë“œë°±ì„ ì°¸ê³ í•˜ì—¬ ìˆ˜ì •í•˜ì„¸ìš”."
                else:
                    recommendation = "ì „ë°˜ì ì¸ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. ê° í•­ëª©ë³„ í”¼ë“œë°±ì„ ì°¸ê³ í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”."
            else:
                recommendation = "ë¬¸ì„œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
            
            analysis_result["overall_summary"]["total_score"] = average_score
            analysis_result["overall_summary"]["recommendation"] = recommendation
            
            processing_time = (datetime.now() - start_time).total_seconds()
            print(f"ë¶„ì„ ì²˜ë¦¬ ì™„ë£Œ: {processing_time:.2f}ì´ˆ")
            
            return DetailedAnalysisResponse(**analysis_result)
            
        except json.JSONDecodeError as e:
            print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            print(f"ì‘ë‹µ ë‚´ìš©: {response_text}")
            raise HTTPException(status_code=500, detail=f"ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        except ValueError as e:
            print(f"ì‘ë‹µ êµ¬ì¡° ì˜¤ë¥˜: {e}")
            print(f"ì‘ë‹µ ë‚´ìš©: {response_text}")
            raise HTTPException(status_code=500, detail=f"ë¶„ì„ ê²°ê³¼ êµ¬ì¡° ì˜¤ë¥˜: {str(e)}")
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìƒì„¸ ë¶„ì„ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@router.post("/file")
async def upload_and_summarize_file(
    file: UploadFile = File(...),
    summary_type: str = Form("general")
):
    """íŒŒì¼ ì—…ë¡œë“œ ë° ìš”ì•½"""
    try:
        # íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
        if not validate_file(file):
            raise HTTPException(
                status_code=400, 
                detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. PDF, DOC, DOCX, TXT íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            )
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = 0
        content = await file.read()
        file_size = len(content)
        
        if file_size > MAX_FILE_SIZE:
            raise HTTPException(
                status_code=400,
                detail="íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ 10MBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            )
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        file_ext = os.path.splitext(file.filename.lower())[1]
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as temp_file:
            temp_file.write(content)
            temp_file_path = temp_file.name
        
        try:
            # íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            extracted_text = await extract_text_from_file(temp_file_path, file_ext)
            
            if not extracted_text or extracted_text.strip() == "":
                raise HTTPException(
                    status_code=400,
                    detail="íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                )
            
            # Gemini APIë¡œ ìš”ì•½ ìƒì„±
            summary_result = await generate_summary_with_gemini(extracted_text, summary_type)
            
            return {
                "filename": file.filename,
                "file_size": file_size,
                "extracted_text_length": len(extracted_text),
                "summary": summary_result.summary,
                "keywords": summary_result.keywords,
                "confidence_score": summary_result.confidence_score,
                "processing_time": summary_result.processing_time,
                "summary_type": summary_type
            }
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(temp_file_path):
                os.unlink(temp_file_path)
                
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

@router.post("/analyze")
async def analyze_documents(
    file: UploadFile = File(...),
    document_type: str = Form("resume"),  # resume, cover_letter, portfolio
    applicant_name: str = Form(""),  # ì§€ì›ì ì´ë¦„
    position: str = Form(""),  # í¬ë§ ì§ë¬´
    department: str = Form("")  # í¬ë§ ë¶€ì„œ
):
    # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë³´ë‚´ëŠ” í•œê¸€ ë¬¸ì„œ íƒ€ì…ì„ ì˜ë¬¸ìœ¼ë¡œ ë³€í™˜
    document_type_mapping = {
        "ì´ë ¥ì„œ": "resume",
        "ìê¸°ì†Œê°œì„œ": "cover_letter", 
        "í¬íŠ¸í´ë¦¬ì˜¤": "portfolio"
    }
    
    # í•œê¸€ë¡œ ë“¤ì–´ì˜¨ ê²½ìš° ì˜ë¬¸ìœ¼ë¡œ ë³€í™˜
    if document_type in document_type_mapping:
        document_type = document_type_mapping[document_type]
    
    print(f"ğŸ” ë³€í™˜ëœ ë¬¸ì„œ íƒ€ì…: {document_type}")
    """íŒŒì¼ ì—…ë¡œë“œ ë° ìƒì„¸ ë¶„ì„"""
    try:
        # íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
        if not validate_file(file):
            raise HTTPException(
                status_code=400, 
                detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. PDF, DOC, DOCX, TXT íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            )
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = 0
        content = await file.read()
        file_size = len(content)
        
        if file_size > MAX_FILE_SIZE:
            raise HTTPException(
                status_code=400,
                detail="íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ 10MBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            )
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        file_ext = os.path.splitext(file.filename.lower())[1]
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as temp_file:
            temp_file.write(content)
            temp_file_path = temp_file.name
        
        try:
            # íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            extracted_text = await extract_text_from_file(temp_file_path, file_ext)
            
            if not extracted_text or extracted_text.strip() == "":
                raise HTTPException(
                    status_code=400,
                    detail="íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                )
            
            # Gemini APIë¡œ ìƒì„¸ ë¶„ì„ ìƒì„±
            analysis_result = await generate_detailed_analysis_with_gemini(extracted_text, document_type)
            
            # ì§€ì›ì ì •ë³´ ìƒì„± ë° MongoDBì— ì €ì¥
            if document_type == "resume" and applicant_name and position and department:
                try:
                    # MongoDB ì—°ê²°
                    from motor.motor_asyncio import AsyncIOMotorClient
                    import uuid
                    from datetime import datetime
                    
                    mongodb_client = AsyncIOMotorClient("mongodb://localhost:27017/")
                    mongodb_db = mongodb_client.Hireme
                    
                    # ì§€ì›ì ë°ì´í„° êµ¬ì„±
                    applicant_data = {
                        "id": str(uuid.uuid4()),
                        "name": applicant_name,
                        "position": position,
                        "department": department,
                        "experience": 0,  # ê¸°ë³¸ê°’, ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸ ê°€ëŠ¥
                        "skills": [],  # ê¸°ë³¸ê°’, ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸ ê°€ëŠ¥
                        "ai_score": analysis_result.overall_summary.total_score,
                        "ai_analysis": analysis_result.overall_summary.recommendation,
                        "status": "ì‹ ê·œ",
                        "created_at": datetime.now(),
                        "updated_at": datetime.now()
                    }
                    
                    # MongoDBì— ì €ì¥
                    result = await mongodb_db.resumes.insert_one(applicant_data)
                    applicant_data["_id"] = result.inserted_id
                    
                    mongodb_client.close()
                    
                    print(f"âœ… ì§€ì›ì ì •ë³´ê°€ MongoDBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {applicant_name}")
                    
                except Exception as e:
                    print(f"âš ï¸ MongoDB ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            
            # ë¬¸ì„œ íƒ€ì…ì— ë”°ë¼ í•´ë‹¹í•˜ëŠ” ë¶„ì„ ê²°ê³¼ë§Œ ë°˜í™˜
            if document_type == "resume":
                return {
                    "filename": file.filename,
                    "file_size": file_size,
                    "extracted_text_length": len(extracted_text),
                    "document_type": document_type,
                    "analysis_type": "resume_analysis",
                    "analysis_result": {
                        "resume_analysis": analysis_result.resume_analysis,
                        "overall_summary": analysis_result.overall_summary
                    },
                    "applicant_saved": applicant_name and position and department
                }
            elif document_type == "cover_letter":
                return {
                    "filename": file.filename,
                    "file_size": file_size,
                    "extracted_text_length": len(extracted_text),
                    "document_type": document_type,
                    "analysis_type": "cover_letter_analysis",
                    "analysis_result": {
                        "cover_letter_analysis": analysis_result.cover_letter_analysis,
                        "overall_summary": analysis_result.overall_summary
                    }
                }
            elif document_type == "portfolio":
                return {
                    "filename": file.filename,
                    "file_size": file_size,
                    "extracted_text_length": len(extracted_text),
                    "document_type": document_type,
                    "analysis_type": "portfolio_analysis",
                    "analysis_result": {
                        "portfolio_analysis": analysis_result.portfolio_analysis,
                        "overall_summary": analysis_result.overall_summary
                    }
                }
            else:
                # ê¸°ë³¸ê°’: ì „ì²´ ê²°ê³¼ ë°˜í™˜
                return {
                    "filename": file.filename,
                    "file_size": file_size,
                    "extracted_text_length": len(extracted_text),
                    "document_type": document_type,
                    "analysis_type": "full_analysis",
                    "analysis_result": analysis_result.dict()
                }
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(temp_file_path):
                os.unlink(temp_file_path)
                
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

@router.post("/summarize")
async def summarize_text(request: SummaryRequest):
    """í…ìŠ¤íŠ¸ ì§ì ‘ ìš”ì•½"""
    try:
        if not request.content or len(request.content.strip()) == 0:
            raise HTTPException(status_code=400, detail="ìš”ì•½í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        summary_result = await generate_summary_with_gemini(
            request.content, 
            request.summary_type
        )
        
        return summary_result
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@router.post("/validate-document-type")
async def validate_document_type(request: DocumentValidationRequest):
    """ë¬¸ì„œ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì„ íƒëœ ë¬¸ì„œ íƒ€ì…ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦"""
    try:
        if not request.content or len(request.content.strip()) == 0:
            raise HTTPException(status_code=400, detail="ê²€ì¦í•  ë¬¸ì„œ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        if not GOOGLE_API_KEY:
            raise HTTPException(status_code=500, detail="Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ë¬¸ì„œ íƒ€ì… ê²€ì¦ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        validation_prompt = f"""
        ë‹¤ìŒ ë¬¸ì„œ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì´ê²ƒì´ "{request.expected_type}"ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.
        
        ë¬¸ì„œ ë‚´ìš©:
        {request.content[:2000]}  # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
        
        ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•´ì£¼ì„¸ìš”:
        
        ì´ë ¥ì„œì˜ ê²½ìš°:
        - ê°œì¸ ì •ë³´ (ì´ë¦„, ì—°ë½ì²˜, ìƒë…„ì›”ì¼ ë“±)
        - í•™ë ¥ ì •ë³´
        - ê²½ë ¥ ì •ë³´ (íšŒì‚¬ëª…, ì§ë¬´, ê¸°ê°„)
        - ê¸°ìˆ  ìŠ¤íƒ
        - ìê²©ì¦
        - í”„ë¡œì íŠ¸ ê²½í—˜
        
        ìê¸°ì†Œê°œì„œì˜ ê²½ìš°:
        - ì§€ì› ë™ê¸°
        - ì„±ì¥ ê³¼ì •
        - ì§€ì› ì§ë¬´ì— ëŒ€í•œ ì´í•´
        - ë³¸ì¸ì˜ ê°•ì ê³¼ ì•½ì 
        - ì…ì‚¬ í›„ í¬ë¶€
        
        í¬íŠ¸í´ë¦¬ì˜¤ì˜ ê²½ìš°:
        - í”„ë¡œì íŠ¸ ê°œìš”
        - ì‚¬ìš© ê¸°ìˆ 
        - êµ¬í˜„ ê³¼ì •
        - ê²°ê³¼ë¬¼
        - GitHub ë§í¬ ë“±
        
        ì‘ë‹µ í˜•ì‹:
        - ìœ íš¨ì„±: true/false
        - ì‹ ë¢°ë„: 0.0-1.0 (ì†Œìˆ˜ì )
        - íŒë‹¨ ì´ìœ : ê°„ë‹¨í•œ ì„¤ëª…
        - ì œì•ˆ íƒ€ì…: ì‹¤ì œ ë¬¸ì„œ íƒ€ì… (ì´ë ¥ì„œ/ìê¸°ì†Œê°œì„œ/í¬íŠ¸í´ë¦¬ì˜¤)
        
        JSON í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        # Gemini API í˜¸ì¶œ
        response = await asyncio.to_thread(
            model.generate_content,
            validation_prompt
        )
        
        response_text = response.text.strip()
        
        # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
        try:
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            if json_start != -1 and json_end != 0:
                json_str = response_text[json_start:json_end]
                import json
                parsed_response = json.loads(json_str)
                
                return DocumentValidationResponse(
                    is_valid=parsed_response.get('ìœ íš¨ì„±', False),
                    confidence=parsed_response.get('ì‹ ë¢°ë„', 0.0),
                    reason=parsed_response.get('íŒë‹¨ ì´ìœ ', 'ë¶„ì„ ì‹¤íŒ¨'),
                    suggested_type=parsed_response.get('ì œì•ˆ íƒ€ì…', 'ì•Œ ìˆ˜ ì—†ìŒ')
                )
        except (json.JSONDecodeError, KeyError):
            pass
        
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ë¶„ì„ìœ¼ë¡œ ëŒ€ì²´
        response_lower = response_text.lower()
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
        resume_keywords = ['ì´ë ¥ì„œ', 'resume', 'cv', 'ê²½ë ¥', 'í•™ë ¥', 'ìê²©ì¦', 'í”„ë¡œì íŠ¸']
        cover_letter_keywords = ['ìê¸°ì†Œê°œì„œ', 'ìì†Œì„œ', 'cover letter', 'ì§€ì›ë™ê¸°', 'ì„±ì¥ê³¼ì •', 'í¬ë¶€']
        portfolio_keywords = ['í¬íŠ¸í´ë¦¬ì˜¤', 'portfolio', 'í”„ë¡œì íŠ¸', 'github', 'êµ¬í˜„']
        
        expected_lower = request.expected_type.lower()
        
        if 'ì´ë ¥ì„œ' in expected_lower:
            relevant_keywords = resume_keywords
            conflicting_keywords = cover_letter_keywords + portfolio_keywords
        elif 'ìê¸°ì†Œê°œì„œ' in expected_lower:
            relevant_keywords = cover_letter_keywords
            conflicting_keywords = resume_keywords + portfolio_keywords
        elif 'í¬íŠ¸í´ë¦¬ì˜¤' in expected_lower:
            relevant_keywords = portfolio_keywords
            conflicting_keywords = resume_keywords + cover_letter_keywords
        else:
            relevant_keywords = []
            conflicting_keywords = []
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ìœ íš¨ì„± íŒë‹¨
        has_relevant = any(keyword in response_lower for keyword in relevant_keywords)
        has_conflicting = any(keyword in response_lower for keyword in conflicting_keywords)
        
        if has_conflicting:
            is_valid = False
            confidence = 0.8
            reason = f"ë¬¸ì„œ ë‚´ìš©ì´ {request.expected_type}ì™€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤."
            suggested_type = "ì•Œ ìˆ˜ ì—†ìŒ"
        elif has_relevant:
            is_valid = True
            confidence = 0.7
            reason = f"ë¬¸ì„œ ë‚´ìš©ì´ {request.expected_type}ì™€ ì¼ì¹˜í•©ë‹ˆë‹¤."
            suggested_type = request.expected_type
        else:
            is_valid = False
            confidence = 0.6
            reason = f"ë¬¸ì„œ ë‚´ìš©ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            suggested_type = "ì•Œ ìˆ˜ ì—†ìŒ"
        
        return DocumentValidationResponse(
            is_valid=is_valid,
            confidence=confidence,
            reason=reason,
            suggested_type=suggested_type
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¬¸ì„œ íƒ€ì… ê²€ì¦ ì‹¤íŒ¨: {str(e)}")

@router.post("/validate-uploaded-file")
async def validate_uploaded_file(
    file: UploadFile = File(...),
    expected_type: str = Form(...)
):
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì„ íƒëœ ë¬¸ì„œ íƒ€ì…ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦"""
    try:
        if not file.filename:
            raise HTTPException(status_code=400, detail="íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
        if not validate_file(file):
            raise HTTPException(status_code=400, detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        content = await file.read()
        file_size = len(content)
        
        if file_size > MAX_FILE_SIZE:
            raise HTTPException(status_code=400, detail="íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ 10MBê¹Œì§€ ì§€ì›í•©ë‹ˆë‹¤.")
        
        # íŒŒì¼ í™•ì¥ì í™•ì¸
        file_ext = os.path.splitext(file.filename.lower())[1]
        
        # ì„ì‹œ íŒŒì¼ ìƒì„±
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as temp_file:
            temp_file.write(content)
            temp_file_path = temp_file.name
        
        try:
            # íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            extracted_text = await extract_text_from_file(temp_file_path, file_ext)
            
            if not extracted_text or extracted_text.strip() == "":
                raise HTTPException(
                    status_code=400,
                    detail="íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                )
            
            # ë¬¸ì„œ íƒ€ì… ê²€ì¦
            validation_result = await validate_document_type_internal(extracted_text, expected_type)
            
            return {
                "filename": file.filename,
                "file_size": file_size,
                "extracted_text_length": len(extracted_text),
                "expected_type": expected_type,
                "validation_result": validation_result.dict()
            }
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(temp_file_path):
                os.unlink(temp_file_path)
                
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {str(e)}")

async def validate_document_type_internal(content: str, expected_type: str) -> DocumentValidationResponse:
    """ë‚´ë¶€ì ìœ¼ë¡œ ë¬¸ì„œ íƒ€ì…ì„ ê²€ì¦í•˜ëŠ” í•¨ìˆ˜"""
    # if not GOOGLE_API_KEY:
    #     raise HTTPException(status_code=500, detail="Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # ë¬¸ì„œ íƒ€ì… ê²€ì¦ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    validation_prompt = f"""
    ë‹¤ìŒ ë¬¸ì„œ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì´ê²ƒì´ "{expected_type}"ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.
    
    ë¬¸ì„œ ë‚´ìš©:
    {content[:2000]}  # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
    
    ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•´ì£¼ì„¸ìš”:
    
    ì´ë ¥ì„œì˜ ê²½ìš°:
    - ê°œì¸ ì •ë³´ (ì´ë¦„, ì—°ë½ì²˜, ìƒë…„ì›”ì¼ ë“±)
    - í•™ë ¥ ì •ë³´
    - ê²½ë ¥ ì •ë³´ (íšŒì‚¬ëª…, ì§ë¬´, ê¸°ê°„)
    - ê¸°ìˆ  ìŠ¤íƒ
    - ìê²©ì¦
    - í”„ë¡œì íŠ¸ ê²½í—˜
    
    ìê¸°ì†Œê°œì„œì˜ ê²½ìš°:
    - ì§€ì› ë™ê¸°
    - ì„±ì¥ ê³¼ì •
    - ì§€ì› ì§ë¬´ì— ëŒ€í•œ ì´í•´
    - ë³¸ì¸ì˜ ê°•ì ê³¼ ì•½ì 
    - ì…ì‚¬ í›„ í¬ë¶€
    
    í¬íŠ¸í´ë¦¬ì˜¤ì˜ ê²½ìš°:
    - í”„ë¡œì íŠ¸ ê°œìš”
    - ì‚¬ìš© ê¸°ìˆ 
    - êµ¬í˜„ ê³¼ì •
    - ê²°ê³¼ë¬¼
    - GitHub ë§í¬ ë“±
    
    ì‘ë‹µ í˜•ì‹:
    - ìœ íš¨ì„±: true/false
    - ì‹ ë¢°ë„: 0.0-1.0 (ì†Œìˆ˜ì )
    - íŒë‹¨ ì´ìœ : ê°„ë‹¨í•œ ì„¤ëª…
    - ì œì•ˆ íƒ€ì…: ì‹¤ì œ ë¬¸ì„œ íƒ€ì… (ì´ë ¥ì„œ/ìê¸°ì†Œê°œì„œ/í¬íŠ¸í´ë¦¬ì˜¤)
    
    JSON í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
    """
    
    # Gemini API í˜¸ì¶œ
    response = await asyncio.to_thread(
        model.generate_content,
        validation_prompt
    )
    
    response_text = response.text.strip()
    
    # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
    try:
        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        json_start = response_text.find('{')
        json_end = response_text.rfind('}') + 1
        if json_start != -1 and json_end != 0:
            json_str = response_text[json_start:json_end]
            import json
            parsed_response = json.loads(json_str)
            
            return DocumentValidationResponse(
                is_valid=parsed_response.get('ìœ íš¨ì„±', False),
                confidence=parsed_response.get('ì‹ ë¢°ë„', 0.0),
                reason=parsed_response.get('íŒë‹¨ ì´ìœ ', 'ë¶„ì„ ì‹¤íŒ¨'),
                suggested_type=parsed_response.get('ì œì•ˆ íƒ€ì…', 'ì•Œ ìˆ˜ ì—†ìŒ')
            )
    except (json.JSONDecodeError, KeyError):
        pass
    
    # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ë¶„ì„ìœ¼ë¡œ ëŒ€ì²´
    response_lower = response_text.lower()
    
    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
    resume_keywords = ['ì´ë ¥ì„œ', 'resume', 'cv', 'ê²½ë ¥', 'í•™ë ¥', 'ìê²©ì¦', 'í”„ë¡œì íŠ¸']
    cover_letter_keywords = ['ìê¸°ì†Œê°œì„œ', 'ìì†Œì„œ', 'cover letter', 'ì§€ì›ë™ê¸°', 'ì„±ì¥ê³¼ì •', 'í¬ë¶€']
    portfolio_keywords = ['í¬íŠ¸í´ë¦¬ì˜¤', 'portfolio', 'í”„ë¡œì íŠ¸', 'github', 'êµ¬í˜„']
    
    expected_lower = expected_type.lower()
    
    if 'ì´ë ¥ì„œ' in expected_lower:
        relevant_keywords = resume_keywords
        conflicting_keywords = cover_letter_keywords + portfolio_keywords
    elif 'ìê¸°ì†Œê°œì„œ' in expected_lower:
        relevant_keywords = cover_letter_keywords
        conflicting_keywords = resume_keywords + portfolio_keywords
    elif 'í¬íŠ¸í´ë¦¬ì˜¤' in expected_lower:
        relevant_keywords = portfolio_keywords
        conflicting_keywords = resume_keywords + cover_letter_keywords
    else:
        relevant_keywords = []
        conflicting_keywords = []
    
    # í‚¤ì›Œë“œ ê¸°ë°˜ ìœ íš¨ì„± íŒë‹¨
    has_relevant = any(keyword in response_lower for keyword in relevant_keywords)
    has_conflicting = any(keyword in response_lower for keyword in conflicting_keywords)
    
    if has_conflicting:
        is_valid = False
        confidence = 0.8
        reason = f"ë¬¸ì„œ ë‚´ìš©ì´ {expected_type}ì™€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤."
        suggested_type = "ì•Œ ìˆ˜ ì—†ìŒ"
    elif has_relevant:
        is_valid = True
        confidence = 0.7
        reason = f"ë¬¸ì„œ ë‚´ìš©ì´ {expected_type}ì™€ ì¼ì¹˜í•©ë‹ˆë‹¤."
        suggested_type = expected_type
    else:
        is_valid = False
        confidence = 0.6
        reason = f"ë¬¸ì„œ ë‚´ìš©ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        suggested_type = "ì•Œ ìˆ˜ ì—†ìŒ"
    
    return DocumentValidationResponse(
        is_valid=is_valid,
        confidence=confidence,
        reason=reason,
        suggested_type=suggested_type
    )

@router.get("/health")
async def upload_health_check():
    """ì—…ë¡œë“œ ì„œë¹„ìŠ¤ í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "gemini_api_configured": bool(GOOGLE_API_KEY),
        "supported_formats": list(ALLOWED_EXTENSIONS.keys()),
        "max_file_size_mb": MAX_FILE_SIZE // (1024 * 1024)
    }
