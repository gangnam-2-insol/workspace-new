import codecs
import csv
import locale
import os
import sys
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

import uvicorn
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ (ê°€ì¥ ë¨¼ì € ì‹¤í–‰)
load_dotenv()
from bson import ObjectId
from chatbot.routers.chatbot_router import router as chatbot_router
from fastapi import Depends, FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.responses import JSONResponse

# chatbot ë¼ìš°í„° ì¶”ê°€
<<<<<<< HEAD
=======
try:
    from github import router as github_router
    print("âœ… GitHub ë¼ìš°í„° import ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ GitHub ëª¨ë“ˆ import ì˜¤ë¥˜: {e}")
    github_router = None
>>>>>>> d2fe75e (250825 15:08 ì¸ì¬ìƒê´€ë¦¬ ì¶”ê°€)
from motor.motor_asyncio import AsyncIOMotorClient
from pydantic import BaseModel
from routers.applicants import get_mongo_service, get_similarity_service
from routers.applicants import router as applicants_router
from routers.integrated_ocr import router as integrated_ocr_router
from routers.job_posting import router as job_posting_router
from routers.pdf_ocr import router as pdf_ocr_router
from routers.pick_chatbot import router as pick_chatbot_router
from routers.sample_data import router as sample_data_router
from routers.upload import router as upload_router

# íšŒì‚¬ ì¸ì¬ìƒ ë¼ìš°í„° ì¶”ê°€
try:
    from routers.company_culture import router as company_culture_router
    print("âœ… íšŒì‚¬ ì¸ì¬ìƒ ë¼ìš°í„° import ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ íšŒì‚¬ ì¸ì¬ìƒ ëª¨ë“ˆ import ì˜¤ë¥˜: {e}")
    company_culture_router = None

# ëª¨ë“ˆí™”ëœ ë¼ìš°í„° ì¶”ê°€
try:
    from modules.resume.router import router as resume_router
    print("âœ… ì´ë ¥ì„œ ë¼ìš°í„° import ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ ì´ë ¥ì„œ ëª¨ë“ˆ import ì˜¤ë¥˜: {e}")
    resume_router = None

try:
    from modules.cover_letter.router import router as cover_letter_router
    print("âœ… ìê¸°ì†Œê°œì„œ ë¼ìš°í„° import ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ ìê¸°ì†Œê°œì„œ ëª¨ë“ˆ import ì˜¤ë¥˜: {e}")
    cover_letter_router = None

try:
    from modules.portfolio.router import router as portfolio_router
    print("âœ… í¬íŠ¸í´ë¦¬ì˜¤ ë¼ìš°í„° import ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ í¬íŠ¸í´ë¦¬ì˜¤ ëª¨ë“ˆ import ì˜¤ë¥˜: {e}")
    portfolio_router = None

try:
    from modules.hybrid.router import router as hybrid_router
    print("âœ… í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°í„° import ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“ˆ import ì˜¤ë¥˜: {e}")
    hybrid_router = None


from modules.core.services.embedding_service import EmbeddingService
from modules.core.services.mongo_service import MongoService
from modules.core.services.similarity_service import SimilarityService
from modules.core.services.vector_service import VectorService

# Python í™˜ê²½ ì¸ì½”ë”© ì„¤ì •
# ì‹œìŠ¤í…œ ê¸°ë³¸ ì¸ì½”ë”©ì„ UTF-8ë¡œ ì„¤ì •
if sys.platform.startswith('win'):
    # Windows í™˜ê²½ì—ì„œ UTF-8 ê°•ì œ ì„¤ì •
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    # ì½˜ì†” ì¶œë ¥ ì¸ì½”ë”© ì„¤ì •
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.detach())
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.detach())

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="AI ì±„ìš© ê´€ë¦¬ ì‹œìŠ¤í…œ API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# í•œê¸€ ì¸ì½”ë”©ì„ ìœ„í•œ ë¯¸ë“¤ì›¨ì–´
@app.middleware("http")
async def add_charset_header(request, call_next):
    response = await call_next(request)

    # ëª¨ë“  JSON ì‘ë‹µì— UTF-8 ì¸ì½”ë”© ëª…ì‹œ
    if response.headers.get("content-type", "").startswith("application/json"):
        response.headers["content-type"] = "application/json; charset=utf-8"

    # í…ìŠ¤íŠ¸ ì‘ë‹µì—ë„ UTF-8 ì¸ì½”ë”© ëª…ì‹œ
    elif response.headers.get("content-type", "").startswith("text/"):
        if "charset" not in response.headers.get("content-type", ""):
            current_content_type = response.headers.get("content-type", "")
            response.headers["content-type"] = f"{current_content_type}; charset=utf-8"

    return response

# ë¼ìš°í„° ë“±ë¡
<<<<<<< HEAD
=======
if github_router:
    app.include_router(github_router, prefix="/api", tags=["github"])
    print("âœ… GitHub ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ")
else:
    print("âŒ GitHub ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨")
>>>>>>> d2fe75e (250825 15:08 ì¸ì¬ìƒê´€ë¦¬ ì¶”ê°€)
app.include_router(upload_router, tags=["upload"])
app.include_router(pick_chatbot_router, prefix="/api/pick-chatbot", tags=["pick-chatbot"])
app.include_router(integrated_ocr_router, prefix="/api/integrated-ocr", tags=["integrated-ocr"])
app.include_router(pdf_ocr_router, prefix="/api/pdf-ocr", tags=["pdf_ocr"])
app.include_router(job_posting_router, tags=["job-postings"])
app.include_router(applicants_router, tags=["applicants"])
app.include_router(sample_data_router, tags=["sample-data"])
app.include_router(chatbot_router, prefix="/chatbot", tags=["chatbot"])

# íšŒì‚¬ ì¸ì¬ìƒ ë¼ìš°í„° ë“±ë¡
if company_culture_router:
    app.include_router(company_culture_router, tags=["company-culture"])
    print("âœ… íšŒì‚¬ ì¸ì¬ìƒ ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ")
else:
    print("âŒ íšŒì‚¬ ì¸ì¬ìƒ ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨")

# ëª¨ë“ˆí™”ëœ ë¼ìš°í„° ë“±ë¡
print("\nğŸ”§ ëª¨ë“ˆí™”ëœ ë¼ìš°í„° ë“±ë¡ ì‹œì‘...")

if resume_router:
    app.include_router(resume_router, prefix="/api/resume", tags=["resume"])
    print("âœ… ì´ë ¥ì„œ ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ")
else:
    print("âŒ ì´ë ¥ì„œ ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨")

if cover_letter_router:
    app.include_router(cover_letter_router, prefix="/api/cover-letter", tags=["cover-letter"])
    print("âœ… ìê¸°ì†Œê°œì„œ ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ")
else:
    print("âŒ ìê¸°ì†Œê°œì„œ ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨")

if portfolio_router:
    app.include_router(portfolio_router, prefix="/api/portfolio", tags=["portfolio"])
    print("âœ… í¬íŠ¸í´ë¦¬ì˜¤ ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ")
else:
    print("âŒ í¬íŠ¸í´ë¦¬ì˜¤ ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨")

if hybrid_router:
    app.include_router(hybrid_router, prefix="/api/hybrid", tags=["hybrid"])
    print("âœ… í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ")
else:
    print("âŒ í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨")

print("ğŸ”§ ëª¨ë“ˆí™”ëœ ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ\n")


# MongoDB ì—°ê²° ìµœì í™”
MONGODB_URI = os.getenv("MONGODB_URI", "mongodb://localhost:27017/hireme")
client = AsyncIOMotorClient(
    MONGODB_URI,
    maxPoolSize=50,  # ìµœëŒ€ ì—°ê²° í’€ í¬ê¸°
    minPoolSize=10,  # ìµœì†Œ ì—°ê²° í’€ í¬ê¸°
    maxIdleTimeMS=30000,  # ìœ íœ´ ì—°ê²° íƒ€ì„ì•„ì›ƒ
    serverSelectionTimeoutMS=5000,  # ì„œë²„ ì„ íƒ íƒ€ì„ì•„ì›ƒ
    socketTimeoutMS=20000,  # ì†Œì¼“ íƒ€ì„ì•„ì›ƒ
    connectTimeoutMS=10000,  # ì—°ê²° íƒ€ì„ì•„ì›ƒ
    retryWrites=True  # ì“°ê¸° ì¬ì‹œë„
)
db = client.hireme

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "resume-vectors")

# ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
try:
    embedding_service = EmbeddingService()
    print("âœ… Embedding ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    print(f"âš ï¸ Embedding ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    embedding_service = None

# VectorService ì„ íƒì  ì´ˆê¸°í™”
try:
    vector_service = VectorService(
        api_key=PINECONE_API_KEY or "dummy-key",
        index_name=PINECONE_INDEX_NAME
    )
    print("âœ… Pinecone ë²¡í„° ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    print(f"âš ï¸ Pinecone ë²¡í„° ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    vector_service = None

# SimilarityService ì´ˆê¸°í™” (vector_serviceê°€ Noneì¼ ìˆ˜ ìˆìŒ)
try:
    similarity_service = SimilarityService(embedding_service, vector_service)
    print("âœ… ìœ ì‚¬ë„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    print(f"âš ï¸ ìœ ì‚¬ë„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    similarity_service = None

# Pydantic ëª¨ë¸ë“¤
class User(BaseModel):
    id: Optional[str] = None
    username: str
    email: str
    role: str = "user"
    created_at: Optional[datetime] = None

class Resume(BaseModel):
    id: Optional[str] = None
    resume_id: Optional[str] = None
    name: str
    position: Optional[str] = ""
    department: Optional[str] = ""
    experience: Optional[str] = ""
    skills: Optional[str] = ""
    growthBackground: Optional[str] = ""
    motivation: Optional[str] = ""
    careerHistory: Optional[str] = ""
    analysisScore: int = 0
    analysisResult: str = ""
    status: str = "pending"
    created_at: Optional[datetime] = None

class ResumeChunk(BaseModel):
    id: Optional[str] = None
    resume_id: str
    chunk_id: str
    text: str
    start_pos: int
    end_pos: int
    chunk_index: int
    field_name: Optional[str] = None  # growthBackground, motivation, careerHistory
    metadata: Optional[Dict[str, Any]] = None
    vector_id: Optional[str] = None  # Pinecone ë²¡í„° ID
    created_at: Optional[datetime] = None

class Interview(BaseModel):
    id: Optional[str] = None
    user_id: str
    company: str
    position: str
    date: datetime
    status: str = "scheduled"
    created_at: Optional[datetime] = None

# ì´ˆê¸° ë°ì´í„° ë¡œë”© ìœ í‹¸ë¦¬í‹°: DBê°€ ë¹„ì–´ìˆìœ¼ë©´ ë£¨íŠ¸ CSVì—ì„œ ì„í¬íŠ¸
async def seed_applicants_from_csv_if_empty() -> None:
    try:
        total_documents = await db.applicants.count_documents({})
        if total_documents > 0:
            return

        project_root_csv_path = os.path.abspath(
            os.path.join(os.path.dirname(__file__), "..", "hireme.applicants.csv")
        )
        if not os.path.exists(project_root_csv_path):
            return

        documents_to_insert = []
        with open(project_root_csv_path, mode="r", encoding="utf-8") as csv_file:
            reader = csv.DictReader(csv_file)
            for row in reader:
                document: Dict[str, Any] = {}

                # _id ì²˜ë¦¬: ê°€ëŠ¥í•˜ë©´ ObjectIdë¡œ ì €ì¥
                raw_id = row.get("_id")
                if raw_id and isinstance(raw_id, str) and len(raw_id) == 24:
                    try:
                        document["_id"] = ObjectId(raw_id)
                    except Exception:
                        document["_id"] = raw_id

                # resume_id ì²˜ë¦¬
                raw_resume_id = row.get("resume_id")
                if raw_resume_id and isinstance(raw_resume_id, str) and len(raw_resume_id) == 24:
                    try:
                        document["resume_id"] = ObjectId(raw_resume_id)
                    except Exception:
                        document["resume_id"] = raw_resume_id
                elif raw_resume_id:
                    document["resume_id"] = raw_resume_id

                # ë¬¸ìì—´ í•„ë“œë“¤: í•­ìƒ ë¬¸ìì—´ë¡œ ìºìŠ¤íŒ…
                string_fields = [
                    "name",
                    "position",
                    "department",
                    "experience",
                    "skills",
                    "growthBackground",
                    "motivation",
                    "careerHistory",
                    "analysisResult",
                    "status",
                ]
                for field_name in string_fields:
                    value = row.get(field_name, "")
                    document[field_name] = "" if value is None else str(value)

                # ìˆ«ì í•„ë“œ
                try:
                    document["analysisScore"] = int(row.get("analysisScore", "0") or 0)
                except Exception:
                    document["analysisScore"] = 0

                # created_at ì²˜ë¦¬
                created_at_raw = row.get("created_at")
                if created_at_raw:
                    try:
                        iso_candidate = created_at_raw.replace("Z", "+00:00")
                        document["created_at"] = datetime.fromisoformat(iso_candidate)
                    except Exception:
                        document["created_at"] = datetime.now()

                documents_to_insert.append(document)

        if documents_to_insert:
            print(f"ğŸ” ì‹œë“œ ëŒ€ìƒ ë¬¸ì„œ ìˆ˜: {len(documents_to_insert)}")
            await db.applicants.insert_many(documents_to_insert)
            new_count = await db.applicants.count_documents({})
            print(f"ğŸ“¥ CSVì—ì„œ {len(documents_to_insert)}ê±´ ì„í¬íŠ¸ ì™„ë£Œ â†’ í˜„ì¬ ì´ ë¬¸ì„œ ìˆ˜: {new_count}")
    except Exception as seed_error:
                    print(f"[ERROR] CSV ì„í¬íŠ¸ ì‹¤íŒ¨: {seed_error}")


def load_applicants_from_csv() -> List[Dict[str, Any]]:
    """DB ë¯¸ê°€ë™/ë¹„ì–´ìˆì„ ë•Œ CSVë¥¼ ì§ì ‘ ì½ì–´ ë°˜í™˜"""
    try:
        project_root_csv_path = os.path.abspath(
            os.path.join(os.path.dirname(__file__), "..", "hireme.applicants.csv")
        )
        if not os.path.exists(project_root_csv_path):
            return []

        applicants: List[Dict[str, Any]] = []
        with open(project_root_csv_path, mode="r", encoding="utf-8") as csv_file:
            reader = csv.DictReader(csv_file)
            for row in reader:
                item: Dict[str, Any] = {}
                # id/_id
                raw_id = row.get("_id") or row.get("id")
                if raw_id:
                    item["id"] = str(raw_id)

                # ê¸°ë³¸ ë¬¸ìì—´ í•„ë“œ
                for field_name in [
                    "name",
                    "position",
                    "department",
                    "experience",
                    "skills",
                    "growthBackground",
                    "motivation",
                    "careerHistory",
                    "analysisResult",
                    "status",
                ]:
                    value = row.get(field_name, "")
                    item[field_name] = "" if value is None else str(value)

                # score
                try:
                    item["analysisScore"] = int(row.get("analysisScore", "0") or 0)
                except Exception:
                    item["analysisScore"] = 0

                # created_at
                created_at_raw = row.get("created_at")
                if created_at_raw:
                    try:
                        iso_candidate = created_at_raw.replace("Z", "+00:00")
                        item["created_at"] = datetime.fromisoformat(iso_candidate)
                    except Exception:
                        item["created_at"] = datetime.now()

                applicants.append(item)
        return applicants
    except Exception:
        return []

# API ë¼ìš°íŠ¸ë“¤
@app.get("/")
async def root():
    return {"message": "AI ì±„ìš© ê´€ë¦¬ ì‹œìŠ¤í…œ APIê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤."}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "message": "ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤."}

# ì‚¬ìš©ì ê´€ë ¨ API
@app.get("/api/users", response_model=List[User])
async def get_users():
    users = await db.users.find().to_list(1000)
    # MongoDBì˜ _idë¥¼ idë¡œ ë³€í™˜
    for user in users:
        user["id"] = str(user["_id"])
        del user["_id"]
    return [User(**user) for user in users]

@app.post("/api/users", response_model=User)
async def create_user(user: User):
    user_dict = user.dict()
    user_dict["created_at"] = datetime.now()
    result = await db.users.insert_one(user_dict)
    user_dict["id"] = str(result.inserted_id)
    return User(**user_dict)

# ì´ë ¥ì„œ ê´€ë ¨ API
@app.get("/api/resumes", response_model=List[Resume])
async def get_resumes():
    resumes = await db.resumes.find().to_list(1000)
    # MongoDBì˜ _idë¥¼ idë¡œ ë³€í™˜
    for resume in resumes:
        resume["id"] = str(resume["_id"])
        del resume["_id"]
    return [Resume(**resume) for resume in resumes]

@app.post("/api/resumes", response_model=Resume)
async def create_resume(resume: Resume):
    resume_dict = resume.dict()
    resume_dict["created_at"] = datetime.now()
    result = await db.resumes.insert_one(resume_dict)
    resume_dict["id"] = str(result.inserted_id)
    return Resume(**resume_dict)

# ë©´ì ‘ ê´€ë ¨ API
@app.get("/api/interviews", response_model=List[Interview])
async def get_interviews():
    interviews = await db.interviews.find().to_list(1000)
    # MongoDBì˜ _idë¥¼ idë¡œ ë³€í™˜
    for interview in interviews:
        interview["id"] = str(interview["_id"])
        del interview["_id"]
    return [Interview(**interview) for interview in interviews]

@app.post("/api/interviews", response_model=Interview)
async def create_interview(interview: Interview):
    interview_dict = interview.dict()
    interview_dict["created_at"] = datetime.now()
    result = await db.interviews.insert_one(interview_dict)
    interview_dict["id"] = str(result.inserted_id)
    return Interview(**interview_dict)

# ì§€ì›ì ê´€ë ¨ API - ì¤‘ë³µ ë¼ìš°í„° ì‚­ì œ (routers/applicants.pyì—ì„œ ì²˜ë¦¬)

# ê°œë³„ ì§€ì›ì ì¡°íšŒ API - ì¤‘ë³µ ë¼ìš°í„° ì‚­ì œ (routers/applicants.pyì—ì„œ ì²˜ë¦¬)
# ì§€ì›ì í†µê³„ API - ì¤‘ë³µ ë¼ìš°í„° ì‚­ì œ (routers/applicants.pyì—ì„œ ì²˜ë¦¬)

# Vector Service API
@app.post("/api/vector/create")
async def create_vector(data: Dict[str, Any]):
    """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥"""
    try:
        text = data.get("text", "")
        document_id = data.get("document_id")
        metadata = data.get("metadata", {})

        # ì—¬ê¸°ì„œ ì‹¤ì œ ë²¡í„°í™” ë¡œì§ êµ¬í˜„
        # ì˜ˆ: embedding_modelì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜

        # ì„ì‹œë¡œ ì„±ê³µ ì‘ë‹µ ë°˜í™˜
        return {
            "message": "Vector created successfully",
            "document_id": document_id,
            "vector_dimension": 384,  # ì˜ˆì‹œ ì°¨ì›
            "status": "success"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë²¡í„° ìƒì„± ì‹¤íŒ¨: {str(e)}")

@app.post("/api/vector/search")
async def search_vectors(data: Dict[str, Any]):
    """ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰"""
    try:
        query_text = data.get("query", "")
        top_k = data.get("top_k", 5)
        threshold = data.get("threshold", 0.7)

        # ì—¬ê¸°ì„œ ì‹¤ì œ ë²¡í„° ê²€ìƒ‰ ë¡œì§ êµ¬í˜„

        # ì„ì‹œë¡œ ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜
        return {
            "results": [
                {
                    "document_id": "doc_001",
                    "score": 0.95,
                    "text": "ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ ìƒ˜í”Œ 1",
                    "metadata": {"type": "resume", "applicant_id": "app_001"}
                },
                {
                    "document_id": "doc_002",
                    "score": 0.87,
                    "text": "ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ ìƒ˜í”Œ 2",
                    "metadata": {"type": "cover_letter", "applicant_id": "app_002"}
                }
            ],
            "total_found": 2
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")

# Chunking Service API
@app.post("/api/chunking/split")
async def split_text(data: Dict[str, Any]):
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ê³  DBì— ì €ì¥"""
    try:
        text = data.get("text", "")
        resume_id = data.get("resume_id")
        field_name = data.get("field_name", "")  # growthBackground, motivation, careerHistory
        chunk_size = data.get("chunk_size", 1000)
        chunk_overlap = data.get("chunk_overlap", 200)
        split_type = data.get("split_type", "recursive")

        if not resume_id:
            raise HTTPException(status_code=400, detail="resume_idê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        # í…ìŠ¤íŠ¸ ë¶„í•  ë¡œì§
        chunks = []
        text_length = len(text)
        start = 0
        chunk_index = 0

        while start < text_length:
            end = min(start + chunk_size, text_length)
            chunk_text = text[start:end]

            if chunk_text.strip():  # ë¹ˆ ì²­í¬ëŠ” ì œì™¸
                chunk_id = f"chunk_{chunk_index:03d}"
                vector_id = f"resume_{resume_id}_{chunk_id}"

                chunk_doc = {
                    "resume_id": resume_id,
                    "chunk_id": chunk_id,
                    "text": chunk_text,
                    "start_pos": start,
                    "end_pos": end,
                    "chunk_index": chunk_index,
                    "field_name": field_name,
                    "vector_id": vector_id,
                    "metadata": {
                        "length": len(chunk_text),
                        "split_type": split_type,
                        "chunk_size": chunk_size,
                        "chunk_overlap": chunk_overlap
                    },
                    "created_at": datetime.now()
                }

                # MongoDBì— ì²­í¬ ì €ì¥
                result = await db.resume_chunks.insert_one(chunk_doc)
                chunk_doc["id"] = str(result.inserted_id)

                chunks.append(chunk_doc)
                chunk_index += 1

            start = end - chunk_overlap if chunk_overlap > 0 else end

            if start >= text_length:
                break

        return {
            "chunks": chunks,
            "total_chunks": len(chunks),
            "original_length": text_length,
            "resume_id": resume_id,
            "field_name": field_name,
            "split_config": {
                "chunk_size": chunk_size,
                "chunk_overlap": chunk_overlap,
                "split_type": split_type
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í…ìŠ¤íŠ¸ ë¶„í•  ì‹¤íŒ¨: {str(e)}")

@app.get("/api/chunking/resume/{resume_id}")
async def get_resume_chunks(resume_id: str):
    """íŠ¹ì • ì´ë ¥ì„œì˜ ëª¨ë“  ì²­í¬ ì¡°íšŒ"""
    try:
        chunks = await db.resume_chunks.find({"resume_id": resume_id}).to_list(1000)

        # MongoDBì˜ _idë¥¼ idë¡œ ë³€í™˜
        for chunk in chunks:
            chunk["id"] = str(chunk["_id"])
            del chunk["_id"]

        return {
            "resume_id": resume_id,
            "chunks": [ResumeChunk(**chunk) for chunk in chunks],
            "total_chunks": len(chunks)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì²­í¬ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/chunking/process-resume")
async def process_resume_with_chunking(data: Dict[str, Any]):
    """ì´ë ¥ì„œ ì „ì²´ë¥¼ í•„ë“œë³„ë¡œ ì²­í‚¹ ì²˜ë¦¬"""
    try:
        resume_id = data.get("resume_id")
        if not resume_id:
            raise HTTPException(status_code=400, detail="resume_idê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        # ì´ë ¥ì„œ ì •ë³´ ì¡°íšŒ
        resume = await db.resumes.find_one({"_id": ObjectId(resume_id)})
        if not resume:
            raise HTTPException(status_code=404, detail="ì´ë ¥ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        chunk_size = data.get("chunk_size", 800)
        chunk_overlap = data.get("chunk_overlap", 150)

        # ì²­í‚¹í•  í•„ë“œë“¤
        fields_to_chunk = ["growthBackground", "motivation", "careerHistory"]
        all_chunks = []

        for field_name in fields_to_chunk:
            field_text = resume.get(field_name, "")
            if field_text and field_text.strip():
                # í•„ë“œë³„ ì²­í‚¹ ì²˜ë¦¬
                field_chunks = []
                text_length = len(field_text)
                start = 0
                chunk_index = 0

                while start < text_length:
                    end = min(start + chunk_size, text_length)
                    chunk_text = field_text[start:end]

                    if chunk_text.strip():
                        chunk_id = f"{field_name}_chunk_{chunk_index:03d}"
                        vector_id = f"resume_{resume_id}_{chunk_id}"

                        chunk_doc = {
                            "resume_id": resume_id,
                            "chunk_id": chunk_id,
                            "text": chunk_text,
                            "start_pos": start,
                            "end_pos": end,
                            "chunk_index": chunk_index,
                            "field_name": field_name,
                            "vector_id": vector_id,
                            "metadata": {
                                "applicant_name": resume.get("name", ""),
                                "position": resume.get("position", ""),
                                "department": resume.get("department", ""),
                                "length": len(chunk_text)
                            },
                            "created_at": datetime.now()
                        }

                        result = await db.resume_chunks.insert_one(chunk_doc)
                        chunk_doc["id"] = str(result.inserted_id)
                        field_chunks.append(chunk_doc)
                        chunk_index += 1

                    start = end - chunk_overlap if chunk_overlap > 0 else end
                    if start >= text_length:
                        break

                all_chunks.extend(field_chunks)

        return {
            "resume_id": resume_id,
            "applicant_name": resume.get("name", ""),
            "processed_fields": fields_to_chunk,
            "total_chunks": len(all_chunks),
            "chunks_by_field": {
                field: len([c for c in all_chunks if c["field_name"] == field])
                for field in fields_to_chunk
            },
            "chunks": all_chunks
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì´ë ¥ì„œ ì²­í‚¹ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/chunking/merge")
async def merge_chunks(data: Dict[str, Any]):
    """ì²­í¬ë“¤ì„ ë³‘í•©"""
    try:
        chunks = data.get("chunks", [])
        separator = data.get("separator", "\n\n")

        # ì²­í¬ ë³‘í•©
        merged_text = separator.join([chunk.get("text", "") for chunk in chunks])

        return {
            "merged_text": merged_text,
            "total_length": len(merged_text),
            "chunks_merged": len(chunks),
            "separator_used": separator
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì²­í¬ ë³‘í•© ì‹¤íŒ¨: {str(e)}")

# Similarity Service API
@app.post("/api/similarity/compare")
async def compare_similarity(data: Dict[str, Any]):
    """ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°"""
    try:
        text1 = data.get("text1", "")
        text2 = data.get("text2", "")
        method = data.get("method", "cosine")  # cosine, jaccard, levenshtein

        # ì—¬ê¸°ì„œ ì‹¤ì œ ìœ ì‚¬ë„ ê³„ì‚° ë¡œì§ êµ¬í˜„
        # ì˜ˆ: sentence-transformersì˜ cosine similarity

        # ì„ì‹œë¡œ ìœ ì‚¬ë„ ì ìˆ˜ ë°˜í™˜
        import random
        similarity_score = random.uniform(0.3, 0.95)  # ì„ì‹œ ì ìˆ˜

        return {
            "similarity_score": round(similarity_score, 4),
            "method": method,
            "text1_length": len(text1),
            "text2_length": len(text2),
            "comparison_result": {
                "highly_similar": similarity_score > 0.8,
                "moderately_similar": 0.5 < similarity_score <= 0.8,
                "low_similar": similarity_score <= 0.5
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")

@app.post("/api/similarity/batch")
async def batch_similarity(data: Dict[str, Any]):
    """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë“¤ ê°„ì˜ ì¼ê´„ ìœ ì‚¬ë„ ê³„ì‚°"""
    try:
        texts = data.get("texts", [])
        reference_text = data.get("reference_text", "")
        method = data.get("method", "cosine")
        threshold = data.get("threshold", 0.7)

        # ë°°ì¹˜ ìœ ì‚¬ë„ ê³„ì‚°
        results = []
        import random

        for i, text in enumerate(texts):
            similarity_score = random.uniform(0.2, 0.95)  # ì„ì‹œ ì ìˆ˜
            results.append({
                "index": i,
                "text_preview": text[:100] + "..." if len(text) > 100 else text,
                "similarity_score": round(similarity_score, 4),
                "above_threshold": similarity_score >= threshold
            })

        # ì„ê³„ê°’ ì´ìƒì¸ ê²°ê³¼ë“¤ í•„í„°ë§
        filtered_results = [r for r in results if r["above_threshold"]]

        return {
            "results": results,
            "filtered_results": filtered_results,
            "total_compared": len(texts),
            "above_threshold_count": len(filtered_results),
            "method": method,
            "threshold": threshold,
            "reference_text_length": len(reference_text)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë°°ì¹˜ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")

@app.get("/api/similarity/metrics")
async def get_similarity_metrics():
    """ìœ ì‚¬ë„ ì„œë¹„ìŠ¤ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    try:
        # ì„ì‹œ ë©”íŠ¸ë¦­ ë°ì´í„°
        return {
            "total_comparisons": 1250,
            "average_similarity": 0.67,
            "supported_methods": ["cosine", "jaccard", "levenshtein", "semantic"],
            "performance_stats": {
                "average_processing_time_ms": 45,
                "comparisons_per_second": 220,
                "cache_hit_rate": 0.78
            },
            "usage_by_method": {
                "cosine": 850,
                "semantic": 300,
                "jaccard": 70,
                "levenshtein": 30
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

# ë‹¤ì¤‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ API ğŸ†•
@app.post("/api/resume/search/multi-hybrid")
async def search_resumes_multi_hybrid(data: Dict[str, Any]):
    """ë‹¤ì¤‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: ë²¡í„° + í…ìŠ¤íŠ¸ + í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ê²°í•©"""
    try:
        query = data.get("query", "")
        search_type = data.get("type", "resume")
        limit = data.get("limit", 10)

        print(f"[API] ë‹¤ì¤‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìš”ì²­ - ì¿¼ë¦¬: '{query}', ì œí•œ: {limit}")

        if not query or not query.strip():
            raise HTTPException(status_code=400, detail="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        # SimilarityServiceì˜ ë‹¤ì¤‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
        result = await similarity_service.search_resumes_multi_hybrid(
            query=query,
            collection=db.applicants,
            search_type=search_type,
            limit=limit
        )

        if not result["success"]:
            raise HTTPException(status_code=500, detail="ë‹¤ì¤‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        return {
            "success": True,
            "message": f"ë‹¤ì¤‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ: '{query}'",
            "data": result["data"]
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"[API] ë‹¤ì¤‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë‹¤ì¤‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")

# í‚¤ì›Œë“œ ê²€ìƒ‰ API
@app.post("/api/resume/search/keyword")
async def search_resumes_keyword(data: Dict[str, Any]):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ì´ë ¥ì„œ ê²€ìƒ‰ (BM25)"""
    try:
        query = data.get("query", "")
        limit = data.get("limit", 10)

        print(f"[API] í‚¤ì›Œë“œ ê²€ìƒ‰ ìš”ì²­ - ì¿¼ë¦¬: '{query}', ì œí•œ: {limit}")

        if not query or not query.strip():
            raise HTTPException(status_code=400, detail="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        # KeywordSearchServiceë¥¼ í†µí•œ BM25 ê²€ìƒ‰
        result = await similarity_service.keyword_search_service.search_by_keywords(
            query=query,
            collection=db.applicants,
            limit=limit
        )

        if not result["success"]:
            raise HTTPException(status_code=500, detail=result.get("message", "í‚¤ì›Œë“œ ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."))

        return {
            "success": True,
            "message": result["message"],
            "data": {
                "query": result["query"],
                "results": result["results"],
                "total": result["total"],
                "search_method": "keyword_bm25",
                "query_tokens": result.get("query_tokens", [])
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"[API] í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")

# í‚¤ì›Œë“œ ê²€ìƒ‰ ì¸ë±ìŠ¤ ê´€ë¦¬ API
@app.post("/api/resume/search/keyword/rebuild-index")
async def rebuild_keyword_index():
    """í‚¤ì›Œë“œ ê²€ìƒ‰ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
    try:
        print(f"[API] í‚¤ì›Œë“œ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ìš”ì²­")

        # KeywordSearchServiceë¥¼ í†µí•œ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
        result = await similarity_service.keyword_search_service.build_index(db.applicants)

        if not result["success"]:
            raise HTTPException(status_code=500, detail=result.get("message", "ì¸ë±ìŠ¤ ì¬êµ¬ì¶•ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."))

        return {
            "success": True,
            "message": result["message"],
            "data": {
                "total_documents": result["total_documents"],
                "index_created_at": result["index_created_at"]
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"[API] í‚¤ì›Œë“œ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í‚¤ì›Œë“œ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì‹¤íŒ¨: {str(e)}")

@app.get("/api/resume/search/keyword/stats")
async def get_keyword_search_stats():
    """í‚¤ì›Œë“œ ê²€ìƒ‰ ì¸ë±ìŠ¤ í†µê³„ ì¡°íšŒ"""
    try:
        stats = await similarity_service.keyword_search_service.get_index_stats()

        return {
            "success": True,
            "data": stats
        }

    except Exception as e:
        print(f"[API] í‚¤ì›Œë“œ ê²€ìƒ‰ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í‚¤ì›Œë“œ ê²€ìƒ‰ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

# ì´ë ¥ì„œ ìœ ì‚¬ë„ ì²´í¬ API
@app.post("/api/resume/similarity-check/{resume_id}")
async def check_resume_similarity(resume_id: str):
    """íŠ¹ì • ì´ë ¥ì„œì˜ ìœ ì‚¬ë„ ì²´í¬ (ë‹¤ë¥¸ ëª¨ë“  ì´ë ¥ì„œì™€ ë¹„êµ)"""
    try:
        print(f"[INFO] ìœ ì‚¬ë„ ì²´í¬ ìš”ì²­ - resume_id: {resume_id}")

        # SimilarityServiceë¥¼ í†µí•œ ì²­í‚¹ ê¸°ë°˜ ìœ ì‚¬ë„ ë¶„ì„
        result = await similarity_service.find_similar_documents_by_chunks(resume_id, db.applicants, "resume", 50)

        # í˜„ì¬ ì´ë ¥ì„œ ì •ë³´ ì¡°íšŒ
        current_resume = await db.applicants.find_one({"_id": ObjectId(resume_id)})
        print(f"[INFO] ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ê²°ê³¼: {current_resume is not None}")

        # ì²­í‚¹ ê¸°ë°˜ API ì‘ë‹µ í˜•ì‹ì— ë§ê²Œ ë³€í™˜
        similarity_results = []
        for similar in result["data"]["similar_resumes"]:
            # ì²­í‚¹ ìƒì„¸ ì •ë³´ì—ì„œ í•„ë“œë³„ ìœ ì‚¬ë„ ì¶”ì¶œ
            chunk_details = similar.get("chunk_details", {})
            field_similarities = {
                "growthBackground": 0.0,
                "motivation": 0.0,
                "careerHistory": 0.0
            }

            # ì²­í¬ ë§¤ì¹­ì—ì„œ í•„ë“œë³„ ìµœê³  ì ìˆ˜ ì¶”ì¶œ
            for chunk_key, chunk_info in chunk_details.items():
                if "growth_background" in chunk_key:
                    field_similarities["growthBackground"] = max(field_similarities["growthBackground"], chunk_info["score"])
                elif "motivation" in chunk_key:
                    field_similarities["motivation"] = max(field_similarities["motivation"], chunk_info["score"])
                elif "career_history" in chunk_key:
                    field_similarities["careerHistory"] = max(field_similarities["careerHistory"], chunk_info["score"])

            similarity_result = {
                "resume_id": str(similar["resume"]["_id"]),
                "applicant_name": similar["resume"].get("name", "ì•Œ ìˆ˜ ì—†ìŒ"),
                "position": similar["resume"].get("position", ""),
                "department": similar["resume"].get("department", ""),
                "overall_similarity": round(similar["similarity_score"], 4),
                "field_similarities": {
                    "growthBackground": round(field_similarities["growthBackground"], 4),
                    "motivation": round(field_similarities["motivation"], 4),
                    "careerHistory": round(field_similarities["careerHistory"], 4)
                },
                "chunk_matches": similar.get("chunk_matches", 0),
                "chunk_details": chunk_details,
                "is_high_similarity": similar["similarity_score"] > 0.7,
                "is_moderate_similarity": 0.4 <= similar["similarity_score"] <= 0.7,
                "is_low_similarity": similar["similarity_score"] < 0.4,
                "llm_analysis": similar.get("llm_analysis")
            }
            similarity_results.append(similarity_result)

        # ë‹¤ë¥¸ ëª¨ë“  ì´ë ¥ì„œ ì¡°íšŒ (í˜„ì¬ ì´ë ¥ì„œ ì œì™¸)
        other_resumes = await db.applicants.find({"_id": {"$ne": ObjectId(resume_id)}}).to_list(1000)

        # í˜„ì¬ ì´ë ¥ì„œì˜ ë¹„êµ í…ìŠ¤íŠ¸ (ìœ ì‚¬ë„ ê³„ì‚° í•„ë“œ)
        current_fields = {
            "growthBackground": current_resume.get("growthBackground", ""),
            "motivation": current_resume.get("motivation", ""),
            "careerHistory": current_resume.get("careerHistory", "")
        }

        # ì „ì²´ í…ìŠ¤íŠ¸ ì¡°í•©
        current_text = " ".join([text for text in current_fields.values() if text])

        similarity_results = []

        for other_resume in other_resumes:
            other_id = str(other_resume["_id"])

            # ë‹¤ë¥¸ ì´ë ¥ì„œì˜ ë¹„êµ í…ìŠ¤íŠ¸
            other_fields = {
                "growthBackground": other_resume.get("growthBackground", ""),
                "motivation": other_resume.get("motivation", ""),
                "careerHistory": other_resume.get("careerHistory", "")
            }
            other_text = " ".join([text for text in other_fields.values() if text])

            # ì‹¤ì œ ìœ ì‚¬ë„ ê³„ì‚° ì‚¬ìš©
            try:
                print(f"ğŸ’« ì´ë ¥ì„œ ê°„ ìœ ì‚¬ë„ ê³„ì‚° ì‹œì‘: {resume_id} vs {other_id}")

                # SimilarityServiceì˜ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° ë©”ì„œë“œ ì§ì ‘ í˜¸ì¶œ
                text_similarity = similarity_service._calculate_text_similarity(current_resume, other_resume)
                overall_similarity = text_similarity if text_similarity is not None else 0.0

                print(f"ğŸ“Š í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²°ê³¼: {overall_similarity:.3f}")

                # í•„ë“œë³„ ìœ ì‚¬ë„ ê³„ì‚°
                field_similarities = {}
                for field_name in current_fields.keys():
                    if current_fields[field_name] and other_fields[field_name]:
                        # í•„ë“œë³„ ê°œë³„ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°
                        field_sim = similarity_service._calculate_text_similarity(
                            {field_name: current_fields[field_name]},
                            {field_name: other_fields[field_name]}
                        )
                        field_similarities[field_name] = field_sim if field_sim is not None else 0.0
                        print(f"ğŸ“‹ {field_name} ìœ ì‚¬ë„: {field_similarities[field_name]:.3f}")
                    else:
                        field_similarities[field_name] = 0.0

            except Exception as e:
                print(f"[ERROR] ìœ ì‚¬ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc()

                # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
                import random
                overall_similarity = random.uniform(0.1, 0.9)
                field_similarities = {}
                for field_name in current_fields.keys():
                    if current_fields[field_name] and other_fields[field_name]:
                        field_similarities[field_name] = random.uniform(0.0, 1.0)
                    else:
                        field_similarities[field_name] = 0.0

            # LLM ë¶„ì„ ì¶”ê°€ (ìœ ì‚¬ë„ê°€ ì¼ì • ìˆ˜ì¤€ ì´ìƒì¼ ë•Œë§Œ)
            llm_analysis = None

            if overall_similarity >= 0.3:  # 30% ì´ìƒ ìœ ì‚¬í•  ë•Œë§Œ LLM ë¶„ì„
                try:
                    print(f"[API] LLM ë¶„ì„ ì‹œì‘ - ìœ ì‚¬ë„: {overall_similarity:.3f}")
                    llm_analysis = await similarity_service.llm_service.analyze_plagiarism_suspicion(
                        similarity_score=overall_similarity,
                        similar_documents=[{
                            "similarity_score": overall_similarity,
                            "name": other_resume.get("name", "Unknown"),
                            "basic_info_names": other_resume.get("name", "Unknown")
                        }],
                        document_type="resume"
                    )
                    print(f"[API] LLM ë¶„ì„ ì™„ë£Œ")
                except Exception as llm_error:
                    print(f"[API] LLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {llm_error}")
                    llm_analysis = {
                        "success": False,
                        "error": str(llm_error),
                        "analysis": "LLM ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                    }

            similarity_result = {
                "resume_id": other_id,
                "applicant_name": other_resume.get("name", "ì•Œ ìˆ˜ ì—†ìŒ"),
                "position": other_resume.get("position", ""),
                "department": other_resume.get("department", ""),
                "overall_similarity": round(overall_similarity, 4),
                "field_similarities": {
                    "growthBackground": round(field_similarities["growthBackground"], 4),
                    "motivation": round(field_similarities["motivation"], 4),
                    "careerHistory": round(field_similarities["careerHistory"], 4)
                },
                "is_high_similarity": overall_similarity > 0.7,
                "is_moderate_similarity": 0.4 <= overall_similarity <= 0.7,
                "is_low_similarity": overall_similarity < 0.4,
                "llm_analysis": llm_analysis
            }

            similarity_results.append(similarity_result)

        # ìœ ì‚¬ë„ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        similarity_results.sort(key=lambda x: x["overall_similarity"], reverse=True)

        # ì „ì²´ í‘œì ˆ ìœ„í—˜ë„ ë¶„ì„ ì¶”ê°€
        plagiarism_analysis = None
        high_similarity_results = [r for r in similarity_results if r["overall_similarity"] >= 0.3]

        if high_similarity_results:
            try:
                print(f"[API] í‘œì ˆ ìœ„í—˜ë„ ë¶„ì„ ì‹œì‘")
                plagiarism_analysis = await similarity_service.llm_service.analyze_plagiarism_risk(
                    original_resume=current_resume,
                    similar_resumes=high_similarity_results
                )
                print(f"[API] í‘œì ˆ ìœ„í—˜ë„ ë¶„ì„ ì™„ë£Œ")
            except Exception as plag_error:
                print(f"[API] í‘œì ˆ ìœ„í—˜ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {plag_error}")
                plagiarism_analysis = {
                    "success": False,
                    "error": str(plag_error),
                    "risk_level": "UNKNOWN",
                    "analysis": "í‘œì ˆ ìœ„í—˜ë„ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                }

        # í†µê³„ ì •ë³´
        high_similarity_count = len([r for r in similarity_results if r["is_high_similarity"]])
        moderate_similarity_count = len([r for r in similarity_results if r["is_moderate_similarity"]])
        low_similarity_count = len([r for r in similarity_results if r["is_low_similarity"]])

        return {
            "current_resume": {
                "id": resume_id,
                "name": current_resume.get("name", ""),
                "position": current_resume.get("position", ""),
                "department": current_resume.get("department", "")
            },
            "similarity_results": similarity_results,
            "statistics": {
                "total_compared": len(similarity_results),
                "high_similarity_count": high_similarity_count,
                "moderate_similarity_count": moderate_similarity_count,
                "low_similarity_count": low_similarity_count,
                "average_similarity": round(sum([r["overall_similarity"] for r in similarity_results]) / len(similarity_results) if similarity_results else 0, 4)
            },
            "top_similar": similarity_results[:5] if similarity_results else [],
            "plagiarism_analysis": plagiarism_analysis,
            "analysis_timestamp": datetime.now().isoformat()
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìœ ì‚¬ë„ ì²´í¬ ì‹¤íŒ¨: {str(e)}")

# ì»¤ë²„ë ˆí„° ìœ ì‚¬ë„ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/coverletter/similarity-check/{applicant_id}")
async def check_coverletter_similarity(
    applicant_id: str,
    mongo_service: MongoService = Depends(get_mongo_service)
):
    """ìê¸°ì†Œê°œì„œ í‘œì ˆì²´í¬ (í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ëª… ì—”ë“œí¬ì¸íŠ¸)"""
    try:
        print(f"[INFO] ìì†Œì„œ í‘œì ˆì²´í¬ ìš”ì²­ - applicant_id: {applicant_id}")

        # 1. ì§€ì›ì ì¡´ì¬ í™•ì¸
        applicant = await mongo_service.get_applicant_by_id(applicant_id)
        if not applicant:
            raise HTTPException(status_code=404, detail="ì§€ì›ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # 2. ìì†Œì„œ ì¡´ì¬ í™•ì¸
        cover_letter_id = applicant.get("cover_letter_id")
        if not cover_letter_id:
            raise HTTPException(status_code=404, detail="ìì†Œì„œê°€ ì—†ìŠµë‹ˆë‹¤")

        # 3. ìì†Œì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        try:
            from bson import ObjectId
            from motor.motor_asyncio import AsyncIOMotorClient

            mongo_uri = os.getenv("MONGODB_URI", "mongodb://localhost:27017/hireme")
            client = AsyncIOMotorClient(mongo_uri)
            db = client.hireme

            # ObjectId ë³€í™˜ ì‹œë„
            try:
                object_id = ObjectId(cover_letter_id)
            except Exception as e:
                print(f"[ERROR] ì˜ëª»ëœ ObjectId í˜•ì‹: {cover_letter_id}")
                client.close()
                raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ìì†Œì„œ ID í˜•ì‹ì…ë‹ˆë‹¤")

            cover_letter = await db.cover_letters.find_one({"_id": object_id})
            client.close()

            if not cover_letter:
                raise HTTPException(status_code=404, detail="ìì†Œì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            # ìì†Œì„œ ë‚´ìš© ì¶”ì¶œ (content ë˜ëŠ” extracted_text í•„ë“œì—ì„œ)
            cover_letter_text = cover_letter.get("content", "") or cover_letter.get("extracted_text", "")
            if not cover_letter_text:
                print(f"[WARNING] ìì†Œì„œ ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ - applicant_id: {applicant_id}")
                return {
                    "status": "success",
                    "applicant_id": applicant_id,
                    "plagiarism_result": {
                        "status": "no_content",
                        "message": "ìì†Œì„œ ë‚´ìš©ì´ ì—†ì–´ í‘œì ˆ ê²€ì‚¬ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                        "similar_count": 0,
                        "suspicion_level": "UNKNOWN"
                    },
                    "message": "ìì†Œì„œ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"
                }
            
            print(f"[INFO] ìì†Œì„œ ë‚´ìš© ë°œê²¬ - ê¸¸ì´: {len(cover_letter_text)}ì")

        except HTTPException:
            raise
        except Exception as e:
            print(f"[ERROR] ìì†Œì„œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise HTTPException(status_code=500, detail="ìì†Œì„œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

        # 4. ìœ ì‚¬ë„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        similarity_service = get_similarity_service()

        # 5. ìì†Œì„œ í‘œì ˆì²´í¬ ìˆ˜í–‰ (ì²­í‚¹ ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‚¬ìš©)
        # cover_letter_idë¥¼ ì‚¬ìš©í•˜ì—¬ cover_letters ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰
        result = await similarity_service.find_similar_documents_by_chunks(
            document_id=cover_letter_id,
            collection=db.cover_letters,
            document_type="cover_letter",
            limit=10
        )

        return {
            "status": "success",
            "applicant_id": applicant_id,
            "plagiarism_result": result,
            "message": "ìì†Œì„œ í‘œì ˆì²´í¬ ì™„ë£Œ"
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] ìì†Œì„œ í‘œì ˆì²´í¬ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"ìì†Œì„œ í‘œì ˆì²´í¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

# ë©”ì¼ í…œí”Œë¦¿ ë° ì„¤ì • ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/mail-templates")
async def get_mail_templates():
    """ë©”ì¼ í…œí”Œë¦¿ ì¡°íšŒ"""
    try:
        templates = await db.mail_templates.find_one({"_id": "default"})
        if not templates:
            # ê¸°ë³¸ í…œí”Œë¦¿ ìƒì„±
            default_templates = {
                "_id": "default",
                "passed": {
                    "subject": "ì¶•í•˜í•©ë‹ˆë‹¤! ì„œë¥˜ ì „í˜• í•©ê²© ì•ˆë‚´",
                    "content": """ì•ˆë…•í•˜ì„¸ìš”, {applicant_name}ë‹˜

ì¶•í•˜ë“œë¦½ë‹ˆë‹¤! {job_posting_title} í¬ì§€ì…˜ì— ëŒ€í•œ ì„œë¥˜ ì „í˜•ì— í•©ê²©í•˜ì…¨ìŠµë‹ˆë‹¤.

ë‹¤ìŒ ë‹¨ê³„ì¸ ë©´ì ‘ ì¼ì •ì€ ì¶”í›„ ë³„ë„ë¡œ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

ê°ì‚¬í•©ë‹ˆë‹¤.
{company_name} ì±„ìš©íŒ€"""
                },
                "rejected": {
                    "subject": "ì„œë¥˜ ì „í˜• ê²°ê³¼ ì•ˆë‚´",
                    "content": """ì•ˆë…•í•˜ì„¸ìš”, {applicant_name}ë‹˜

{job_posting_title} í¬ì§€ì…˜ì— ëŒ€í•œ ì„œë¥˜ ì „í˜• ê²°ê³¼ë¥¼ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤.

ì•ˆíƒ€ê¹ê²Œë„ ì´ë²ˆ ì „í˜•ì—ì„œëŠ” í•©ê²©í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.
ì•ìœ¼ë¡œ ë” ì¢‹ì€ ê¸°íšŒê°€ ìˆì„ ë•Œ ë‹¤ì‹œ ì§€ì›í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.

ê°ì‚¬í•©ë‹ˆë‹¤.
{company_name} ì±„ìš©íŒ€"""
                },
                "created_at": datetime.now(),
                "updated_at": datetime.now()
            }
            await db.mail_templates.insert_one(default_templates)
            templates = default_templates

        # _id ì œê±°í•˜ê³  ë°˜í™˜
        templates.pop("_id", None)
        return templates
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë©”ì¼ í…œí”Œë¦¿ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/mail-templates")
async def save_mail_templates(templates: Dict[str, Any]):
    """ë©”ì¼ í…œí”Œë¦¿ ì €ì¥"""
    try:
        update_data = {
            "passed": templates.get("passed", {}),
            "rejected": templates.get("rejected", {}),
            "updated_at": datetime.now()
        }

        result = await db.mail_templates.update_one(
            {"_id": "default"},
            {"$set": update_data},
            upsert=True
        )

        return {"success": True, "message": "ë©”ì¼ í…œí”Œë¦¿ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë©”ì¼ í…œí”Œë¦¿ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/mail-settings")
async def get_mail_settings():
    """ë©”ì¼ ì„¤ì • ì¡°íšŒ"""
    try:
        settings = await db.mail_settings.find_one({"_id": "default"})
        if not settings:
            # ê¸°ë³¸ ì„¤ì • ìƒì„±
            default_settings = {
                "_id": "default",
                "senderEmail": "",
                "senderPassword": "",
                "senderName": "",
                "smtpServer": "smtp.gmail.com",
                "smtpPort": 587,
                "created_at": datetime.now(),
                "updated_at": datetime.now()
            }
            await db.mail_settings.insert_one(default_settings)
            settings = default_settings

        # _id ì œê±°í•˜ê³  ë°˜í™˜
        settings.pop("_id", None)
        return settings
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë©”ì¼ ì„¤ì • ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/mail-settings")
async def save_mail_settings(settings: Dict[str, Any]):
    """ë©”ì¼ ì„¤ì • ì €ì¥"""
    try:
        update_data = {
            "senderEmail": settings.get("senderEmail", ""),
            "senderPassword": settings.get("senderPassword", ""),
            "senderName": settings.get("senderName", ""),
            "smtpServer": settings.get("smtpServer", "smtp.gmail.com"),
            "smtpPort": settings.get("smtpPort", 587),
            "updated_at": datetime.now()
        }

        result = await db.mail_settings.update_one(
            {"_id": "default"},
            {"$set": update_data},
            upsert=True
        )

        return {"success": True, "message": "ë©”ì¼ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë©”ì¼ ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/send-test-mail")
async def send_test_mail(request: Request):
    """í…ŒìŠ¤íŠ¸ ë©”ì¼ ë°œì†¡"""
    try:
        import smtplib
        from email.mime.multipart import MIMEMultipart
        from email.mime.text import MIMEText

        data = await request.json()
        print(f"ë°›ì€ ë°ì´í„°: {data}")  # ë””ë²„ê¹…ìš© ë¡œê·¸

        test_email = data.get("testEmail")
        mail_settings = data.get("mailSettings")

        print(f"í…ŒìŠ¤íŠ¸ ì´ë©”ì¼: {test_email}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
        print(f"ë©”ì¼ ì„¤ì •: {mail_settings}")  # ë””ë²„ê¹…ìš© ë¡œê·¸

        if not test_email or not mail_settings:
            print("í…ŒìŠ¤íŠ¸ ì´ë©”ì¼ ë˜ëŠ” ë©”ì¼ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")  # ë””ë²„ê¹…ìš© ë¡œê·¸
            raise HTTPException(status_code=400, detail="í…ŒìŠ¤íŠ¸ ì´ë©”ì¼ê³¼ ë©”ì¼ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        # ë©”ì¼ í…œí”Œë¦¿ ì¡°íšŒ
        mail_templates = await db.mail_templates.find_one({"_id": "default"})
        if not mail_templates:
            raise HTTPException(status_code=400, detail="ë©”ì¼ í…œí”Œë¦¿ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        # í…ŒìŠ¤íŠ¸ ë©”ì¼ ë‚´ìš© ìƒì„±
        template = mail_templates.get("passed", {})
        subject = template.get("subject", "í…ŒìŠ¤íŠ¸ ë©”ì¼")
        content = template.get("content", "í…ŒìŠ¤íŠ¸ ë©”ì¼ì…ë‹ˆë‹¤.")

        # ë³€ìˆ˜ ì¹˜í™˜
        content = content.format(
            applicant_name="í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì",
            job_posting_title="í…ŒìŠ¤íŠ¸ ì±„ìš©ê³µê³ ",
            company_name="í…ŒìŠ¤íŠ¸ íšŒì‚¬",
            position="í…ŒìŠ¤íŠ¸ ì§ë¬´"
        )

        # ë©”ì¼ ê°ì²´ ìƒì„±
        msg = MIMEMultipart()
        msg['From'] = f"{mail_settings.get('senderName', '')} <{mail_settings.get('senderEmail')}>"
        msg['To'] = test_email
        msg['Subject'] = f"[í…ŒìŠ¤íŠ¸] {subject}"

        # ë©”ì¼ ë³¸ë¬¸ ì¶”ê°€
        msg.attach(MIMEText(content, 'plain', 'utf-8'))

        # SMTP ì„œë²„ ì—°ê²° ë° ë©”ì¼ ë°œì†¡
        try:
            print(f"SMTP ì„œë²„ ì—°ê²° ì‹œë„: {mail_settings.get('smtpServer')}:{mail_settings.get('smtpPort')}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
            print(f"ë°œì†¡ì ì´ë©”ì¼: {mail_settings.get('senderEmail')}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
            print(f"ë°œì†¡ì ë¹„ë°€ë²ˆí˜¸ ê¸¸ì´: {len(mail_settings.get('senderPassword', ''))}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
            print(f"ë°œì†¡ì ë¹„ë°€ë²ˆí˜¸: {mail_settings.get('senderPassword', '')[:4]}***")  # ë””ë²„ê¹…ìš© ë¡œê·¸ (ì• 4ìë¦¬ë§Œ)

            smtp_port = mail_settings.get('smtpPort', 587)
            smtp_server = mail_settings.get('smtpServer', 'smtp.gmail.com')

            # í¬íŠ¸ 465ì¸ ê²½ìš° SSL ì‚¬ìš©
            if smtp_port == 465:
                with smtplib.SMTP_SSL(smtp_server, smtp_port) as server:
                    print("SMTP SSL ì„œë²„ ì—°ê²° ì„±ê³µ")  # ë””ë²„ê¹…ìš© ë¡œê·¸
                    print(f"ë¡œê·¸ì¸ ì‹œë„: {mail_settings.get('senderEmail')}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
                    server.login(mail_settings.get('senderEmail'), mail_settings.get('senderPassword'))
                    print("ë¡œê·¸ì¸ ì„±ê³µ")  # ë””ë²„ê¹…ìš© ë¡œê·¸
                    server.send_message(msg)
                    print("ë©”ì¼ ë°œì†¡ ì„±ê³µ")  # ë””ë²„ê¹…ìš© ë¡œê·¸
            else:
                with smtplib.SMTP(smtp_server, smtp_port) as server:
                    print("SMTP ì„œë²„ ì—°ê²° ì„±ê³µ")  # ë””ë²„ê¹…ìš© ë¡œê·¸
                    server.starttls()
                    print("STARTTLS ì„±ê³µ")  # ë””ë²„ê¹…ìš© ë¡œê·¸
                    print(f"ë¡œê·¸ì¸ ì‹œë„: {mail_settings.get('senderEmail')}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
                    server.login(mail_settings.get('senderEmail'), mail_settings.get('senderPassword'))
                    print("ë¡œê·¸ì¸ ì„±ê³µ")  # ë””ë²„ê¹…ìš© ë¡œê·¸
                    server.send_message(msg)
                    print("ë©”ì¼ ë°œì†¡ ì„±ê³µ")  # ë””ë²„ê¹…ìš© ë¡œê·¸

            return {
                "success": True,
                "message": "í…ŒìŠ¤íŠ¸ ë©”ì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "subject": f"[í…ŒìŠ¤íŠ¸] {subject}",
                "to": test_email
            }

        except smtplib.SMTPAuthenticationError as e:
            print(f"ì¸ì¦ ì‹¤íŒ¨: {str(e)}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
            raise HTTPException(status_code=400, detail="ì¸ì¦ ì‹¤íŒ¨. ì´ë©”ì¼ ì£¼ì†Œì™€ ì•± ë¹„ë°€ë²ˆí˜¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        except smtplib.SMTPException as e:
            print(f"SMTP ì˜¤ë¥˜: {str(e)}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
            raise HTTPException(status_code=400, detail=f"SMTP ì˜¤ë¥˜: {str(e)}")
        except Exception as e:
            print(f"ë©”ì¼ ë°œì†¡ ì˜¤ë¥˜: {str(e)}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
            raise HTTPException(status_code=500, detail=f"ë©”ì¼ ë°œì†¡ ì˜¤ë¥˜: {str(e)}")

    except HTTPException:
        raise
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ ë©”ì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
        raise HTTPException(status_code=500, detail=f"í…ŒìŠ¤íŠ¸ ë©”ì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
