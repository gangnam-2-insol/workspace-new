"""
AI ê¸°ë°˜ ì¸ì¬ ë§¤ì¹­ ì„œë¹„ìŠ¤
Googleì˜ ko-sroberta-multitask ëª¨ë¸ì„ ì‚¬ìš©í•œ ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°
"""

# HuggingFace ëª¨ë¸ ì„ì‹œ ë¹„í™œì„±í™”
# from sentence_transformers import SentenceTransformer
# from sklearn.metrics.pairwise import cosine_similarity
# import numpy as np
import re
from typing import Dict, List, Any, Optional
import logging

logger = logging.getLogger(__name__)

class AIMatchingService:
    """AI ê¸°ë°˜ ì¸ì¬ ë§¤ì¹­ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        """ëª¨ë¸ ì´ˆê¸°í™” (HuggingFace ëª¨ë¸ ì„ì‹œ ë¹„í™œì„±í™”)"""
        # HuggingFace ëª¨ë¸ ì„ì‹œ ë¹„í™œì„±í™” - ë¹Œë“œ ì‹œê°„ ë‹¨ì¶•ì„ ìœ„í•´
        self.model = None
        logger.info("ğŸ“ HuggingFace ëª¨ë¸ ë¹„í™œì„±í™” (ê¸°ì¡´ í‚¤ì›Œë“œ ë§¤ì¹­ ì‚¬ìš©)")
        # try:
        #     # í•œêµ­ì–´ íŠ¹í™” SentenceTransformer ëª¨ë¸ ë¡œë“œ
        #     self.model = SentenceTransformer('jhgan/ko-sroberta-multitask')
        #     logger.info("âœ… ko-sroberta-multitask ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        # except Exception as e:
        #     logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        #     self.model = None
    
    def calculate_semantic_similarity(self, text1: str, text2: str) -> float:
        """ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if not self.model:
            logger.warning("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ ê¸°ë³¸ê°’ ë°˜í™˜")
            return 0.5
        
        try:
            # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
            embeddings = self.model.encode([text1, text2])
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]
            
            # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
            return max(0.0, min(1.0, similarity))
            
        except Exception as e:
            logger.error(f"ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.5
    
    def analyze_requirements_with_ai(self, requirements_text: str) -> Dict[str, Any]:
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ìš”êµ¬ì‚¬í•­ í…ìŠ¤íŠ¸ë¥¼ ë” ì •êµí•˜ê²Œ ë¶„ì„í•©ë‹ˆë‹¤."""
        
        # ê¸°ë³¸ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        basic_analysis = self._basic_keyword_analysis(requirements_text)
        
        # AI ê¸°ë°˜ ì¶”ê°€ ë¶„ì„
        ai_analysis = self._ai_enhanced_analysis(requirements_text)
        
        # ê²°ê³¼ ë³‘í•©
        return {
            **basic_analysis,
            'ai_embedding': ai_analysis.get('embedding'),
            'semantic_keywords': ai_analysis.get('semantic_keywords', [])
        }
    
    def _basic_keyword_analysis(self, requirements_text: str) -> Dict[str, Any]:
        """ê¸°ì¡´ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ (ë°±ì—…ìš©)"""
        
        # ì§ë¬´ í‚¤ì›Œë“œ
        position_keywords = {
            'ê°œë°œì': ['ê°œë°œì', 'í”„ë¡œê·¸ë˜ë¨¸', 'ì—”ì§€ë‹ˆì–´', 'ê°œë°œ', 'í”„ë¡œê·¸ë˜ë°'],
            'ë””ìì´ë„ˆ': ['ë””ìì´ë„ˆ', 'ë””ìì¸', 'UI', 'UX', 'ì¸í„°í˜ì´ìŠ¤'],
            'ë§¤ë‹ˆì €': ['ë§¤ë‹ˆì €', 'ê´€ë¦¬ì', 'íŒ€ì¥', 'ë¦¬ë”', 'ê´€ë¦¬'],
            'ë¶„ì„ê°€': ['ë¶„ì„ê°€', 'ë¶„ì„', 'ë°ì´í„°', 'í†µê³„', 'ì¸ì‚¬ì´íŠ¸'],
            'ë§ˆì¼€í„°': ['ë§ˆì¼€í„°', 'ë§ˆì¼€íŒ…', 'í™ë³´', 'ë¸Œëœë”©', 'ê´‘ê³ ']
        }
        
        # ê¸°ìˆ  í‚¤ì›Œë“œ
        tech_keywords = ['React', 'Vue', 'Angular', 'JavaScript', 'TypeScript', 'Python', 'Java', 
                        'Node.js', 'Spring', 'Django', 'MySQL', 'MongoDB', 'AWS', 'Docker', 'Kubernetes']
        
        # ì„±ê²©/ëŠ¥ë ¥ í‚¤ì›Œë“œ
        ability_keywords = ['ì°½ì˜ì ', 'ë¶„ì„ì ', 'í˜‘ì—…', 'ë¦¬ë”ì‹­', 'ì»¤ë®¤ë‹ˆì¼€ì´ì…˜', 'ë¬¸ì œí•´ê²°', 
                           'ì ê·¹ì ', 'ì£¼ë„ì ', 'ê¼¼ê¼¼', 'ìœ ì—°']
        
        text_lower = requirements_text.lower()
        
        # ì¶”ì¶œëœ í‚¤ì›Œë“œë“¤
        extracted_position = None
        for pos, keywords in position_keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                extracted_position = pos
                break
        
        extracted_skills = []
        for skill in tech_keywords:
            if skill.lower() in text_lower:
                extracted_skills.append(skill)
        
        extracted_abilities = []
        for ability in ability_keywords:
            if ability in text_lower:
                extracted_abilities.append(ability)
        
        return {
            'position': extracted_position,
            'skills': extracted_skills,
            'abilities': extracted_abilities,
            'original_text': requirements_text
        }
    
    def _ai_enhanced_analysis(self, requirements_text: str) -> Dict[str, Any]:
        """AI ê¸°ë°˜ í–¥ìƒëœ ë¶„ì„"""
        if not self.model:
            return {'embedding': None, 'semantic_keywords': []}
        
        try:
            # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
            embedding = self.model.encode(requirements_text)
            
            # ì˜ë¯¸ì  í‚¤ì›Œë“œ ì¶”ì¶œ (í–¥í›„ í™•ì¥ ê°€ëŠ¥)
            semantic_keywords = self._extract_semantic_keywords(requirements_text)
            
            return {
                'embedding': embedding.tolist(),  # JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡ ë³€í™˜
                'semantic_keywords': semantic_keywords
            }
        except Exception as e:
            logger.error(f"AI ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {'embedding': None, 'semantic_keywords': []}
    
    def _extract_semantic_keywords(self, text: str) -> List[str]:
        """ì˜ë¯¸ì  í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë²„ì „)"""
        # í–¥í›„ ë” ì •êµí•œ NERì´ë‚˜ í‚¤ì›Œë“œ ì¶”ì¶œ ëª¨ë¸ë¡œ í™•ì¥ ê°€ëŠ¥
        keywords = []
        
        # í˜„ì¬ëŠ” ë‹¨ìˆœ í† í°í™” + í•„í„°ë§
        words = re.findall(r'\b[ê°€-í£a-zA-Z]{2,}\b', text)
        
        # ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œë§Œ í•„í„°ë§
        meaningful_words = [word for word in words if len(word) >= 2]
        
        return meaningful_words[:10]  # ìƒìœ„ 10ê°œë§Œ ë°˜í™˜
    
    def calculate_ai_talent_match_score(self, talent: Dict[str, Any], requirements: Dict[str, Any]) -> int:
        """AI ê¸°ë°˜ ì¸ì¬ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
        
        if not self.model:
            # AI ëª¨ë¸ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
            return self._fallback_match_score(talent, requirements)
        
        try:
            # 1. í…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜ë¯¸ì  ìœ ì‚¬ë„ (40ì )
            semantic_score = self._calculate_semantic_score(talent, requirements)
            
            # 2. ê¸°ìˆ  ìŠ¤íƒ ë§¤ì¹­ (30ì ) 
            skills_score = self._calculate_skills_score(talent, requirements)
            
            # 3. ì§ë¬´ ë§¤ì¹­ (20ì )
            position_score = self._calculate_position_score(talent, requirements)
            
            # 4. ê²½ë ¥ ì ìˆ˜ (10ì )
            experience_score = self._calculate_experience_score(talent)
            
            # ì´ì  ê³„ì‚°
            total_score = semantic_score + skills_score + position_score + experience_score
            
            # 0-100 ë²”ìœ„ë¡œ ì •ê·œí™”
            final_score = max(60, min(100, int(total_score)))
            
            logger.info(f"ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°: ì˜ë¯¸ì ={semantic_score:.1f}, ê¸°ìˆ ={skills_score:.1f}, "
                       f"ì§ë¬´={position_score:.1f}, ê²½ë ¥={experience_score:.1f}, ì´ì ={final_score}")
            
            return final_score
            
        except Exception as e:
            logger.error(f"AI ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return self._fallback_match_score(talent, requirements)
    
    def _calculate_semantic_score(self, talent: Dict[str, Any], requirements: Dict[str, Any]) -> float:
        """ì˜ë¯¸ì  ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚° (40ì  ë§Œì )"""
        
        talent_text = talent.get('profileText', '')
        requirements_text = requirements.get('original_text', '')
        
        if not talent_text or not requirements_text:
            return 20.0  # ê¸°ë³¸ ì ìˆ˜
        
        # ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°
        similarity = self.calculate_semantic_similarity(talent_text, requirements_text)
        
        # 0-40ì ìœ¼ë¡œ ë³€í™˜
        return similarity * 40.0
    
    def _calculate_skills_score(self, talent: Dict[str, Any], requirements: Dict[str, Any]) -> float:
        """ê¸°ìˆ  ìŠ¤íƒ ë§¤ì¹­ ì ìˆ˜ (30ì  ë§Œì )"""
        
        talent_skills = [skill.lower() for skill in talent.get('skills', [])]
        req_skills = [skill.lower() for skill in requirements.get('skills', [])]
        
        if not req_skills:
            return 20.0  # ìš”êµ¬ì‚¬í•­ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì ìˆ˜
        
        # ì •í™•í•œ ë§¤ì¹­
        exact_matches = sum(1 for skill in req_skills if skill in talent_skills)
        
        # ë¶€ë¶„ ë§¤ì¹­ (AI ëª¨ë¸ë¡œ ìœ ì‚¬í•œ ê¸°ìˆ  ì°¾ê¸°)
        partial_matches = 0
        for req_skill in req_skills:
            if req_skill not in talent_skills:
                for talent_skill in talent_skills:
                    similarity = self.calculate_semantic_similarity(req_skill, talent_skill)
                    if similarity > 0.7:  # 70% ì´ìƒ ìœ ì‚¬í•˜ë©´ ë¶€ë¶„ ë§¤ì¹­
                        partial_matches += 0.5
                        break
        
        total_matches = exact_matches + partial_matches
        match_ratio = min(total_matches / len(req_skills), 1.0)
        
        return match_ratio * 30.0
    
    def _calculate_position_score(self, talent: Dict[str, Any], requirements: Dict[str, Any]) -> float:
        """ì§ë¬´ ë§¤ì¹­ ì ìˆ˜ (20ì  ë§Œì )"""
        
        talent_position = talent.get('position', '').lower()
        req_position = requirements.get('position', '')
        
        if not req_position or not talent_position:
            return 10.0  # ê¸°ë³¸ ì ìˆ˜
        
        req_position_lower = req_position.lower()
        
        # ì •í™•í•œ ë§¤ì¹­
        if req_position_lower in talent_position or talent_position in req_position_lower:
            return 20.0
        
        # ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­
        similarity = self.calculate_semantic_similarity(talent_position, req_position_lower)
        return similarity * 20.0
    
    def _calculate_experience_score(self, talent: Dict[str, Any]) -> float:
        """ê²½ë ¥ ì ìˆ˜ (10ì  ë§Œì )"""
        
        talent_exp = talent.get('experience', '0')
        exp_numbers = re.findall(r'\d+', talent_exp)
        
        if exp_numbers:
            exp_years = int(exp_numbers[0])
            return min(exp_years * 2, 10.0)
        
        return 5.0  # ê¸°ë³¸ ì ìˆ˜
    
    def _fallback_match_score(self, talent: Dict[str, Any], requirements: Dict[str, Any]) -> int:
        """AI ëª¨ë¸ì´ ì—†ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ê¸°ë³¸ ë§¤ì¹­ ë¡œì§"""
        base_score = 60
        
        # ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼
        position_score = 0
        if requirements.get('position'):
            talent_position = talent.get('position', '').lower()
            req_position = requirements['position'].lower()
            if req_position in talent_position or talent_position in req_position:
                position_score = 30
            elif any(word in talent_position for word in req_position.split()):
                position_score = 20
        
        skills_score = 0
        talent_skills = [skill.lower() for skill in talent.get('skills', [])]
        req_skills = [skill.lower() for skill in requirements.get('skills', [])]
        if req_skills:
            matched_skills = sum(1 for skill in req_skills if any(skill in ts for ts in talent_skills))
            skills_score = min((matched_skills / len(req_skills)) * 25, 25)
        
        experience_score = 0
        talent_exp = talent.get('experience', '0')
        exp_numbers = re.findall(r'\d+', talent_exp)
        if exp_numbers:
            exp_years = int(exp_numbers[0])
            experience_score = min(exp_years * 2, 10)
        
        final_score = base_score + position_score + skills_score + experience_score
        return min(max(final_score, 60), 100)

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
ai_matching_service = AIMatchingService()