"""
ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹… ì‹œìŠ¤í…œ

ì±—ë´‡ ìš´ì˜ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  ë¡œê¹…í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
"""

import logging
import time
import json
import os
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from collections import defaultdict, deque
from dataclasses import dataclass, asdict
from threading import Lock
import smtplib

# ì´ë©”ì¼ ê´€ë ¨ ëª¨ë“ˆ ì„ íƒì  import
try:
    from email.mime.text import MIMEText
    from email.mime.multipart import MIMEMultipart
    EMAIL_AVAILABLE = True
except ImportError:
    EMAIL_AVAILABLE = False
    MIMEText = None
    MIMEMultipart = None

logger = logging.getLogger(__name__)

@dataclass
class ToolExecutionLog:
    """íˆ´ ì‹¤í–‰ ë¡œê·¸ ë°ì´í„° í´ë˜ìŠ¤"""
    timestamp: str
    session_id: str
    user_id: Optional[str]
    tool: str
    action: str
    status: str
    duration_ms: int
    error_message: Optional[str]
    parameters: Dict[str, Any]
    response_size: Optional[int]
    cache_hit: bool = False
    retry_count: int = 0

@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""
    tool: str
    action: str
    total_executions: int
    successful_executions: int
    failed_executions: int
    average_duration_ms: float
    max_duration_ms: int
    min_duration_ms: int
    error_rate: float
    cache_hit_rate: float

class MonitoringSystem:
    """í†µí•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""
    
    def __init__(self, log_file: str = "logs/tool_executions.log", max_logs: int = 10000):
        """
        ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            log_file: ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
            max_logs: ìµœëŒ€ ë¡œê·¸ ë³´ê´€ ìˆ˜
        """
        self.log_file = log_file
        self.max_logs = max_logs
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(log_file), exist_ok=True)
        
        # ë¡œê¹… ì„¤ì •
        self._setup_logging()
        
        # ë©”íŠ¸ë¦­ ì €ì¥ì†Œ
        self.metrics = defaultdict(lambda: {
            "total_executions": 0,
            "successful_executions": 0,
            "failed_executions": 0,
            "durations": deque(maxlen=1000),  # ìµœê·¼ 1000ê°œ ì‹¤í–‰ ì‹œê°„
            "cache_hits": 0,
            "retry_counts": deque(maxlen=1000)
        })
        
        # ì•Œë¦¼ ì„¤ì •
        self.alert_thresholds = {
            "error_rate": 0.1,  # 10% ì´ìƒ ì—ëŸ¬ìœ¨
            "avg_duration_ms": 5000,  # 5ì´ˆ ì´ìƒ í‰ê·  ì‹¤í–‰ ì‹œê°„
            "max_duration_ms": 30000  # 30ì´ˆ ì´ìƒ ìµœëŒ€ ì‹¤í–‰ ì‹œê°„
        }
        
        # ìŠ¤ë ˆë“œ ì•ˆì „ì„ ìœ„í•œ ë½
        self.lock = Lock()
        
        # ì•Œë¦¼ ê¸°ë¡ (ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€)
        self.alert_history = defaultdict(lambda: deque(maxlen=10))
        
        logger.info("MonitoringSystem initialized")
    
    def _setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        # íŒŒì¼ í•¸ë“¤ëŸ¬
        file_handler = logging.FileHandler(self.log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # í¬ë§·í„°
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(formatter)
        
        # ë¡œê±°ì— í•¸ë“¤ëŸ¬ ì¶”ê°€
        monitoring_logger = logging.getLogger('monitoring')
        monitoring_logger.addHandler(file_handler)
        monitoring_logger.setLevel(logging.INFO)
        
        self.monitoring_logger = monitoring_logger
    
    def log_tool_execution(self, log_data: ToolExecutionLog):
        """
        íˆ´ ì‹¤í–‰ ë¡œê·¸ ê¸°ë¡
        
        Args:
            log_data: íˆ´ ì‹¤í–‰ ë¡œê·¸ ë°ì´í„°
        """
        with self.lock:
            # ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡
            log_entry = asdict(log_data)
            self.monitoring_logger.info(json.dumps(log_entry, ensure_ascii=False))
            
            # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            key = f"{log_data.tool}.{log_data.action}"
            metrics = self.metrics[key]
            
            metrics["total_executions"] += 1
            metrics["durations"].append(log_data.duration_ms)
            
            if log_data.status == "success":
                metrics["successful_executions"] += 1
            else:
                metrics["failed_executions"] += 1
            
            if log_data.cache_hit:
                metrics["cache_hits"] += 1
            
            metrics["retry_counts"].append(log_data.retry_count)
            
            # ì•Œë¦¼ ì²´í¬
            self._check_alerts(key, log_data)
    
    def _check_alerts(self, tool_action: str, log_data: ToolExecutionLog):
        """
        ì•Œë¦¼ ì¡°ê±´ ì²´í¬
        
        Args:
            tool_action: íˆ´.ì•¡ì…˜ í‚¤
            log_data: ë¡œê·¸ ë°ì´í„°
        """
        metrics = self.metrics[tool_action]
        
        if metrics["total_executions"] < 10:  # ìµœì†Œ 10ë²ˆ ì‹¤í–‰ í›„ ì•Œë¦¼
            return
        
        # ì—ëŸ¬ìœ¨ ì²´í¬
        error_rate = metrics["failed_executions"] / metrics["total_executions"]
        if error_rate > self.alert_thresholds["error_rate"]:
            self._send_alert(
                "high_error_rate",
                f"ë†’ì€ ì—ëŸ¬ìœ¨ ê°ì§€: {tool_action} - {error_rate:.2%}",
                {"tool_action": tool_action, "error_rate": error_rate}
            )
        
        # í‰ê·  ì‹¤í–‰ ì‹œê°„ ì²´í¬
        if metrics["durations"]:
            avg_duration = sum(metrics["durations"]) / len(metrics["durations"])
            if avg_duration > self.alert_thresholds["avg_duration_ms"]:
                self._send_alert(
                    "slow_execution",
                    f"ëŠë¦° ì‹¤í–‰ ê°ì§€: {tool_action} - í‰ê·  {avg_duration:.0f}ms",
                    {"tool_action": tool_action, "avg_duration": avg_duration}
                )
        
        # ê°œë³„ ì‹¤í–‰ ì‹œê°„ ì²´í¬
        if log_data.duration_ms > self.alert_thresholds["max_duration_ms"]:
            self._send_alert(
                "very_slow_execution",
                f"ë§¤ìš° ëŠë¦° ì‹¤í–‰ ê°ì§€: {tool_action} - {log_data.duration_ms}ms",
                {"tool_action": tool_action, "duration": log_data.duration_ms}
            )
    
    def _send_alert(self, alert_type: str, message: str, data: Dict[str, Any]):
        """
        ì•Œë¦¼ ì „ì†¡
        
        Args:
            alert_type: ì•Œë¦¼ ìœ í˜•
            message: ì•Œë¦¼ ë©”ì‹œì§€
            data: ì•Œë¦¼ ë°ì´í„°
        """
        # ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€ (5ë¶„ ë‚´ ê°™ì€ ì•Œë¦¼ì€ ë¬´ì‹œ)
        now = datetime.now()
        alert_key = f"{alert_type}_{data.get('tool_action', 'unknown')}"
        
        if alert_key in self.alert_history:
            last_alert = self.alert_history[alert_key][-1]
            if (now - last_alert).total_seconds() < 300:  # 5ë¶„
                return
        
        self.alert_history[alert_key].append(now)
        
        # ë¡œê·¸ì— ì•Œë¦¼ ê¸°ë¡
        alert_log = {
            "timestamp": now.isoformat(),
            "alert_type": alert_type,
            "message": message,
            "data": data
        }
        
        self.monitoring_logger.warning(f"ALERT: {json.dumps(alert_log, ensure_ascii=False)}")
        
        # ì‹¤ì œ ì•Œë¦¼ ì „ì†¡ (ì´ë©”ì¼, Slack ë“±)
        self._send_notification(alert_type, message, data)
    
    def _send_notification(self, alert_type: str, message: str, data: Dict[str, Any]):
        """
        ì‹¤ì œ ì•Œë¦¼ ì „ì†¡ (ì´ë©”ì¼, Slack ë“±)
        
        Args:
            alert_type: ì•Œë¦¼ ìœ í˜•
            message: ì•Œë¦¼ ë©”ì‹œì§€
            data: ì•Œë¦¼ ë°ì´í„°
        """
        # ì´ë©”ì¼ ì•Œë¦¼ (í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•„ìš”)
        email_enabled = os.getenv("MONITORING_EMAIL_ENABLED", "false").lower() == "true"
        if email_enabled:
            self._send_email_alert(alert_type, message, data)
        
        # Slack ì•Œë¦¼ (í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•„ìš”)
        slack_enabled = os.getenv("MONITORING_SLACK_ENABLED", "false").lower() == "true"
        if slack_enabled:
            self._send_slack_alert(alert_type, message, data)
    
    def _send_email_alert(self, alert_type: str, message: str, data: Dict[str, Any]):
        """ì´ë©”ì¼ ì•Œë¦¼ ì „ì†¡"""
        if not EMAIL_AVAILABLE:
            logger.warning("Email functionality not available")
            return
            
        try:
            smtp_server = os.getenv("SMTP_SERVER", "smtp.gmail.com")
            smtp_port = int(os.getenv("SMTP_PORT", "587"))
            smtp_username = os.getenv("SMTP_USERNAME")
            smtp_password = os.getenv("SMTP_PASSWORD")
            alert_email = os.getenv("ALERT_EMAIL")
            
            if not all([smtp_username, smtp_password, alert_email]):
                logger.warning("Email alert configuration incomplete")
                return
            
            msg = MIMEMultipart()
            msg['From'] = smtp_username
            msg['To'] = alert_email
            msg['Subject'] = f"ì±—ë´‡ ì•Œë¦¼: {alert_type}"
            
            body = f"""
            ì±—ë´‡ ëª¨ë‹ˆí„°ë§ ì•Œë¦¼
            
            ìœ í˜•: {alert_type}
            ë©”ì‹œì§€: {message}
            ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
            ë°ì´í„°: {json.dumps(data, ensure_ascii=False, indent=2)}
            """
            
            msg.attach(MIMEText(body, 'plain', 'utf-8'))
            
            with smtplib.SMTP(smtp_server, smtp_port) as server:
                server.starttls()
                server.login(smtp_username, smtp_password)
                server.send_message(msg)
            
            logger.info(f"Email alert sent: {alert_type}")
            
        except Exception as e:
            logger.error(f"Failed to send email alert: {str(e)}")
    
    def _send_slack_alert(self, alert_type: str, message: str, data: Dict[str, Any]):
        """Slack ì•Œë¦¼ ì „ì†¡"""
        try:
            import requests
            
            webhook_url = os.getenv("SLACK_WEBHOOK_URL")
            if not webhook_url:
                logger.warning("Slack webhook URL not configured")
                return
            
            payload = {
                "text": f"ğŸš¨ ì±—ë´‡ ì•Œë¦¼\n\n**ìœ í˜•**: {alert_type}\n**ë©”ì‹œì§€**: {message}\n**ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                "attachments": [
                    {
                        "fields": [
                            {"title": "ë°ì´í„°", "value": json.dumps(data, ensure_ascii=False, indent=2), "short": False}
                        ]
                    }
                ]
            }
            
            response = requests.post(webhook_url, json=payload)
            response.raise_for_status()
            
            logger.info(f"Slack alert sent: {alert_type}")
            
        except Exception as e:
            logger.error(f"Failed to send Slack alert: {str(e)}")
    
    def get_performance_metrics(self, tool_action: str = None) -> Dict[str, Any]:
        """
        ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ
        
        Args:
            tool_action: íŠ¹ì • íˆ´.ì•¡ì…˜ (Noneì´ë©´ ì „ì²´)
            
        Returns:
            ì„±ëŠ¥ ë©”íŠ¸ë¦­
        """
        with self.lock:
            if tool_action:
                return self._calculate_metrics(tool_action)
            else:
                return {
                    action: self._calculate_metrics(action)
                    for action in self.metrics.keys()
                }
    
    def _calculate_metrics(self, tool_action: str) -> Dict[str, Any]:
        """íŠ¹ì • íˆ´.ì•¡ì…˜ì˜ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        metrics = self.metrics[tool_action]
        
        if not metrics["durations"]:
            return {
                "tool_action": tool_action,
                "total_executions": 0,
                "successful_executions": 0,
                "failed_executions": 0,
                "average_duration_ms": 0,
                "max_duration_ms": 0,
                "min_duration_ms": 0,
                "error_rate": 0,
                "cache_hit_rate": 0
            }
        
        durations = list(metrics["durations"])
        avg_duration = sum(durations) / len(durations)
        error_rate = metrics["failed_executions"] / metrics["total_executions"]
        cache_hit_rate = metrics["cache_hits"] / metrics["total_executions"]
        
        return {
            "tool_action": tool_action,
            "total_executions": metrics["total_executions"],
            "successful_executions": metrics["successful_executions"],
            "failed_executions": metrics["failed_executions"],
            "average_duration_ms": round(avg_duration, 2),
            "max_duration_ms": max(durations),
            "min_duration_ms": min(durations),
            "error_rate": round(error_rate, 4),
            "cache_hit_rate": round(cache_hit_rate, 4)
        }
    
    def get_usage_statistics(self, days: int = 7) -> Dict[str, Any]:
        """
        ì‚¬ìš©ëŸ‰ í†µê³„ ì¡°íšŒ
        
        Args:
            days: ì¡°íšŒ ê¸°ê°„ (ì¼)
            
        Returns:
            ì‚¬ìš©ëŸ‰ í†µê³„
        """
        with self.lock:
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë¡œê·¸ íŒŒì¼ì—ì„œ í†µê³„ ê³„ì‚°
            # ì—¬ê¸°ì„œëŠ” ë©”ëª¨ë¦¬ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°
            
            total_executions = sum(m["total_executions"] for m in self.metrics.values())
            total_successful = sum(m["successful_executions"] for m in self.metrics.values())
            total_failed = sum(m["failed_executions"] for m in self.metrics.values())
            
            # ì¸ê¸° íˆ´ ìˆœìœ„
            tool_usage = {}
            for tool_action, metrics in self.metrics.items():
                tool = tool_action.split('.')[0]
                tool_usage[tool] = tool_usage.get(tool, 0) + metrics["total_executions"]
            
            popular_tools = sorted(tool_usage.items(), key=lambda x: x[1], reverse=True)
            
            return {
                "period_days": days,
                "total_executions": total_executions,
                "successful_executions": total_successful,
                "failed_executions": total_failed,
                "success_rate": round(total_successful / total_executions, 4) if total_executions > 0 else 0,
                "popular_tools": popular_tools[:5],  # ìƒìœ„ 5ê°œ
                "unique_tool_actions": len(self.metrics)
            }
    
    def get_recent_logs(self, limit: int = 100) -> List[Dict[str, Any]]:
        """
        ìµœê·¼ ë¡œê·¸ ì¡°íšŒ
        
        Args:
            limit: ì¡°íšŒí•  ë¡œê·¸ ìˆ˜
            
        Returns:
            ìµœê·¼ ë¡œê·¸ ëª©ë¡
        """
        try:
            with open(self.log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                recent_lines = lines[-limit:] if len(lines) > limit else lines
                
                logs = []
                for line in recent_lines:
                    try:
                        # ë¡œê·¸ ë¼ì¸ì—ì„œ JSON ë¶€ë¶„ ì¶”ì¶œ
                        json_start = line.find('{')
                        if json_start != -1:
                            json_str = line[json_start:]
                            log_data = json.loads(json_str)
                            logs.append(log_data)
                    except json.JSONDecodeError:
                        continue
                
                return logs
        except FileNotFoundError:
            return []
    
    def clear_metrics(self):
        """ë©”íŠ¸ë¦­ ì´ˆê¸°í™”"""
        with self.lock:
            self.metrics.clear()
            self.alert_history.clear()
            logger.info("All metrics cleared")

# ì „ì—­ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
monitoring_system = MonitoringSystem()

def log_tool_execution(
    session_id: str,
    tool: str,
    action: str,
    status: str,
    duration_ms: int,
    error_message: str = None,
    parameters: Dict[str, Any] = None,
    response_size: int = None,
    cache_hit: bool = False,
    retry_count: int = 0,
    user_id: str = None
):
    """
    íˆ´ ì‹¤í–‰ ë¡œê·¸ ê¸°ë¡ í—¬í¼ í•¨ìˆ˜
    
    Args:
        session_id: ì„¸ì…˜ ID
        tool: íˆ´ ì´ë¦„
        action: ì•¡ì…˜ ì´ë¦„
        status: ì‹¤í–‰ ìƒíƒœ
        duration_ms: ì‹¤í–‰ ì‹œê°„ (ë°€ë¦¬ì´ˆ)
        error_message: ì—ëŸ¬ ë©”ì‹œì§€
        parameters: ì‹¤í–‰ ë§¤ê°œë³€ìˆ˜
        response_size: ì‘ë‹µ í¬ê¸°
        cache_hit: ìºì‹œ íˆíŠ¸ ì—¬ë¶€
        retry_count: ì¬ì‹œë„ íšŸìˆ˜
        user_id: ì‚¬ìš©ì ID
    """
    log_data = ToolExecutionLog(
        timestamp=datetime.now().isoformat(),
        session_id=session_id,
        user_id=user_id,
        tool=tool,
        action=action,
        status=status,
        duration_ms=duration_ms,
        error_message=error_message,
        parameters=parameters or {},
        response_size=response_size,
        cache_hit=cache_hit,
        retry_count=retry_count
    )
    
    monitoring_system.log_tool_execution(log_data)

def monitor_tool_execution(func):
    """
    íˆ´ ì‹¤í–‰ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°
    
    Args:
        func: ëª¨ë‹ˆí„°ë§í•  í•¨ìˆ˜
    """
    def wrapper(*args, **kwargs):
        start_time = time.time()
        session_id = kwargs.get('session_id', 'unknown')
        tool_name = getattr(args[0], '__class__.__name__', 'UnknownTool')
        
        try:
            result = func(*args, **kwargs)
            status = result.get('status', 'unknown')
            duration_ms = int((time.time() - start_time) * 1000)
            
            # ë¡œê·¸ ê¸°ë¡
            log_tool_execution(
                session_id=session_id,
                tool=tool_name,
                action=kwargs.get('action', 'unknown'),
                status=status,
                duration_ms=duration_ms,
                parameters=kwargs,
                response_size=len(str(result)) if result else 0,
                cache_hit=result.get('cached', False),
                retry_count=result.get('retry_count', 0)
            )
            
            return result
            
        except Exception as e:
            duration_ms = int((time.time() - start_time) * 1000)
            
            # ì—ëŸ¬ ë¡œê·¸ ê¸°ë¡
            log_tool_execution(
                session_id=session_id,
                tool=tool_name,
                action=kwargs.get('action', 'unknown'),
                status='error',
                duration_ms=duration_ms,
                error_message=str(e),
                parameters=kwargs
            )
            
            raise
    
    return wrapper
