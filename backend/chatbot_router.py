from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional
import uuid
import asyncio
import json
from datetime import datetime
import os
from dotenv import load_dotenv
import traceback
import re
from openai import AsyncOpenAI

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    print("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    print(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    client = None

# ì˜ë„ ê°ì§€ ìœ í‹¸ë¦¬í‹°
HARDCODED_FIELDS = {
    "UI/UX ë””ìì¸": "ì§€ì› ë¶„ì•¼: UI/UX ë””ìì¸ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.",
    "ê·¸ë˜í”½ ë””ìì¸": "ì§€ì› ë¶„ì•¼: ê·¸ë˜í”½ ë””ìì¸ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.",
    "Figma ê²½í—˜": "ì‚¬ìš© íˆ´: Figmaë¡œ ë“±ë¡í–ˆìŠµë‹ˆë‹¤.",
    "ê°œë°œíŒ€": "ë¶€ì„œ: ê°œë°œíŒ€ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.",
    "ë§ˆì¼€íŒ…íŒ€": "ë¶€ì„œ: ë§ˆì¼€íŒ…íŒ€ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.",
    "ì˜ì—…íŒ€": "ë¶€ì„œ: ì˜ì—…íŒ€ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.",
    "ë””ìì¸íŒ€": "ë¶€ì„œ: ë””ìì¸íŒ€ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.",
}

def classify_input(text: str) -> dict:
    """
    í‚¤ì›Œë“œ ê¸°ë°˜ 1ì°¨ ë¶„ë¥˜ í•¨ìˆ˜
    """
    text_lower = text.lower()
    
    # ì±„ìš© ê´€ë ¨ í‚¤ì›Œë“œ ë¶„ë¥˜
    if any(keyword in text_lower for keyword in ["ì±„ìš© ì¸ì›", "ëª‡ ëª…", "ì¸ì›ìˆ˜", "ì±„ìš©ì¸ì›"]):
        return {'type': 'question', 'category': 'ì±„ìš© ì¸ì›', 'confidence': 0.8}
    
    if any(keyword in text_lower for keyword in ["ì£¼ìš” ì—…ë¬´", "ì—…ë¬´ ë‚´ìš©", "ë‹´ë‹¹ ì—…ë¬´", "ì§ë¬´"]):
        return {'type': 'question', 'category': 'ì£¼ìš” ì—…ë¬´', 'confidence': 0.8}
    
    if any(keyword in text_lower for keyword in ["ê·¼ë¬´ ì‹œê°„", "ê·¼ë¬´ì‹œê°„", "ì¶œê·¼ ì‹œê°„", "í‡´ê·¼ ì‹œê°„"]):
        return {'type': 'question', 'category': 'ê·¼ë¬´ ì‹œê°„', 'confidence': 0.8}
    
    if any(keyword in text_lower for keyword in ["ê¸‰ì—¬", "ì—°ë´‰", "ì›”ê¸‰", "ë³´ìˆ˜", "ì„ê¸ˆ"]):
        return {'type': 'question', 'category': 'ê¸‰ì—¬ ì¡°ê±´', 'confidence': 0.8}
    
    if any(keyword in text_lower for keyword in ["ê·¼ë¬´ ìœ„ì¹˜", "ê·¼ë¬´ì§€", "ì‚¬ë¬´ì‹¤", "ì˜¤í”¼ìŠ¤"]):
        return {'type': 'question', 'category': 'ê·¼ë¬´ ìœ„ì¹˜', 'confidence': 0.8}
    
    if any(keyword in text_lower for keyword in ["ë§ˆê°ì¼", "ì§€ì› ë§ˆê°", "ì±„ìš© ë§ˆê°", "ë§ˆê°"]):
        return {'type': 'question', 'category': 'ë§ˆê°ì¼', 'confidence': 0.8}
    
    if any(keyword in text_lower for keyword in ["ì´ë©”ì¼", "ì—°ë½ì²˜", "contact", "email"]):
        return {'type': 'question', 'category': 'ì—°ë½ì²˜ ì´ë©”ì¼', 'confidence': 0.8}
    
    # ë¶€ì„œ ê´€ë ¨ í‚¤ì›Œë“œ
    if any(keyword in text_lower for keyword in ["ê°œë°œíŒ€", "ê°œë°œ", "í”„ë¡œê·¸ë˜ë°", "ì½”ë”©"]):
        return {'type': 'field', 'category': 'ë¶€ì„œ', 'value': 'ê°œë°œíŒ€', 'confidence': 0.9}
    
    if any(keyword in text_lower for keyword in ["ë§ˆì¼€íŒ…íŒ€", "ë§ˆì¼€íŒ…", "í™ë³´", "ê´‘ê³ "]):
        return {'type': 'field', 'category': 'ë¶€ì„œ', 'value': 'ë§ˆì¼€íŒ…íŒ€', 'confidence': 0.9}
    
    if any(keyword in text_lower for keyword in ["ì˜ì—…íŒ€", "ì˜ì—…", "ì„¸ì¼ì¦ˆ"]):
        return {'type': 'field', 'category': 'ë¶€ì„œ', 'value': 'ì˜ì—…íŒ€', 'confidence': 0.9}
    
    if any(keyword in text_lower for keyword in ["ë””ìì¸íŒ€", "ë””ìì¸", "UI/UX", "ê·¸ë˜í”½"]):
        return {'type': 'field', 'category': 'ë¶€ì„œ', 'value': 'ë””ìì¸íŒ€', 'confidence': 0.9}
    
    # ì§ˆë¬¸ í‚¤ì›Œë“œ ê°ì§€
    question_keywords = ["ì–´ë–»ê²Œ", "ì™œ", "ë¬´ì—‡", "ë­", "ì–¸ì œ", "ì–´ë””", "ì¶”ì²œ", "ê¸°ì¤€", "ì¥ì ", "ë‹¨ì ", "ì°¨ì´", "ìˆì„ê¹Œ", "ìˆë‚˜ìš”", "ì–´ë–¤", "ë¬´ìŠ¨", "ê¶ê¸ˆ", "ì•Œë ¤ì¤˜", "ì„¤ëª…í•´ì¤˜"]
    if any(keyword in text_lower for keyword in question_keywords) or text.strip().endswith("?"):
        return {'type': 'question', 'category': 'general', 'confidence': 0.8}
    
    # ì¼ìƒ ëŒ€í™” í‚¤ì›Œë“œ
    chat_keywords = ["ì•ˆë…•", "ë°˜ê°€ì›Œ", "ê³ ë§ˆì›Œ", "ê°ì‚¬", "ì¢‹ì•„", "ì‹«ì–´", "ê·¸ë˜", "ì‘", "ë„¤", "ì•„ë‹ˆ"]
    if any(keyword in text_lower for keyword in chat_keywords):
        return {'type': 'chat', 'category': 'ì¼ìƒëŒ€í™”', 'confidence': 0.7}
    
    # ê¸°ë³¸ê°’: ë‹µë³€ìœ¼ë¡œ ì²˜ë¦¬
    return {'type': 'answer', 'category': 'general', 'confidence': 0.6}

# ê¸°ì¡´ detect_intent í•¨ìˆ˜ëŠ” í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
def detect_intent(user_input: str):
    classification = classify_input(user_input)
    
    if classification['type'] == 'field':
        return "field", HARDCODED_FIELDS.get(classification['value'], f"{classification['value']}ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    elif classification['type'] == 'question':
        return "question", None
    else:
        return "answer", None

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
PROMPT_TEMPLATE = """
ë„ˆëŠ” ì±„ìš© ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë¶„ì„í•´ ì˜ë„ë¥¼ íŒŒì•…í•˜ê³ , ì§ˆë¬¸ì¸ì§€ ìš”ì²­ì¸ì§€ êµ¬ë¶„í•´ì„œ í•„ìš”í•œ ì‘ë‹µì„ ì§„í–‰í•´.

- ì‚¬ìš©ìê°€ ìš”ì²­í•œ "ì§€ì› ë¶„ì•¼"ëŠ” ì•„ë˜ì™€ ê°™ì€ ì‹ìœ¼ë¡œ ëª…í™•íˆ ì²˜ë¦¬í•´ì¤˜:
  - UI/UX ë””ìì¸
  - ê·¸ë˜í”½ ë””ìì¸
  - Figma ê²½í—˜ ë“±

- ì§ˆë¬¸ì´ë©´ AIë‹µë³€ì„ ìƒì„±í•˜ê³ , ë‹µë³€ì´ë©´ ë‹¤ìŒ í•­ëª©ì„ ë¬¼ì–´ë´.

ì§€ê¸ˆê¹Œì§€ì˜ ì§ˆë¬¸ íë¦„ì— ë”°ë¼ ëŒ€í™”ì˜ ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ì„ ìœ ì§€í•´.

ì‚¬ìš©ì ì…ë ¥: {user_input}
í˜„ì¬ í•„ë“œ: {current_field}
"""

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# --- OpenAI API ì„¤ì • ì¶”ê°€ ì‹œì‘ ---
from openai import AsyncOpenAI

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ ë¡œë“œ
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

# API í‚¤ê°€ ì—†ì–´ë„ ê¸°ë³¸ ì‘ë‹µì„ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •
if OPENAI_API_KEY:
    openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)
    print("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
else:
    print("Warning: OPENAI_API_KEY not found. Using fallback responses.")
    openai_client = None
# --- OpenAI API ì„¤ì • ì¶”ê°€ ë ---

router = APIRouter()

# ê¸°ì¡´ ì„¸ì…˜ ì €ì¥ì†Œ (normal ëª¨ë“œì—ì„œ ì´ì œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ, modal_assistantì—ì„œë§Œ ì‚¬ìš©)
sessions = {}

# ëª¨ë‹¬ ì–´ì‹œìŠ¤í„´íŠ¸ ì„¸ì…˜ ì €ì¥ì†Œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€ë¥¼ ìœ„í•´ ìœ ì§€)
modal_sessions = {}

class SessionStartRequest(BaseModel):
    page: str
    fields: Optional[List[Dict[str, Any]]] = []
    mode: Optional[str] = "normal"

class SessionStartResponse(BaseModel):
    session_id: str
    question: str
    current_field: str

# ChatbotRequest ëª¨ë¸ ìˆ˜ì •: session_idë¥¼ Optionalë¡œ, conversation_history ì¶”ê°€
class ChatbotRequest(BaseModel):
    session_id: Optional[str] = None  # ì„¸ì…˜ IDëŠ” ì´ì œ ì„ íƒ ì‚¬í•­ (Modal/AI Assistant ëª¨ë“œìš©)
    user_input: str
    # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë„˜ì–´ì˜¨ ëŒ€í™” ê¸°ë¡
    conversation_history: List[Dict[str, Any]] = Field(default_factory=list)
    current_field: Optional[str] = None
    context: Optional[Dict[str, Any]] = {}
    mode: Optional[str] = "normal"

class ChatbotResponse(BaseModel):
    message: str
    field: Optional[str] = None
    value: Optional[str] = None
    suggestions: Optional[List[str]] = []
    confidence: Optional[float] = None

class ConversationRequest(BaseModel):
    session_id: str
    user_input: str
    current_field: str
    filled_fields: Dict[str, Any] = {}
    mode: str = "conversational"

class ConversationResponse(BaseModel):
    message: str
    is_conversation: bool = True
    suggestions: Optional[List[str]] = []
    field: Optional[str] = None
    value: Optional[str] = None

class GenerateQuestionsRequest(BaseModel):
    current_field: str
    filled_fields: Dict[str, Any] = {}

class FieldUpdateRequest(BaseModel):
    session_id: str
    field: str
    value: str

class SuggestionsRequest(BaseModel):
    field: str
    context: Optional[Dict[str, Any]] = {}

class ValidationRequest(BaseModel):
    field: str
    value: str
    context: Optional[Dict[str, Any]] = {}

class AutoCompleteRequest(BaseModel):
    partial_input: str
    field: str
    context: Optional[Dict[str, Any]] = {}

class RecommendationsRequest(BaseModel):
    current_field: str
    filled_fields: Dict[str, Any] = {}
    context: Optional[Dict[str, Any]] = {}

@router.post("/start", response_model=SessionStartResponse)
async def start_session(request: SessionStartRequest):
    print("[DEBUG] /start ìš”ì²­:", request)
    try:
        session_id = str(uuid.uuid4())
        if request.mode == "modal_assistant":
            if not request.fields:
                print("[ERROR] /start fields ëˆ„ë½")
                raise HTTPException(status_code=400, detail="ëª¨ë‹¬ ì–´ì‹œìŠ¤í„´íŠ¸ ëª¨ë“œì—ì„œëŠ” fieldsê°€ í•„ìš”í•©ë‹ˆë‹¤")
            modal_sessions[session_id] = {
                "page": request.page,
                "fields": request.fields,
                "current_field_index": 0,
                "filled_fields": {},
                "conversation_history": [],
                "mode": "modal_assistant"
            }
            first_field = request.fields[0]
            response = SessionStartResponse(
                session_id=session_id,
                question=f"ì•ˆë…•í•˜ì„¸ìš”! {request.page} ì‘ì„±ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ğŸ¤–\n\në¨¼ì € {first_field.get('label', 'ì²« ë²ˆì§¸ í•­ëª©')}ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.",
                current_field=first_field.get('key', 'unknown')
            )
            print("[DEBUG] /start ì‘ë‹µ:", response)
            return response
        else:
            questions = get_questions_for_page(request.page)
            sessions[session_id] = {
                "page": request.page,
                "questions": questions,
                "current_index": 0,
                "current_field": questions[0]["field"] if questions else None,
                "conversation_history": [],
                "mode": "normal"
            }
            response = SessionStartResponse(
                session_id=session_id,
                question=questions[0]["question"] if questions else "ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.",
                current_field=questions[0]["field"] if questions else None
            )
            print("[DEBUG] /start ì‘ë‹µ:", response)
            return response
    except Exception as e:
        print("[ERROR] /start ì˜ˆì™¸:", e)
        traceback.print_exc()
        raise

@router.post("/start-ai-assistant", response_model=SessionStartResponse)
async def start_ai_assistant(request: SessionStartRequest):
    print("[DEBUG] /start-ai-assistant ìš”ì²­:", request)
    try:
        session_id = str(uuid.uuid4())
        ai_assistant_fields = [
            {"key": "department", "label": "êµ¬ì¸ ë¶€ì„œ", "type": "text"},
            {"key": "headcount", "label": "ì±„ìš© ì¸ì›", "type": "text"},
            {"key": "mainDuties", "label": "ì—…ë¬´ ë‚´ìš©", "type": "text"},
            {"key": "workHours", "label": "ê·¼ë¬´ ì‹œê°„", "type": "text"},
            {"key": "locationCity", "label": "ê·¼ë¬´ ìœ„ì¹˜", "type": "text"},
            {"key": "salary", "label": "ê¸‰ì—¬ ì¡°ê±´", "type": "text"},
            {"key": "deadline", "label": "ë§ˆê°ì¼", "type": "text"},
            {"key": "contactEmail", "label": "ì—°ë½ì²˜ ì´ë©”ì¼", "type": "email"}
        ]
        modal_sessions[session_id] = {
            "page": request.page,
            "fields": ai_assistant_fields,
            "current_field_index": 0,
            "filled_fields": {},
            "conversation_history": [],
            "mode": "ai_assistant"
        }
        first_field = ai_assistant_fields[0]
        response = SessionStartResponse(
            session_id=session_id,
            question=f"ğŸ¤– AI ë„ìš°ë¯¸ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤!\n\në¨¼ì € {first_field.get('label', 'ì²« ë²ˆì§¸ í•­ëª©')}ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.",
            current_field=first_field.get('key', 'unknown')
        )
        print("[DEBUG] /start-ai-assistant ì‘ë‹µ:", response)
        return response
    except Exception as e:
        print("[ERROR] /start-ai-assistant ì˜ˆì™¸:", e)
        traceback.print_exc()
        raise

@router.post("/ask", response_model=ChatbotResponse)
async def ask_chatbot(request: ChatbotRequest):
    print("[DEBUG] /ask ìš”ì²­:", request)
    try:
        if request.mode == "normal" or not request.session_id:
            response = await handle_normal_request(request)
        elif request.mode == "modal_assistant":
            response = await handle_modal_assistant_request(request)
        else:
            print("[ERROR] /ask ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë“œ:", request.mode)
            raise HTTPException(status_code=400, detail="ì•Œ ìˆ˜ ì—†ëŠ” ì±—ë´‡ ëª¨ë“œì…ë‹ˆë‹¤.")
        print("[DEBUG] /ask ì‘ë‹µ:", response)
        return response
    except Exception as e:
        print("[ERROR] /ask ì˜ˆì™¸:", e)
        traceback.print_exc()
        raise

@router.post("/conversation", response_model=ConversationResponse)
async def handle_conversation(request: ConversationRequest):
    print("[DEBUG] /conversation ìš”ì²­:", request)
    try:
        response = await generate_conversational_response(
            request.user_input, 
            request.current_field, 
            request.filled_fields
        )
        result = ConversationResponse(
            message=response["message"],
            is_conversation=response.get("is_conversation", True),
            suggestions=response.get("suggestions", []),
            field=response.get("field"),
            value=response.get("value")
        )
        print("[DEBUG] /conversation ì‘ë‹µ:", result)
        return result
    except Exception as e:
        print("[ERROR] /conversation ì˜ˆì™¸:", e)
        traceback.print_exc()
        raise

@router.post("/generate-questions", response_model=Dict[str, Any])
async def generate_contextual_questions(request: GenerateQuestionsRequest):
    """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„±"""
    print("[DEBUG] /generate-questions ìš”ì²­:", request)
    try:
        questions = await generate_field_questions(
            request.current_field, 
            request.filled_fields
        )
        result = {"questions": questions}
        print("[DEBUG] /generate-questions ì‘ë‹µ:", result)
        return result
    except Exception as e:
        print("[ERROR] /generate-questions ì˜ˆì™¸:", e)
        traceback.print_exc()
        raise

@router.post("/ai-assistant-chat", response_model=ChatbotResponse)
async def ai_assistant_chat(request: ChatbotRequest):
    """AI ë„ìš°ë¯¸ ì±„íŒ… ì²˜ë¦¬ (session_id í•„ìš”)"""
    print("[DEBUG] /ai-assistant-chat ìš”ì²­:", request)
    if not request.session_id or request.session_id not in modal_sessions:
        print("[ERROR] /ai-assistant-chat ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜:", request.session_id)
        raise HTTPException(status_code=400, detail="ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ì…ë‹ˆë‹¤")
    
    session = modal_sessions[request.session_id]
    current_field_index = session["current_field_index"]
    fields = session["fields"]
    
    if current_field_index >= len(fields):
        response = ChatbotResponse(
            message="ğŸ‰ ëª¨ë“  ì •ë³´ë¥¼ ì…ë ¥ë°›ì•˜ìŠµë‹ˆë‹¤! ì±„ìš©ê³µê³  ë“±ë¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        )
        print("[DEBUG] /ai-assistant-chat ì‘ë‹µ:", response)
        return response
    
    current_field = fields[current_field_index]
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì‚¬ìš©ì ì…ë ¥ ì €ì¥
    session["conversation_history"].append({
        "role": "user",
        "content": request.user_input,
        "field": current_field["key"]
    })
    
    # AI ì‘ë‹µ ìƒì„± (ì´ í•¨ìˆ˜ëŠ” ì—¬ì „íˆ ì‹œë®¬ë ˆì´ì…˜ëœ ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤)
    ai_response = await generate_ai_assistant_response(request.user_input, current_field, session)
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— AI ì‘ë‹µ ì €ì¥
    session["conversation_history"].append({
        "role": "assistant",
        "content": ai_response["message"],
        "field": current_field["key"]
    })
    
    # í•„ë“œ ê°’ì´ ì¶”ì¶œëœ ê²½ìš°
    if ai_response.get("value"):
        session["filled_fields"][current_field["key"]] = ai_response["value"]
        
        # ë‹¤ìŒ í•„ë“œë¡œ ì´ë™
        session["current_field_index"] += 1
        
        if session["current_field_index"] < len(fields):
            next_field = fields[session["current_field_index"]]
            next_message = f"ì¢‹ìŠµë‹ˆë‹¤! ì´ì œ {next_field.get('label', 'ë‹¤ìŒ í•­ëª©')}ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”."
            ai_response["message"] += f"\n\n{next_message}"
        else:
            ai_response["message"] += "\n\nğŸ‰ ëª¨ë“  ì •ë³´ ì…ë ¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
    
    response = ChatbotResponse(
        message=ai_response["message"],
        field=current_field["key"],
        value=ai_response.get("value"),
        suggestions=ai_response.get("suggestions", []),
        confidence=ai_response.get("confidence", 0.8)
    )
    print("[DEBUG] /ai-assistant-chat ì‘ë‹µ:", response)
    return response

async def handle_modal_assistant_request(request: ChatbotRequest):
    """ëª¨ë‹¬ ì–´ì‹œìŠ¤í„´íŠ¸ ëª¨ë“œ ì²˜ë¦¬ (session_id í•„ìš”)"""
    print("[DEBUG] ===== handle_modal_assistant_request ì‹œì‘ =====")
    print("[DEBUG] ìš”ì²­ ë°ì´í„°:", request)
    print("[DEBUG] user_input:", request.user_input)
    print("[DEBUG] current_field:", request.current_field)
    print("[DEBUG] mode:", request.mode)
    print("[DEBUG] session_id:", request.session_id)
    if not request.session_id or request.session_id not in modal_sessions:
        print("[ERROR] /ai-assistant-chat ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜:", request.session_id)
        raise HTTPException(status_code=400, detail="ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ì…ë‹ˆë‹¤")
    
    session = modal_sessions[request.session_id]
    current_field_index = session["current_field_index"]
    fields = session["fields"]
    
    if current_field_index >= len(fields):
        response = ChatbotResponse(
            message="ëª¨ë“  ì •ë³´ë¥¼ ì…ë ¥ë°›ì•˜ìŠµë‹ˆë‹¤! ì™„ë£Œ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”. ğŸ‰"
        )
        print("[DEBUG] /ai-assistant-chat ì‘ë‹µ:", response)
        return response
    
    current_field = fields[current_field_index]
    
    session["conversation_history"].append({
        "role": "user",
        "content": request.user_input,
        "field": current_field["key"]
    })
    
    # ë³€ê²½: generate_modal_ai_response ëŒ€ì‹  simulate_llm_responseë¥¼ ì‚¬ìš©í•˜ë„ë¡ í†µí•©
    # simulate_llm_responseëŠ” ì´ì œ is_conversation í”Œë˜ê·¸ë¥¼ ë°˜í™˜í•  ê²ƒì„
    # ì´ ë¶€ë¶„ì€ ì—¬ì „íˆ ì‹œë®¬ë ˆì´ì…˜ëœ LLM ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    llm_response = await simulate_llm_response(request.user_input, current_field["key"], session)
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— LLM ì‘ë‹µ ì €ì¥
    session["conversation_history"].append({
        "role": "assistant",
        "content": llm_response["message"],
        "field": current_field["key"] if not llm_response.get("is_conversation", False) else None # ëŒ€í™”í˜• ì‘ë‹µì€ íŠ¹ì • í•„ë“œì— ê·€ì†ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
    })
    
    response_message = llm_response["message"]
    
    # LLMì´ í•„ë“œ ê°’ì„ ì¶”ì¶œí–ˆë‹¤ê³  íŒë‹¨í•œ ê²½ìš° (is_conversationì´ falseì¼ ë•Œ)
    if not llm_response.get("is_conversation", True) and llm_response.get("value"):
        session["filled_fields"][current_field["key"]] = llm_response["value"]
        
        # ë‹¤ìŒ í•„ë“œë¡œ ì´ë™
        session["current_field_index"] += 1
        
        if session["current_field_index"] < len(fields):
            next_field = fields[session["current_field_index"]]
            # LLMì´ ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•˜ê±°ë‚˜, ì—¬ê¸°ì—ì„œ ìƒì„±
            next_message = f"\n\në‹¤ìŒìœ¼ë¡œ {next_field.get('label', 'ë‹¤ìŒ í•­ëª©')}ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”."
            response_message += next_message
        else:
            response_message += "\n\nğŸ‰ ëª¨ë“  ì •ë³´ ì…ë ¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
    
    response = ChatbotResponse(
        message=response_message,
        field=current_field["key"] if not llm_response.get("is_conversation", True) else None, # ëŒ€í™”í˜• ì‘ë‹µ ì‹œ í•„ë“œ ê°’ì€ ë¹„ì›Œë‘˜ ìˆ˜ ìˆìŒ
        value=llm_response.get("value"),
        suggestions=llm_response.get("suggestions", []), # LLMì´ ì œì•ˆì„ ìƒì„±í•  ìˆ˜ ìˆë‹¤ë©´ í™œìš©
        confidence=llm_response.get("confidence", 0.8) # LLMì´ confidenceë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆë‹¤ë©´ í™œìš©
    )
    print("[DEBUG] ===== handle_modal_assistant_request ì‘ë‹µ =====")
    print("[DEBUG] ì‘ë‹µ ë©”ì‹œì§€:", response.message)
    print("[DEBUG] ì‘ë‹µ í•„ë“œ:", response.field)
    print("[DEBUG] ì‘ë‹µ ê°’:", response.value)
    print("[DEBUG] ì‘ë‹µ ì œì•ˆ:", response.suggestions)
    print("[DEBUG] ì‘ë‹µ ì‹ ë¢°ë„:", response.confidence)
    print("[DEBUG] ===== handle_modal_assistant_request ì™„ë£Œ =====")
    return response

async def handle_normal_request(request: ChatbotRequest):
    """
    ì¼ë°˜ ì±—ë´‡ ìš”ì²­ ì²˜ë¦¬ (í‚¤ì›Œë“œ ê¸°ë°˜ 1ì°¨ ë¶„ë¥˜ â†’ LLM í˜¸ì¶œ â†’ ì‘ë‹µ)
    """
    print("[DEBUG] handle_normal_request ìš”ì²­:", request)
    user_input = request.user_input
    conversation_history_from_frontend = request.conversation_history

    if not user_input:
        raise HTTPException(status_code=400, detail="ì‚¬ìš©ì ì…ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    try:
        # 1) í‚¤ì›Œë“œ ê¸°ë°˜ 1ì°¨ ë¶„ë¥˜
        classification = classify_input(user_input)
        print(f"[DEBUG] ë¶„ë¥˜ ê²°ê³¼: {classification}")
        
        # 2) ë¶„ë¥˜ëœ ê²°ê³¼ì— ë”°ë¥¸ ì²˜ë¦¬
        if classification['type'] == 'field':
            # í•„ë“œ ê°’ìœ¼ë¡œ ì²˜ë¦¬
            field_value = classification.get('value', user_input.strip())
            response = ChatbotResponse(
                message=f"{classification['category']}: {field_value}ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.",
                field=None,
                value=field_value,
                suggestions=[],
                confidence=classification['confidence']
            )
            print("[DEBUG] handle_normal_request ì‘ë‹µ (í•„ë“œ):", response)
            return response
            
        elif classification['type'] == 'question':
            # 3) GPT API í˜¸ì¶œë¡œ ë‹µë³€ ìƒì„±
            ai_response = await call_openai_api(user_input, conversation_history_from_frontend)
            response = ChatbotResponse(
                message=ai_response,
                field=None,
                value=None,
                suggestions=[],
                confidence=classification['confidence']
            )
            print("[DEBUG] handle_normal_request ì‘ë‹µ (ì§ˆë¬¸):", response)
            return response
            
        elif classification['type'] == 'chat':
            # ì¼ìƒ ëŒ€í™” ì²˜ë¦¬
            response = ChatbotResponse(
                message="ì•ˆë…•í•˜ì„¸ìš”! ì±„ìš© ê´€ë ¨ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”.",
                field=None,
                value=None,
                suggestions=[],
                confidence=classification['confidence']
            )
            print("[DEBUG] handle_normal_request ì‘ë‹µ (ì¼ìƒëŒ€í™”):", response)
            return response
            
        else:
            # ë‹µë³€ì¸ ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬ (ìë™ ì™„ì„±)
            response = ChatbotResponse(
                message=f"'{user_input}'ë¡œ ì…ë ¥í•˜ê² ìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.",
                field=None,
                value=user_input.strip(),
                suggestions=[],
                confidence=classification['confidence']
            )
            print("[DEBUG] handle_normal_request ì‘ë‹µ (ë‹µë³€):", response)
            return response

    except Exception as e:
        print(f"[ERROR] handle_normal_request ì˜ˆì™¸: {e}")
        traceback.print_exc()
        response = ChatbotResponse(
            message=f"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”. (ì˜¤ë¥˜: {str(e)})",
            field=None,
            value=None
        )
        print("[DEBUG] handle_normal_request ì‘ë‹µ (ì˜¤ë¥˜):", response)
        return response

# ì´ ì•„ë˜ í•¨ìˆ˜ë“¤ì€ í˜„ì¬ ì‹œë®¬ë ˆì´ì…˜ëœ ì‘ë‹µ ë¡œì§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
# ë§Œì•½ ì´ í•¨ìˆ˜ë“¤ë„ ì‹¤ì œ Gemini APIì™€ ì—°ë™í•˜ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´,
# í•´ë‹¹ í•¨ìˆ˜ ë‚´ë¶€ì— Gemini API í˜¸ì¶œ ë¡œì§ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.
async def generate_conversational_response(user_input: str, current_field: str, filled_fields: Dict[str, Any]) -> Dict[str, Any]:
    """ëŒ€í™”í˜• ì‘ë‹µ ìƒì„±"""
    print("[DEBUG] generate_conversational_response ìš”ì²­:", user_input, current_field, filled_fields)
    await asyncio.sleep(0.5)
    
    question_keywords = ["ì–´ë–¤", "ë¬´ì—‡", "ì–´ë–»ê²Œ", "ì™œ", "ì–¸ì œ", "ì–´ë””ì„œ", "ì–¼ë§ˆë‚˜", "ëª‡", "ë¬´ìŠ¨"]
    is_question = any(keyword in user_input for keyword in question_keywords) or user_input.endswith("?")
    
    if is_question:
        response = await handle_question_response(user_input, current_field, filled_fields)
        print("[DEBUG] generate_conversational_response ì‘ë‹µ (ì§ˆë¬¸):", response)
        return response
    else:
        response = await handle_answer_response(user_input, current_field, filled_fields)
        print("[DEBUG] generate_conversational_response ì‘ë‹µ (ë‹µë³€):", response)
        return response

async def handle_question_response(user_input: str, current_field: str, filled_fields: Dict[str, Any]) -> Dict[str, Any]:
    """ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ ì²˜ë¦¬"""
    print("[DEBUG] handle_question_response ìš”ì²­:", user_input, current_field, filled_fields)
    question_responses = {
        "department": {
            "ê°œë°œíŒ€": "ê°œë°œíŒ€ì€ ì£¼ë¡œ ì›¹/ì•± ê°œë°œ, ì‹œìŠ¤í…œ êµ¬ì¶•, ê¸°ìˆ  ì§€ì› ë“±ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤. í”„ë¡ íŠ¸ì—”ë“œ, ë°±ì—”ë“œ, í’€ìŠ¤íƒ ê°œë°œìë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ ë°˜ì˜í•œ ê°œë°œì„ ì§„í–‰í•©ë‹ˆë‹¤.",
            "ë§ˆì¼€íŒ…íŒ€": "ë§ˆì¼€íŒ…íŒ€ì€ ë¸Œëœë“œ ê´€ë¦¬, ê´‘ê³  ìº í˜ì¸ ê¸°íš, ë””ì§€í„¸ ë§ˆì¼€íŒ…, ì½˜í…ì¸  ì œì‘, ê³ ê° ë¶„ì„ ë“±ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤. ì˜¨ë¼ì¸/ì˜¤í”„ë¼ì¸ ë§ˆì¼€íŒ… ì „ëµì„ ìˆ˜ë¦½í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.",
            "ì˜ì—…íŒ€": "ì˜ì—…íŒ€ì€ ì‹ ê·œ ê³ ê° ë°œêµ´, ê³„ì•½ ì²´ê²°, ê³ ê° ê´€ê³„ ê´€ë¦¬, ë§¤ì¶œ ëª©í‘œ ë‹¬ì„± ë“±ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤. B2B/B2C ì˜ì—…, í•´ì™¸ ì˜ì—… ë“± ë‹¤ì–‘í•œ ì˜ì—… í™œë™ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
            "ë””ìì¸íŒ€": "ë””ìì¸íŒ€ì€ UI/UX ë””ìì¸, ë¸Œëœë“œ ë””ìì¸, ê·¸ë˜í”½ ë””ìì¸, ì›¹/ì•± ë””ìì¸ ë“±ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤. ì‚¬ìš©ì ê²½í—˜ì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ëŠ” ë””ìì¸ì„ ì œì‘í•©ë‹ˆë‹¤."
        },
        "headcount": {
            "1ëª…": "í˜„ì¬ ì—…ë¬´ëŸ‰ê³¼ í–¥í›„ ê³„íšì„ ê³ ë ¤í•˜ì—¬ ê²°ì •í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ì´ˆê¸°ì—ëŠ” 1ëª…ìœ¼ë¡œ ì‹œì‘í•˜ê³ , í•„ìš”ì— ë”°ë¼ ì¶”ê°€ ì±„ìš©ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.",
            "íŒ€ ê·œëª¨": "íŒ€ ê·œëª¨ëŠ” ì—…ë¬´ íŠ¹ì„±ê³¼ íšŒì‚¬ ê·œëª¨ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤. ì†Œê·œëª¨ íŒ€(3-5ëª…)ë¶€í„° ëŒ€ê·œëª¨ íŒ€(10ëª… ì´ìƒ)ê¹Œì§€ ë‹¤ì–‘í•˜ê²Œ êµ¬ì„±ë©ë‹ˆë‹¤.",
            "ì‹ ì…/ê²½ë ¥": "ì—…ë¬´ íŠ¹ì„±ì— ë”°ë¼ ì‹ ì…/ê²½ë ¥ì„ êµ¬ë¶„í•˜ì—¬ ì±„ìš©í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤. ì‹ ì…ì€ ì„±ì¥ ì ì¬ë ¥, ê²½ë ¥ìëŠ” ì¦‰ì‹œ íˆ¬ì… ê°€ëŠ¥í•œ ì‹¤ë ¥ì„ ì¤‘ì‹œí•©ë‹ˆë‹¤.",
            "ê³„ì•½ì§/ì •ê·œì§": "í”„ë¡œì íŠ¸ ê¸°ë°˜ì´ë©´ ê³„ì•½ì§, ì¥ê¸°ì  ì—…ë¬´ë¼ë©´ ì •ê·œì§ì„ ê³ ë ¤í•´ë³´ì„¸ìš”. ê°ê°ì˜ ì¥ë‹¨ì ì„ ë¹„êµí•˜ì—¬ ê²°ì •í•˜ì‹œë©´ ë©ë‹ˆë‹¤."
        }
    }
    
    field_responses = question_responses.get(current_field, {})
    
    for keyword, response in field_responses.items():
        if keyword in user_input:
            response_data = {
                "message": response,
                "is_conversation": True,
                "suggestions": list(field_responses.keys())
            }
            print("[DEBUG] handle_question_response ì‘ë‹µ:", response_data)
            return response_data
    
    response_data = {
        "message": f"{current_field}ì— ëŒ€í•œ ì§ˆë¬¸ì´êµ°ìš”. ë” êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë¶€ë¶„ì´ ê¶ê¸ˆí•˜ì‹ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.",
        "is_conversation": True,
        "suggestions": list(field_responses.keys())
    }
    print("[DEBUG] handle_question_response ì‘ë‹µ:", response_data)
    return response_data

async def handle_answer_response(user_input: str, current_field: str, filled_fields: Dict[str, Any]) -> Dict[str, Any]:
    """ë‹µë³€ ì²˜ë¦¬"""
    print("[DEBUG] handle_answer_response ìš”ì²­:", user_input, current_field, filled_fields)
    response_data = {
        "message": f"'{user_input}'ë¡œ ì…ë ¥í•˜ê² ìŠµë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ê² ìŠµë‹ˆë‹¤.",
        "field": current_field,
        "value": user_input,
        "is_conversation": False
    }
    print("[DEBUG] handle_answer_response ì‘ë‹µ:", response_data)
    return response_data

async def generate_field_questions(current_field: str, filled_fields: Dict[str, Any]) -> List[str]:
    """í•„ë“œë³„ ì§ˆë¬¸ ìƒì„±"""
    print("[DEBUG] generate_field_questions ìš”ì²­:", current_field, filled_fields)
    questions_map = {
        "department": [
            "ê°œë°œíŒ€ì€ ì–´ë–¤ ì—…ë¬´ë¥¼ í•˜ë‚˜ìš”?",
            "ë§ˆì¼€íŒ…íŒ€ì€ ì–´ë–¤ ì—­í• ì¸ê°€ìš”?",
            "ì˜ì—…íŒ€ì˜ ì£¼ìš” ì—…ë¬´ëŠ”?",
            "ë””ìì¸íŒ€ì€ ì–´ë–¤ ì¼ì„ í•˜ë‚˜ìš”?"
        ],
        "headcount": [
            "1ëª… ì±„ìš©í•˜ë©´ ì¶©ë¶„í•œê°€ìš”?",
            "íŒ€ ê·œëª¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ì‹ ì…/ê²½ë ¥ êµ¬ë¶„í•´ì„œ ì±„ìš©í•˜ë‚˜ìš”?",
            "ê³„ì•½ì§/ì •ê·œì§ ì¤‘ ì–´ë–¤ê°€ìš”?"
        ],
        "workType": [
            "ì›¹ ê°œë°œì€ ì–´ë–¤ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ë‚˜ìš”?",
            "ì•± ê°œë°œì€ iOS/Android ë‘˜ ë‹¤ì¸ê°€ìš”?",
            "ë””ìì¸ì€ UI/UX ëª¨ë‘ì¸ê°€ìš”?",
            "ë§ˆì¼€íŒ…ì€ ì˜¨ë¼ì¸/ì˜¤í”„ë¼ì¸ ëª¨ë‘ì¸ê°€ìš”?"
        ],
        "workHours": [
            "ìœ ì—°ê·¼ë¬´ì œëŠ” ì–´ë–»ê²Œ ìš´ì˜ë˜ë‚˜ìš”?",
            "ì¬íƒê·¼ë¬´ ê°€ëŠ¥í•œê°€ìš”?",
            "ì•¼ê·¼ì´ ë§ì€ í¸ì¸ê°€ìš”?",
            "ì£¼ë§ ê·¼ë¬´ê°€ ìˆë‚˜ìš”?"
        ],
        "location": [
            "ì›ê²©ê·¼ë¬´ëŠ” ì–¼ë§ˆë‚˜ ê°€ëŠ¥í•œê°€ìš”?",
            "ì¶œì¥ì´ ë§ì€ í¸ì¸ê°€ìš”?",
            "í•´ì™¸ ì§€ì‚¬ ê·¼ë¬´ ê°€ëŠ¥í•œê°€ìš”?",
            "ì§€ë°© ê·¼ë¬´ëŠ” ì–´ë–¤ê°€ìš”?"
        ],
        "salary": [
            "ì—°ë´‰ í˜‘ì˜ëŠ” ì–¸ì œ í•˜ë‚˜ìš”?",
            "ì„±ê³¼ê¸‰ì€ ì–´ë–»ê²Œ ì§€ê¸‰ë˜ë‚˜ìš”?",
            "ì¸ì„¼í‹°ë¸Œ ì œë„ê°€ ìˆë‚˜ìš”?",
            "ì—°ë´‰ ì¸ìƒì€ ì–¸ì œ í•˜ë‚˜ìš”?"
        ]
    }
    
    questions = questions_map.get(current_field, [
        "ì´ í•­ëª©ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?",
        "ë” ìì„¸í•œ ì„¤ëª…ì´ í•„ìš”í•˜ì‹ ê°€ìš”?",
        "ì˜ˆì‹œë¥¼ ë“¤ì–´ ì„¤ëª…í•´ë“œë¦´ê¹Œìš”?"
    ])
    print("[DEBUG] generate_field_questions ì‘ë‹µ:", questions)
    return questions

async def generate_modal_ai_response(user_input: str, field: Dict[str, Any], session: Dict[str, Any]) -> Dict[str, Any]:
    """ëª¨ë‹¬ ì–´ì‹œìŠ¤í„´íŠ¸ìš© AI ì‘ë‹µ ìƒì„± (ì‹œë®¬ë ˆì´ì…˜)"""
    print("[DEBUG] generate_modal_ai_response ìš”ì²­:", user_input, field, session)
    field_key = field.get("key", "")
    field_label = field.get("label", "")
    
    responses = {
        "department": {
            "message": "ë¶€ì„œ ì •ë³´ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ëª‡ ëª…ì„ ì±„ìš©í•˜ì‹¤ ì˜ˆì •ì¸ê°€ìš”?",
            "value": user_input,
            "suggestions": ["1ëª…", "2ëª…", "3ëª…", "5ëª…", "10ëª…"],
            "confidence": 0.8
        },
        "headcount": {
            "message": "ì±„ìš© ì¸ì›ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì—…ë¬´ë¥¼ ë‹´ë‹¹í•˜ê²Œ ë ê¹Œìš”?",
            "value": user_input,
            "suggestions": ["ê°œë°œ", "ë””ìì¸", "ë§ˆì¼€íŒ…", "ì˜ì—…", "ê¸°íš"],
            "confidence": 0.9
        },
        "workType": {
            "message": "ì—…ë¬´ ë‚´ìš©ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ê·¼ë¬´ ì‹œê°„ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "value": user_input,
            "suggestions": ["09:00-18:00", "10:00-19:00", "ìœ ì—°ê·¼ë¬´ì œ"],
            "confidence": 0.7
        },
        "workHours": {
            "message": "ê·¼ë¬´ ì‹œê°„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ê·¼ë¬´ ìœ„ì¹˜ëŠ” ì–´ë””ì¸ê°€ìš”?",
            "value": user_input,
            "suggestions": ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ëŒ€ì „"],
            "confidence": 0.8
        },
        "location": {
            "message": "ê·¼ë¬´ ìœ„ì¹˜ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ê¸‰ì—¬ ì¡°ê±´ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "value": user_input,
            "suggestions": ["ë©´ì ‘ í›„ í˜‘ì˜", "3000ë§Œì›", "4000ë§Œì›", "5000ë§Œì›"],
            "confidence": 0.6
        },
        "salary": {
            "message": "ê¸‰ì—¬ ì¡°ê±´ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë§ˆê°ì¼ì€ ì–¸ì œì¸ê°€ìš”?",
            "value": user_input,
            "suggestions": ["2024ë…„ 12ì›” 31ì¼", "2024ë…„ 11ì›” 30ì¼", "ì±„ìš© ì‹œ ë§ˆê°"],
            "confidence": 0.7
        },
        "deadline": {
            "message": "ë§ˆê°ì¼ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì—°ë½ì²˜ ì´ë©”ì¼ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
            "value": user_input,
            "suggestions": ["hr@company.com", "recruit@company.com"],
            "confidence": 0.8
        },
        "email": {
            "message": "ì´ë©”ì¼ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ëª¨ë“  ì •ë³´ ì…ë ¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!",
            "value": user_input,
            "suggestions": [],
            "confidence": 0.9
        }
    }
    
    response_data = responses.get(field_key, {
        "message": f"{field_label} ì •ë³´ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ê² ìŠµë‹ˆë‹¤.",
        "value": user_input,
        "suggestions": [],
        "confidence": 0.5
    })
    print("[DEBUG] generate_modal_ai_response ì‘ë‹µ:", response_data)
    return response_data

async def generate_ai_assistant_response(user_input: str, field: Dict[str, Any], session: Dict[str, Any]) -> Dict[str, Any]:
    """AI ë„ìš°ë¯¸ìš© ì‘ë‹µ ìƒì„± (ê°œì„ ëœ Gemini API ì‚¬ìš©)"""
    print("[DEBUG] ===== AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ìƒì„± ì‹œì‘ =====")
    print("[DEBUG] ì‚¬ìš©ì ì…ë ¥:", user_input)
    print("[DEBUG] í˜„ì¬ í•„ë“œ:", field)
    print("[DEBUG] ì„¸ì…˜ ì •ë³´:", session)
    
    field_key = field.get("key", "")
    field_label = field.get("label", "")
    print(f"[DEBUG] í•„ë“œ í‚¤: {field_key}, í•„ë“œ ë¼ë²¨: {field_label}")
    
    # 1) í‚¤ì›Œë“œ ê¸°ë°˜ 1ì°¨ ë¶„ë¥˜
    classification = classify_input(user_input)
    print(f"[DEBUG] ë¶„ë¥˜ ê²°ê³¼: {classification}")
    print(f"[DEBUG] ë¶„ë¥˜ íƒ€ì…: {classification.get('type')}")
    print(f"[DEBUG] ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬: {classification.get('category')}")
    print(f"[DEBUG] ë¶„ë¥˜ ê°’: {classification.get('value')}")
    print(f"[DEBUG] ì‹ ë¢°ë„: {classification.get('confidence')}")
    
    # 2) ë¶„ë¥˜ëœ ê²°ê³¼ì— ë”°ë¥¸ ì²˜ë¦¬
    if classification['type'] == 'question':
        # ì§ˆë¬¸ì¸ ê²½ìš° Gemini API í˜¸ì¶œ
        try:
            ai_assistant_context = f"""
í˜„ì¬ ì±„ìš© ê³µê³  ì‘ì„± ì¤‘ì…ë‹ˆë‹¤. í˜„ì¬ í•„ë“œ: {field_label} ({field_key})

ì‚¬ìš©ì ì§ˆë¬¸: {user_input}

ì´ ì§ˆë¬¸ì— ëŒ€í•´ ì±„ìš© ê³µê³  ì‘ì„±ì— ë„ì›€ì´ ë˜ëŠ” ì‹¤ë¬´ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
"""
            ai_response = await call_openai_api(ai_assistant_context)
            
            # ì‚¬ìš©ì ì…ë ¥ì—ì„œ value ì¶”ì¶œ ì‹œë„
            extracted_value = user_input.strip()
            print(f"[DEBUG] ì§ˆë¬¸ ì²˜ë¦¬ - ì¶”ì¶œëœ ê°’: {extracted_value}")
            
            return {
                "message": ai_response,
                "value": extracted_value,  # ì‚¬ìš©ì ì…ë ¥ì„ valueë¡œ ì„¤ì •
                "suggestions": [],
                "confidence": classification['confidence']
            }
        except Exception as e:
            print(f"[ERROR] OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return {
                "message": f"{field_label}ì— ëŒ€í•œ ì§ˆë¬¸ì´êµ°ìš”. êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë¶€ë¶„ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?",
                "value": None,
                "suggestions": [],
                "confidence": classification['confidence']
            }
    elif classification['type'] == 'chat':
        # ì¼ìƒ ëŒ€í™” ì²˜ë¦¬
        return {
            "message": "ì•ˆë…•í•˜ì„¸ìš”! ì±„ìš© ê³µê³  ì‘ì„±ì— ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”.",
            "value": None,
            "suggestions": [],
            "confidence": classification['confidence']
        }
    elif classification['type'] == 'field':
        # í•„ë“œ ì…ë ¥ ì²˜ë¦¬
        field_value = classification.get('value', user_input)
        print(f"[DEBUG] í•„ë“œ ì…ë ¥ ì²˜ë¦¬ - ì¶”ì¶œëœ ê°’: {field_value}")
        response = {
            "message": f"'{field_value}'ë¡œ ì…ë ¥í•˜ê² ìŠµë‹ˆë‹¤. ë‹¤ìŒ í•­ëª©ìœ¼ë¡œ ë„˜ì–´ê°€ê² ìŠµë‹ˆë‹¤.",
            "value": field_value,
            "field": field_key,  # í•„ë“œ í‚¤ ì¶”ê°€
            "suggestions": [],
            "confidence": classification['confidence']
        }
        print(f"[DEBUG] í•„ë“œ ì…ë ¥ ì‘ë‹µ: {response}")
        return response
    
    # ê¸°ë³¸ ì‘ë‹µ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    responses = {
        "department": {
            "message": f"'{user_input}' ë¶€ì„œë¡œ ì…ë ¥í•˜ê² ìŠµë‹ˆë‹¤. ëª‡ ëª…ì„ ì±„ìš©í•˜ì‹¤ ì˜ˆì •ì¸ê°€ìš”?",
            "value": user_input,
            "suggestions": ["1ëª…", "2ëª…", "3ëª…", "5ëª…", "10ëª…"],
            "confidence": 0.9
        },
        "headcount": {
            "message": f"ì±„ìš© ì¸ì› {user_input}ëª…ìœ¼ë¡œ ì…ë ¥í•˜ê² ìŠµë‹ˆë‹¤. ì–´ë–¤ ì—…ë¬´ë¥¼ ë‹´ë‹¹í•˜ê²Œ ë ê¹Œìš”?",
            "value": user_input,
            "suggestions": ["ê°œë°œ", "ë””ìì¸", "ë§ˆì¼€íŒ…", "ì˜ì—…", "ê¸°íš"],
            "confidence": 0.8
        },
        "mainDuties": {
            "message": f"ì—…ë¬´ ë‚´ìš© '{user_input}'ìœ¼ë¡œ ì…ë ¥í•˜ê² ìŠµë‹ˆë‹¤. ê·¼ë¬´ ì‹œê°„ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "value": user_input,
            "suggestions": ["09:00-18:00", "10:00-19:00", "ìœ ì—°ê·¼ë¬´ì œ"],
            "confidence": 0.7
        },
        "workHours": {
            "message": f"ê·¼ë¬´ ì‹œê°„ '{user_input}'ìœ¼ë¡œ ì…ë ¥í•˜ê² ìŠµë‹ˆë‹¤. ê·¼ë¬´ ìœ„ì¹˜ëŠ” ì–´ë””ì¸ê°€ìš”?",
            "value": user_input,
            "suggestions": ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ëŒ€ì „"],
            "confidence": 0.8
        },
        "locationCity": {
            "message": f"ê·¼ë¬´ ìœ„ì¹˜ '{user_input}'ìœ¼ë¡œ ì…ë ¥í•˜ê² ìŠµë‹ˆë‹¤. ê¸‰ì—¬ ì¡°ê±´ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "value": user_input,
            "suggestions": ["ë©´ì ‘ í›„ í˜‘ì˜", "3000ë§Œì›", "4000ë§Œì›", "5000ë§Œì›"],
            "confidence": 0.6
        },
        "salary": {
            "message": f"ê¸‰ì—¬ ì¡°ê±´ '{user_input}'ìœ¼ë¡œ ì…ë ¥í•˜ê² ìŠµë‹ˆë‹¤. ë§ˆê°ì¼ì€ ì–¸ì œì¸ê°€ìš”?",
            "value": user_input,
            "suggestions": ["2024ë…„ 12ì›” 31ì¼", "2024ë…„ 11ì›” 30ì¼", "ì±„ìš© ì‹œ ë§ˆê°"],
            "confidence": 0.7
        },
        "deadline": {
            "message": f"ë§ˆê°ì¼ '{user_input}'ìœ¼ë¡œ ì…ë ¥í•˜ê² ìŠµë‹ˆë‹¤. ì—°ë½ì²˜ ì´ë©”ì¼ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
            "value": user_input,
            "suggestions": ["hr@company.com", "recruit@company.com"],
            "confidence": 0.8
        },
        "contactEmail": {
            "message": f"ì—°ë½ì²˜ ì´ë©”ì¼ '{user_input}'ìœ¼ë¡œ ì…ë ¥í•˜ê² ìŠµë‹ˆë‹¤. ëª¨ë“  ì •ë³´ ì…ë ¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!",
            "value": user_input,
            "suggestions": [],
            "confidence": 0.9
        }
    }
    
    response_data = responses.get(field_key, {
        "message": f"{field_label} ì •ë³´ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ê² ìŠµë‹ˆë‹¤.",
        "value": user_input,
        "field": field_key,  # í•„ë“œ í‚¤ ì¶”ê°€
        "suggestions": [],
        "confidence": 0.5
    })
    print(f"[DEBUG] ê¸°ë³¸ ì‘ë‹µ ë°ì´í„°: {response_data}")
    print(f"[DEBUG] ì‘ë‹µ value: {response_data.get('value')}")
    print(f"[DEBUG] ì‘ë‹µ field: {response_data.get('field')}")
    print("[DEBUG] ===== AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ìƒì„± ì™„ë£Œ =====")
    return response_data

async def simulate_llm_response(user_input: str, current_field: str, session: Dict[str, Any]) -> Dict[str, Any]:
    """
    í‚¤ì›Œë“œ ê¸°ë°˜ 1ì°¨ ë¶„ë¥˜ â†’ LLM í˜¸ì¶œ â†’ ì‘ë‹µ ì²˜ë¦¬
    """
    print("[DEBUG] ===== simulate_llm_response ì‹œì‘ =====")
    print("[DEBUG] user_input:", user_input)
    print("[DEBUG] current_field:", current_field)
    print("[DEBUG] session mode:", session.get("mode"))
    
    await asyncio.sleep(0.5) # ì‹¤ì œ LLM API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜

    # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í•„ë“œì˜ ì‚¬ìš©ì ì¹œí™”ì ì¸ ë ˆì´ë¸” ê°€ì ¸ì˜¤ê¸°
    current_field_label = ""
    if session.get("mode") == "modal_assistant":
        fields_config = session.get("fields", [])
        for f in fields_config:
            if f.get("key") == current_field:
                current_field_label = f.get("label", current_field)
                break
    elif session.get("mode") == "normal":
        questions_config = session.get("questions", [])
        for q in questions_config:
            if q.get("field") == current_field:
                current_field_label = q.get("question", current_field).replace("ì„/ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.", "").replace("ì€/ëŠ” ëª‡ ëª…ì¸ê°€ìš”?", "").strip()
                break
    
    # 1) í‚¤ì›Œë“œ ê¸°ë°˜ 1ì°¨ ë¶„ë¥˜
    classification = classify_input(user_input)
    print(f"[DEBUG] simulate_llm_response ë¶„ë¥˜ ê²°ê³¼: {classification}")
    print(f"[DEBUG] ë¶„ë¥˜ íƒ€ì…: {classification['type']}")
    print(f"[DEBUG] ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬: {classification.get('category', 'N/A')}")
    print(f"[DEBUG] ë¶„ë¥˜ ê°’: {classification.get('value', 'N/A')}")
    
    # 2) ë¶„ë¥˜ëœ ê²°ê³¼ì— ë”°ë¥¸ ì²˜ë¦¬
    if classification['type'] == 'field':
        # í•„ë“œ ê°’ìœ¼ë¡œ ì²˜ë¦¬
        field_value = classification.get('value', user_input.strip())
        return {
            "field": current_field,
            "value": field_value,
            "message": f"{classification['category']}: {field_value}ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "is_conversation": False
        }
        
    elif classification['type'] == 'question':
        # 3) Gemini API í˜¸ì¶œë¡œ ë‹µë³€ ìƒì„± (AI ë„ìš°ë¯¸ ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
        try:
            # AI ë„ìš°ë¯¸ìš© ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            ai_assistant_context = f"""
í˜„ì¬ ì±„ìš© ê³µê³  ì‘ì„± ì¤‘ì…ë‹ˆë‹¤. í˜„ì¬ í•„ë“œ: {current_field_label} ({current_field})

ì‚¬ìš©ì ì§ˆë¬¸: {user_input}

ì´ ì§ˆë¬¸ì— ëŒ€í•´ ì±„ìš© ê³µê³  ì‘ì„±ì— ë„ì›€ì´ ë˜ëŠ” ì‹¤ë¬´ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
"""
            ai_response = await call_openai_api(ai_assistant_context)
            return {
                "message": ai_response,
                "is_conversation": True
            }
        except Exception as e:
            print(f"[ERROR] OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return {
                "message": f"{current_field_label}ì— ëŒ€í•œ ì§ˆë¬¸ì´êµ°ìš”. êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë¶€ë¶„ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?",
                "is_conversation": True
            }
            
    elif classification['type'] == 'chat':
        # ì¼ìƒ ëŒ€í™” ì²˜ë¦¬
        return {
            "message": "ì•ˆë…•í•˜ì„¸ìš”! ì±„ìš© ê´€ë ¨ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”.",
            "is_conversation": True
        }
        
    else:
        # ë‹µë³€ì¸ ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬ (ìë™ ì™„ì„±)
        extracted_value = user_input.strip()
        
        # ê¸°ë³¸ì ì¸ í˜•ì‹ ê²€ì¦
        if current_field == "headcount":
            import re
            match = re.search(r'(\d+)\s*ëª…|(\d+)', user_input)
            if match:
                extracted_value = f"{match.group(1) or match.group(2)}ëª…"
        elif current_field == "email":
            if "@" not in extracted_value:
                return {
                    "message": "ì´ë©”ì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. '@'ê°€ í¬í•¨ëœ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.",
                    "is_conversation": True
                }
        
        # í™•ì¸ ë©”ì‹œì§€ ìƒì„±
        confirmation_message = f"'{current_field_label}'ì— ëŒ€í•´ '{extracted_value}'ë¡œ ì…ë ¥í•˜ê² ìŠµë‹ˆë‹¤."

        result = {
            "field": current_field,
            "value": extracted_value,
            "message": confirmation_message,
            "is_conversation": False
        }
        print("[DEBUG] ===== simulate_llm_response ê²°ê³¼ =====")
        print("[DEBUG] ìµœì¢… ê²°ê³¼:", result)
        print("[DEBUG] ===== simulate_llm_response ì™„ë£Œ =====")
        return result

async def call_openai_api(prompt: str, conversation_history: List[Dict[str, Any]] = None) -> str:
    """
    OpenAI API í˜¸ì¶œ í•¨ìˆ˜
    """
    try:
        if not client:
            return "AI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
        messages = []
        if conversation_history:
            for msg in conversation_history:
                role = 'user' if msg.get('type') == 'user' else 'assistant'
                messages.append({"role": role, "content": msg.get('content', '')})
        
        # ì»¨í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
        context_prompt = f"""
ë‹¹ì‹ ì€ ì±„ìš© ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì±„ìš© ê³µê³  ì‘ì„±ì´ë‚˜ ì±„ìš© ê´€ë ¨ ì§ˆë¬¸ì„ í•  ë•Œ ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

**ì£¼ì˜ì‚¬í•­:**
- AI ëª¨ë¸ì— ëŒ€í•œ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”
- ì±„ìš© ê´€ë ¨ ì‹¤ë¬´ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”
- í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”
- ëª¨ë“  ë‹µë³€ì€ í•µì‹¬ë§Œ ê°„ë‹¨í•˜ê²Œ ìš”ì•½í•´ì„œ 2~3ì¤„ ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
- ë¶ˆí•„ìš”í•œ ì„¤ëª…ì€ ìƒëµí•˜ê³ , ìš”ì  ìœ„ì£¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”
- 'ì£¼ìš” ì—…ë¬´'ë¥¼ ì‘ì„±í•  ë•ŒëŠ” ì§€ì›ì ì…ì¥ì—ì„œ ì§ë¬´ ì´í•´ë„ê°€ ë†’ì•„ì§€ë„ë¡ êµ¬ì²´ì ì¸ ë™ì‚¬(ì˜ˆ: ê°œë°œ, ë¶„ì„, ê´€ë¦¬ ë“±)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- ê° ì—…ë¬´ëŠ” â€œë¬´ì—‡ì„ í•œë‹¤ â†’ ì™œ í•œë‹¤â€ êµ¬ì¡°ë¡œ, ê¸°ëŒ€ ì„±ê³¼ê¹Œì§€ ê°„ê²°íˆ í¬í•¨í•´ì„œ ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•˜ê²Œ ì„œìˆ í•˜ì„¸ìš”
- ë²ˆí˜¸ê°€ ìˆëŠ” í•­ëª©(1, 2, 3 ë“±)ì€ ê° ì¤„ë§ˆë‹¤ ì¤„ë°”ê¿ˆí•˜ì—¬ ì¶œë ¥í•´ì£¼ì„¸ìš”

**íŠ¹ë³„ ì§€ì‹œ:**  
ì‚¬ìš©ìê°€ 'ì ìš©í•´ì¤˜', 'ì…ë ¥í•´ì¤˜', 'ì´ê±¸ë¡œ í•´ì¤˜' ë“±ì˜ ì„ íƒì  ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ë©´,  
ì§ì „ AIê°€ ì œì‹œí•œ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì ìš©í•˜ëŠ” ë™ì‘ìœ¼ë¡œ ì´í•´í•˜ê³ ,  
ì‚¬ìš©ìê°€ ì¶”ê°€ ì„¤ëª…ì„ ìš”ì²­í•˜ì§€ ì•ŠëŠ” ì´ìƒ ë‹µë³€ì„ ê°„ë‹¨íˆ ìš”ì•½í•˜ë©° ë‹¤ìŒ ë‹¨ê³„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë„˜ì–´ê°€ì„¸ìš”.

**ì‚¬ìš©ì ì§ˆë¬¸:** {prompt}

ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ ì±„ìš© ì „ë¬¸ê°€ ê´€ì ì—ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""

        messages.append({"role": "user", "content": context_prompt})
        
        # OpenAI API í˜¸ì¶œ
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.7,
            max_tokens=1000
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        print(f"[ERROR] OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return f"AI ì‘ë‹µì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”. (ì˜¤ë¥˜: {str(e)})"

@router.post("/suggestions")
async def get_suggestions(request: SuggestionsRequest):
    """í•„ë“œë³„ ì œì•ˆ ê°€ì ¸ì˜¤ê¸°"""
    print("[DEBUG] /suggestions ìš”ì²­:", request)
    suggestions = get_field_suggestions(request.field, request.context)
    response = {"suggestions": suggestions}
    print("[DEBUG] /suggestions ì‘ë‹µ:", response)
    return response

@router.post("/validate")
async def validate_field(request: ValidationRequest):
    """í•„ë“œ ê°’ ê²€ì¦"""
    print("[DEBUG] /validate ìš”ì²­:", request)
    validation_result = validate_field_value(request.field, request.value, request.context)
    response = validation_result
    print("[DEBUG] /validate ì‘ë‹µ:", response)
    return response

@router.post("/autocomplete")
async def smart_autocomplete(request: AutoCompleteRequest):
    """ìŠ¤ë§ˆíŠ¸ ìë™ ì™„ì„±"""
    print("[DEBUG] /autocomplete ìš”ì²­:", request)
    completions = get_autocomplete_suggestions(request.partial_input, request.field, request.context)
    response = {"completions": completions}
    print("[DEBUG] /autocomplete ì‘ë‹µ:", response)
    return response

@router.post("/recommendations")
async def get_recommendations(request: RecommendationsRequest):
    """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì²œ"""
    print("[DEBUG] /recommendations ìš”ì²­:", request)
    recommendations = get_contextual_recommendations(request.current_field, request.filled_fields, request.context)
    response = {"recommendations": recommendations}
    print("[DEBUG] /recommendations ì‘ë‹µ:", response)
    return response

@router.post("/update-field")
async def update_field_in_realtime(request: FieldUpdateRequest):
    """ì‹¤ì‹œê°„ í•„ë“œ ì—…ë°ì´íŠ¸"""
    print("[DEBUG] /update-field ìš”ì²­:", request)
    if request.session_id in modal_sessions:
        modal_sessions[request.session_id]["filled_fields"][request.field] = request.value
        response = {"status": "success", "message": "í•„ë“œê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."}
        print("[DEBUG] /update-field ì‘ë‹µ:", response)
        return response
    else:
        print("[ERROR] /update-field ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜:", request.session_id)
        raise HTTPException(status_code=400, detail="ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ì…ë‹ˆë‹¤")

@router.post("/end")
async def end_session(request: dict):
    """ì„¸ì…˜ ì¢…ë£Œ"""
    print("[DEBUG] /end ìš”ì²­:", request)
    session_id = request.get("session_id")
    if session_id in sessions:
        del sessions[session_id]
    if session_id in modal_sessions:
        del modal_sessions[session_id]
    response = {"status": "success", "message": "ì„¸ì…˜ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."}
    print("[DEBUG] /end ì‘ë‹µ:", response)
    return response

def get_questions_for_page(page: str) -> List[Dict[str, Any]]:
    """í˜ì´ì§€ë³„ ì§ˆë¬¸ ëª©ë¡"""
    print("[DEBUG] get_questions_for_page ìš”ì²­:", page)
    questions_map = {
        "job_posting": [
            {"field": "department", "question": "êµ¬ì¸ ë¶€ì„œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."},
            {"field": "headcount", "question": "ì±„ìš© ì¸ì›ì€ ëª‡ ëª…ì¸ê°€ìš”?"},
            {"field": "workType", "question": "ì–´ë–¤ ì—…ë¬´ë¥¼ ë‹´ë‹¹í•˜ê²Œ ë˜ë‚˜ìš”?"},
            {"field": "workHours", "question": "ê·¼ë¬´ ì‹œê°„ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"},
            {"field": "location", "question": "ê·¼ë¬´ ìœ„ì¹˜ëŠ” ì–´ë””ì¸ê°€ìš”?"},
            {"field": "salary", "question": "ê¸‰ì—¬ ì¡°ê±´ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"},
            {"field": "deadline", "question": "ë§ˆê°ì¼ì€ ì–¸ì œì¸ê°€ìš”?"},
            {"field": "email", "question": "ì—°ë½ì²˜ ì´ë©”ì¼ì„ ì•Œë ¤ì£¼ì„¸ìš”."}
        ]
    }
    questions = questions_map.get(page, [])
    print("[DEBUG] get_questions_for_page ì‘ë‹µ:", questions)
    return questions

def get_field_suggestions(field: str, context: Dict[str, Any]) -> List[str]:
    """í•„ë“œë³„ ì œì•ˆ ëª©ë¡"""
    print("[DEBUG] get_field_suggestions ìš”ì²­:", field, context)
    suggestions_map = {
        "department": ["ê°œë°œíŒ€", "ë§ˆì¼€íŒ…íŒ€", "ì˜ì—…íŒ€", "ë””ìì¸íŒ€", "ê¸°íšíŒ€"],
        "headcount": ["1ëª…", "2ëª…", "3ëª…", "5ëª…", "10ëª…"],
        "workType": ["ì›¹ ê°œë°œ", "ì•± ê°œë°œ", "ë””ìì¸", "ë§ˆì¼€íŒ…", "ì˜ì—…"],
        "workHours": ["09:00-18:00", "10:00-19:00", "ìœ ì—°ê·¼ë¬´ì œ"],
        "location": ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ëŒ€ì „"],
        "salary": ["ë©´ì ‘ í›„ í˜‘ì˜", "3000ë§Œì›", "4000ë§Œì›", "5000ë§Œì›"],
        "deadline": ["2024ë…„ 12ì›” 31ì¼", "2024ë…„ 11ì›” 30ì¼", "ì±„ìš© ì‹œ ë§ˆê°"],
        "email": ["hr@company.com", "recruit@company.com"]
    }
    suggestions = suggestions_map.get(field, [])
    print("[DEBUG] get_field_suggestions ì‘ë‹µ:", suggestions)
    return suggestions

def validate_field_value(field: str, value: str, context: Dict[str, Any]) -> Dict[str, Any]:
    """í•„ë“œ ê°’ ê²€ì¦"""
    print("[DEBUG] validate_field_value ìš”ì²­:", field, value, context)
    if field == "email" and "@" not in value:
        response = {"valid": False, "message": "ì˜¬ë°”ë¥¸ ì´ë©”ì¼ í˜•ì‹ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."}
        print("[DEBUG] validate_field_value ì‘ë‹µ (ì´ë©”ì¼ í˜•ì‹ ì˜¤ë¥˜):", response)
        return response
    elif field == "headcount" and not any(char.isdigit() for char in value):
        response = {"valid": False, "message": "ìˆ«ìë¥¼ í¬í•¨í•œ ì¸ì› ìˆ˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."}
        print("[DEBUG] validate_field_value ì‘ë‹µ (í—¤ë“œì¹´ìš´íŠ¸ ìˆ«ì ì˜¤ë¥˜):", response)
        return response
    else:
        response = {"valid": True, "message": "ì˜¬ë°”ë¥¸ í˜•ì‹ì…ë‹ˆë‹¤."}
        print("[DEBUG] validate_field_value ì‘ë‹µ (ìœ íš¨):", response)
        return response

def get_autocomplete_suggestions(partial_input: str, field: str, context: Dict[str, Any]) -> List[str]:
    """ìë™ ì™„ì„± ì œì•ˆ"""
    print("[DEBUG] get_autocomplete_suggestions ìš”ì²­:", partial_input, field, context)
    suggestions = get_field_suggestions(field, context)
    completions = [s for s in suggestions if partial_input.lower() in s.lower()]
    print("[DEBUG] get_autocomplete_suggestions ì‘ë‹µ:", completions)
    return completions

def get_contextual_recommendations(current_field: str, filled_fields: Dict[str, Any], context: Dict[str, Any]) -> List[str]:
    """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì²œ"""
    print("[DEBUG] get_contextual_recommendations ìš”ì²­:", current_field, filled_fields, context)
    if current_field == "workType" and filled_fields.get("department") == "ê°œë°œíŒ€":
        recommendations = ["ì›¹ ê°œë°œ", "ì•± ê°œë°œ", "ë°±ì—”ë“œ ê°œë°œ", "í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ"]
    elif current_field == "salary" and filled_fields.get("workType") == "ê°œë°œ":
        recommendations = ["4000ë§Œì›", "5000ë§Œì›", "6000ë§Œì›", "ë©´ì ‘ í›„ í˜‘ì˜"]
    else:
        recommendations = get_field_suggestions(current_field, context)
    print("[DEBUG] get_contextual_recommendations ì‘ë‹µ:", recommendations)
    return recommendations

@router.post("/chat")
async def chat_endpoint(request: ChatbotRequest):
    """
    í‚¤ì›Œë“œ ê¸°ë°˜ 1ì°¨ ë¶„ë¥˜ â†’ LLM í˜¸ì¶œ â†’ ì‘ë‹µ ì²˜ë¦¬ API
    """
    print("[DEBUG] /chat ìš”ì²­:", request)
    
    try:
        user_input = request.user_input
        conversation_history = request.conversation_history
        
        if not user_input:
            raise HTTPException(status_code=400, detail="ì‚¬ìš©ì ì…ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # 1) í‚¤ì›Œë“œ ê¸°ë°˜ 1ì°¨ ë¶„ë¥˜
        classification = classify_input(user_input)
        print(f"[DEBUG] /chat ë¶„ë¥˜ ê²°ê³¼: {classification}")
        
        # 2) ë¶„ë¥˜ëœ ê²°ê³¼ì— ë”°ë¥¸ ì²˜ë¦¬
        if classification['type'] == 'field':
            # í•„ë“œ ê°’ìœ¼ë¡œ ì²˜ë¦¬
            field_value = classification.get('value', user_input.strip())
            response = {
                "type": "field",
                "content": f"{classification['category']}: {field_value}ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "value": field_value,
                "confidence": classification['confidence']
            }
            
        elif classification['type'] == 'question':
            # 3) OpenAI API í˜¸ì¶œë¡œ ë‹µë³€ ìƒì„±
            ai_response = await call_openai_api(user_input, conversation_history)
            response = {
                "type": "answer",
                "content": ai_response,
                "confidence": classification['confidence']
            }
            
        elif classification['type'] == 'chat':
            # ì¼ìƒ ëŒ€í™” ì²˜ë¦¬
            response = {
                "type": "chat",
                "content": "ì•ˆë…•í•˜ì„¸ìš”! ì±„ìš© ê´€ë ¨ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”.",
                "confidence": classification['confidence']
            }
            
        else:
            # ë‹µë³€ì¸ ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬ (ìë™ ì™„ì„±)
            response = {
                "type": "answer",
                "content": f"'{user_input}'ë¡œ ì…ë ¥í•˜ê² ìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.",
                "value": user_input.strip(),
                "confidence": classification['confidence']
            }
        
        print("[DEBUG] /chat ì‘ë‹µ:", response)
        return response
        
    except Exception as e:
        print(f"[ERROR] /chat ì˜ˆì™¸: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")