from typing import Dict, Any, Optional, List
from openai import OpenAI
import os
from datetime import datetime

class LLMService:
    def __init__(self):
        """
        LLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        """
        print(f"[LLMService] === LLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹œì‘ ===")
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print(f"[LLMService] ê²½ê³ : OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        else:
            print(f"[LLMService] OPENAI_API_KEY í™•ì¸ë¨ (ê¸¸ì´: {len(api_key)})")
        
        self.client = OpenAI(api_key=api_key)
        self.model_name = 'gpt-4o'
        print(f"[LLMService] OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {self.model_name}")
        print(f"[LLMService] === LLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ ===")
    
    async def chat_completion(self, messages: List[Dict[str, str]], max_tokens: int = 1000, temperature: float = 0.7) -> str:
        """
        OpenAI Chat Completion APIë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            messages (List[Dict[str, str]]): ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            max_tokens (int): ìµœëŒ€ í† í° ìˆ˜
            temperature (float): ì°½ì˜ì„± ì¡°ì ˆ (0.0 ~ 1.0)
            
        Returns:
            str: AI ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        try:
            print(f"[LLMService] === Chat Completion ì‹œì‘ ===")
            print(f"[LLMService] ë©”ì‹œì§€ ìˆ˜: {len(messages)}")
            print(f"[LLMService] ëª¨ë¸: {self.model_name}")
            
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            
            result = response.choices[0].message.content
            print(f"[LLMService] ì‘ë‹µ ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(result) if result else 0})")
            print(f"[LLMService] === Chat Completion ì™„ë£Œ ===")
            
            return result
            
        except Exception as e:
            print(f"[LLMService] === Chat Completion ì˜¤ë¥˜ ===")
            print(f"[LLMService] ì˜¤ë¥˜: {str(e)}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    async def analyze_plagiarism_suspicion(self, 
                                    original_resume: Dict[str, Any], 
                                    similar_resumes: List[Dict[str, Any]],
                                    document_type: str = "ìì†Œì„œ") -> Dict[str, Any]:
        """
        í‘œì ˆ ì˜ì‹¬ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            original_resume (Dict[str, Any]): ì›ë³¸ ë¬¸ì„œ
            similar_resumes (List[Dict[str, Any]]): ìœ ì‚¬í•œ ë¬¸ì„œë“¤
            document_type (str): ë¬¸ì„œ íƒ€ì… ("ì´ë ¥ì„œ" ë˜ëŠ” "ìì†Œì„œ")
            
        Returns:
            Dict[str, Any]: í‘œì ˆ ì˜ì‹¬ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            print(f"[LLMService] === í‘œì ˆ ì˜ì‹¬ë„ ë¶„ì„ ì‹œì‘ ===")
            # ìì†Œì„œì˜ ê²½ìš° basic_info_names í•„ë“œì—ì„œ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
            if document_type == "ìì†Œì„œ":
                original_name = original_resume.get('basic_info_names') or original_resume.get('name', 'Unknown')
            else:
                original_name = original_resume.get('name', 'Unknown')
            print(f"[LLMService] ì›ë³¸ {document_type}: {original_name}")
            print(f"[LLMService] ìœ ì‚¬í•œ {document_type} ìˆ˜: {len(similar_resumes)}")
            
            if not similar_resumes:
                print(f"[LLMService] ìœ ì‚¬í•œ {document_type}ê°€ ì—†ìŒ - LOW ì˜ì‹¬ë„ ë°˜í™˜")
                return {
                    "success": True,
                    "suspicion_level": "LOW",
                    "suspicion_score": 0.0,
                    "suspicion_score_percent": 0,
                    "analysis": f"ìœ ì‚¬í•œ {document_type}ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í‘œì ˆ ì˜ì‹¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.",
                    "recommendations": []
                }
            
            # ìµœê³  ìœ ì‚¬ë„ ì ìˆ˜ í™•ì¸ (API ì‘ë‹µ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •)
            similarities = []
            for resume in similar_resumes:
                if "similarity_score" in resume:
                    similarities.append(resume["similarity_score"])
                elif "overall_similarity" in resume:
                    similarities.append(resume["overall_similarity"])
                else:
                    print(f"[LLMService] ê²½ê³ : ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ - {resume.keys()}")
                    similarities.append(0.0)
            
            max_similarity = max(similarities) if similarities else 0.0
            print(f"[LLMService] ìµœê³  ìœ ì‚¬ë„ ì ìˆ˜: {max_similarity:.3f}")
            
            # ì˜ì‹¬ë„ ë ˆë²¨ ê²°ì •
            if max_similarity >= 0.8:
                suspicion_level = "HIGH"
            elif max_similarity >= 0.6:
                suspicion_level = "MEDIUM"
            else:
                suspicion_level = "LOW"
            
            suspicion_score = max_similarity
            
            # LLMì„ ì‚¬ìš©í•˜ì—¬ ìƒì„¸í•œ ë¶„ì„ ìƒì„±
            analysis = await self._generate_plagiarism_analysis(
                max_similarity, suspicion_level, len(similar_resumes), document_type, similar_resumes
            )
            
            recommendations = []
            
            print(f"[LLMService] ì˜ì‹¬ë„ ê²°ì • ì™„ë£Œ: {suspicion_level} (ì ìˆ˜: {suspicion_score:.3f})")
            print(f"[LLMService] === í‘œì ˆ ì˜ì‹¬ë„ ë¶„ì„ ì™„ë£Œ ===")
            
            return {
                "success": True,
                "suspicion_level": suspicion_level,
                "suspicion_score": suspicion_score,
                "suspicion_score_percent": int(suspicion_score * 100),
                "analysis": analysis,
                "recommendations": recommendations,
                "similar_count": len(similar_resumes),
                "analyzed_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"[LLMService] === í‘œì ˆ ì˜ì‹¬ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ===")
            print(f"[LLMService] ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
            print(f"[LLMService] ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}")
            import traceback
            print(f"[LLMService] ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
            return {
                "success": False,
                "error": str(e),
                "suspicion_level": "UNKNOWN",
                "suspicion_score": 0.0,
                "suspicion_score_percent": 0,
                "analysis": "í‘œì ˆ ì˜ì‹¬ë„ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                "analyzed_at": datetime.now().isoformat()
            }

    async def analyze_similar_applicants(self, target_applicant: Dict[str, Any], 
                                       similar_applicants: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ìœ ì‚¬ ì§€ì›ìë“¤ì— ëŒ€í•œ LLM ë¶„ì„ ìˆ˜í–‰
        
        Args:
            target_applicant (Dict): ê¸°ì¤€ ì§€ì›ì ì •ë³´
            similar_applicants (List[Dict]): ìœ ì‚¬í•œ ì§€ì›ìë“¤ ì •ë³´
            
        Returns:
            Dict: LLM ë¶„ì„ ê²°ê³¼
        """
        try:
            print(f"[LLMService] === ìœ ì‚¬ ì§€ì›ì LLM ë¶„ì„ ì‹œì‘ ===")
            print(f"[LLMService] ê¸°ì¤€ ì§€ì›ì: {target_applicant.get('name', 'N/A')}")
            print(f"[LLMService] ìœ ì‚¬ ì§€ì›ì ìˆ˜: {len(similar_applicants)}")
            
            if not similar_applicants:
                return {
                    "success": False,
                    "message": "ë¶„ì„í•  ìœ ì‚¬ ì§€ì›ìê°€ ì—†ìŠµë‹ˆë‹¤."
                }
            
            # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._create_similar_applicants_analysis_prompt(target_applicant, similar_applicants)
            
            # OpenAI API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¸ì¬ ì±„ìš© ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ìš”ì²­ëœ ì •í™•í•œ í˜•ì‹ì„ ë”°ë¼ ì‘ë‹µí•´ì£¼ì„¸ìš”. íŠ¹íˆ '### 3. ê° ìœ ì‚¬ ì§€ì›ìë³„ ìƒì„¸ ë¶„ì„' ì„¹ì…˜ì—ì„œ ê° ì§€ì›ìë§ˆë‹¤ ğŸ” í•µì‹¬ ê³µí†µì , ğŸ’¡ ì£¼ìš” íŠ¹ì§•, â­ ì¶”ì²œ ì´ìœ , ğŸ¯ ìœ ì‚¬ì„± ìš”ì¸ì„ ëª¨ë‘ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # ë” ì¼ê´€ëœ ì‘ë‹µì„ ìœ„í•´ ë‚®ì¶¤
                max_tokens=1000
            )
            
            analysis_text = response.choices[0].message.content.strip()
            
            print(f"[LLMService] LLM ë¶„ì„ ì™„ë£Œ")
            print(f"[LLMService] === LLM ë¶„ì„ ê²°ê³¼ ===")
            print(analysis_text[:500] + "..." if len(analysis_text) > 500 else analysis_text)
            print(f"[LLMService] === LLM ë¶„ì„ ê²°ê³¼ ë ===")
            
            return {
                "success": True,
                "analysis": analysis_text,
                "target_applicant": target_applicant,
                "similar_count": len(similar_applicants),
                "analyzed_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"[LLMService] ìœ ì‚¬ ì§€ì›ì ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "message": "ìœ ì‚¬ ì§€ì›ì ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "analyzed_at": datetime.now().isoformat()
            }

    def _create_similar_applicants_analysis_prompt(self, target_applicant: Dict[str, Any], 
                                                 similar_applicants: List[Dict[str, Any]]) -> str:
        """ìœ ì‚¬ ì§€ì›ì ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # ê¸°ì¤€ ì§€ì›ì ì •ë³´
        prompt = f"""ë‹¤ìŒ ê¸°ì¤€ ì§€ì›ìì™€ ìœ ì‚¬í•œ ì§€ì›ìë“¤ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. ì™œ ìœ ì‚¬í•œì§€ ë¶„ì„í•´ì£¼ì„¸ìš”.

**ê¸°ì¤€ ì§€ì›ì:**
- ì´ë¦„: {target_applicant.get('name', 'N/A')}
- ì§€ì›ì§ë¬´: {target_applicant.get('position', 'N/A')}
- ê²½ë ¥: {target_applicant.get('experience', 'N/A')}
- ê¸°ìˆ ìŠ¤íƒ: {target_applicant.get('skills', 'N/A')}
- ë¶€ì„œ: {target_applicant.get('department', 'N/A')}

**ìœ ì‚¬í•œ ì§€ì›ìë“¤:**
"""
        
        # ìœ ì‚¬ ì§€ì›ìë“¤ ì •ë³´
        for applicant in similar_applicants:
            prompt += f"""
{applicant['rank']}ìˆœìœ„. {applicant.get('name', 'N/A')}
- ì§€ì›ì§ë¬´: {applicant.get('position', 'N/A')}
- ê²½ë ¥: {applicant.get('experience', 'N/A')}
- ê¸°ìˆ ìŠ¤íƒ: {applicant.get('skills', 'N/A')}
- ë¶€ì„œ: {applicant.get('department', 'N/A')}
- ìœ ì‚¬ë„ ì ìˆ˜: {applicant.get('final_score', 0):.3f} (ë²¡í„°: {applicant.get('vector_score', 0):.3f}, í‚¤ì›Œë“œ: {applicant.get('keyword_score', 0):.3f})
"""
        
        prompt += """

**ì¤‘ìš”: ë°˜ë“œì‹œ ì•„ë˜ ì •í™•í•œ í˜•ì‹ì„ ë”°ë¼ ì‘ë‹µí•´ì£¼ì„¸ìš”.**

### 1. ê¸°ì¤€ ì§€ì›ìì™€ ê° ìœ ì‚¬ ì§€ì›ì ê°„ì˜ ê³µí†µì 

### 2. ìœ ì‚¬ì„±ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹œ íŠ¹ì„± ë¶„ì„

### 3. ê° ìœ ì‚¬ ì§€ì›ìë³„ ìƒì„¸ ë¶„ì„

- **[ì§€ì›ìëª…]**
  - ğŸ” **í•µì‹¬ ê³µí†µì **: [ê¸°ì¤€ ì§€ì›ìì™€ì˜ ì£¼ìš” ê³µí†µì  1ì¤„]
  - ğŸ’¡ **ì£¼ìš” íŠ¹ì§•**: [í•µì‹¬ ì—­ëŸ‰ì´ë‚˜ ê²½ë ¥ ìš”ì•½ 1ì¤„]  
  - â­ **ì¶”ì²œ ì´ìœ **: [êµ¬ì²´ì ì¸ ì¶”ì²œ ê·¼ê±°]
  - ğŸ¯ **ìœ ì‚¬ì„± ìš”ì¸**: [ìœ ì‚¬ì„±ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹œ íŠ¹ì„±]

**í•„ìˆ˜ ì¤€ìˆ˜ì‚¬í•­:**
1. ë°˜ë“œì‹œ "### 3. ê° ìœ ì‚¬ ì§€ì›ìë³„ ìƒì„¸ ë¶„ì„" ì„¹ì…˜ì„ í¬í•¨í•˜ì„¸ìš”
2. ê° ì§€ì›ìë§ˆë‹¤ ğŸ”, ğŸ’¡, â­, ğŸ¯ ë„¤ ê°€ì§€ í•­ëª©ì„ ëª¨ë‘ ì‘ì„±í•˜ì„¸ìš”
3. ì§€ì›ì ì´ë¦„ì€ **[ì§€ì›ìëª…]** í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
4. ìœ„ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¥´ì§€ ì•Šìœ¼ë©´ ì‹œìŠ¤í…œì—ì„œ íŒŒì‹±ì´ ì‹¤íŒ¨í•©ë‹ˆë‹¤
"""
        
        return prompt

    async def _generate_plagiarism_analysis(self, 
                                          similarity_score: float, 
                                          suspicion_level: str, 
                                          similar_count: int, 
                                          document_type: str,
                                          similar_documents: List[Dict[str, Any]]) -> str:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ í‘œì ˆ ì˜ì‹¬ë„ ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            similarity_score (float): ìµœê³  ìœ ì‚¬ë„ ì ìˆ˜ (0.0 ~ 1.0)
            suspicion_level (str): ìœ„í—˜ë„ ë ˆë²¨ (HIGH/MEDIUM/LOW)
            similar_count (int): ìœ ì‚¬í•œ ë¬¸ì„œ ê°œìˆ˜
            document_type (str): ë¬¸ì„œ íƒ€ì…
            similar_documents (List[Dict]): ìœ ì‚¬í•œ ë¬¸ì„œë“¤ì˜ ìƒì„¸ ì •ë³´
            
        Returns:
            str: LLMì´ ìƒì„±í•œ ìƒì„¸ ë¶„ì„ í…ìŠ¤íŠ¸
        """
        try:
            print(f"[LLMService] LLM ê¸°ë°˜ í‘œì ˆ ì˜ì‹¬ë„ ë¶„ì„ ì‹œì‘...")
            
            # ìœ ì‚¬ë„ ì ìˆ˜ë“¤ì„ ìˆ˜ì§‘
            similarity_details = []
            for doc in similar_documents[:3]:  # ìƒìœ„ 3ê°œë§Œ ë¶„ì„ì— í¬í•¨
                score = doc.get("similarity_score", doc.get("overall_similarity", 0.0))
                name = doc.get("basic_info_names", doc.get("name", "Unknown"))
                similarity_details.append(f"- {name}: {score:.1%} ìœ ì‚¬ë„")
            
            similarity_details_text = "\n".join(similarity_details)
            
            # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {document_type} í‘œì ˆ ì˜ì‹¬ë„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

[ì—­í• ]  
ë‹¹ì‹ ì€ ìê¸°ì†Œê°œì„œì˜ ì˜ë¯¸ ê¸°ë°˜ ìœ ì‚¬ì„±ì„ í‰ê°€í•˜ëŠ” ê²€í†  ë³´ì¡°ìì…ë‹ˆë‹¤.  
ê¸°ì¤€ ìì†Œì„œì˜ ì¼ë¶€ ë¬¸ì¥ì—ì„œ ì˜ë¯¸ ì¤‘ë³µì´ ê°ì§€ëœ ê²½ìš°, í‘œí˜„ êµ¬ì¡°ë‚˜ íë¦„ ì¤‘ì‹¬ìœ¼ë¡œ í‰ê°€ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

[ì…ë ¥ ë°ì´í„°]  
- ê¸°ì¤€ ìì†Œì„œ ë¬¸ì¥ ì¤‘ ìœ ì‚¬ë„ê°€ ë†’ì€ ë¬¸ì¥ 1~2ê°œ  
- ê° ë¬¸ì¥ì— ëŒ€í•œ ìœ ì‚¬ë„ ë ˆë²¨ (HIGH / MEDIUM / LOW)  
- ê° ë¬¸ì¥ì— ëŒ€í•´ ìœ ì‚¬ íŒë‹¨ëœ ì´ìœ  (í‘œí˜„ êµ¬ì¡°, íë¦„, í‚¤ì›Œë“œ ë“±)

[ì‘ì„± ëª©í‘œ]  
- ìœ ì‚¬ë„ ìˆ˜ì¹˜ë‚˜ ìœ ì‚¬ ìì†Œì„œ ê°œìˆ˜ëŠ” **ë§í•˜ì§€ ë§ˆì„¸ìš”**  
- ê¸°ì¤€ ìì†Œì„œ ë‚´ **ìœ ì‚¬ ë¬¸ì¥**ê³¼ ê·¸ì— ëŒ€í•œ **ìœ ì‚¬ ì´ìœ **ë§Œ ê°„ê²°í•˜ê²Œ ì œì‹œ  
- ë§ˆì§€ë§‰ ì¤„ì—ëŠ” ì¤‘ë¦½ì  LLM í‰ê°€ ë¬¸ì¥ì„ ë„£ìœ¼ì„¸ìš” ("ê²€í†  ê¶Œì¥" ë“±)

[ì¶œë ¥ ì˜ˆì‹œ]

â€œâ€˜ê³ ê° ì¤‘ì‹¬ ì‚¬ê³ ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í–ˆìŠµë‹ˆë‹¤.â€™ ë¬¸ì¥ì€ í‘œí˜„ êµ¬ì¡°ì™€ í•µì‹¬ ë‹¨ì–´ê°€ ë°˜ë³µë˜ì–´ HIGH ë“±ê¸‰ì˜ ìœ ì‚¬ì„±ì´ ê´€ì¸¡ë˜ì—ˆìŠµë‹ˆë‹¤.  
ë˜í•œ â€˜í˜‘ì—…ì„ í†µí•´ ì–´ë ¤ì›€ì„ ê·¹ë³µí•˜ë©° ì„±ì¥í–ˆìŠµë‹ˆë‹¤.â€™ ë¬¸ì¥ë„ ìœ ì‚¬í•œ íë¦„ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ MEDIUM ë“±ê¸‰ìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.  
ì¼ë¶€ ë¬¸ì¥ì—ì„œ ì˜ë¯¸ì  ì¤‘ë³µì´ ë‚˜íƒ€ë‚˜ë¯€ë¡œ, í‘œì ˆ ì—¬ë¶€ì— ëŒ€í•œ ê²€í† ê°€ ê¶Œì¥ë©ë‹ˆë‹¤.â€


"""

            # OpenAI API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ ë¬¸ì„œ í‘œì ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì„ë² ë”© ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ í‘œì ˆ ì˜ì‹¬ë„ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                temperature=0.3,  # ì¼ê´€ì„± ìˆëŠ” ë¶„ì„ì„ ìœ„í•´ ë‚®ì€ temperature ì‚¬ìš©
                max_tokens=200
            )
            
            analysis_text = response.choices[0].message.content.strip()
            
            # 3ì¤„ ì œí•œ ì²˜ë¦¬
            lines = analysis_text.split('\n')
            if len(lines) > 3:
                analysis_text = '\n'.join(lines[:3])
                print(f"[LLMService] LLM ì‘ë‹µì´ {len(lines)}ì¤„ì´ë¯€ë¡œ 3ì¤„ë¡œ ì œí•œë¨")
            
            print(f"[LLMService] LLM ê¸°ë°˜ í‘œì ˆ ë¶„ì„ ì™„ë£Œ (ê¸¸ì´: {len(analysis_text)})")
            
            return analysis_text
            
        except Exception as e:
            print(f"[LLMService] LLM ê¸°ë°˜ ë¶„ì„ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            # í´ë°±: ê¸°ë³¸ ê·œì¹™ ê¸°ë°˜ ë¶„ì„
            if suspicion_level == "HIGH":
                return f"ë§¤ìš° ë†’ì€ ìœ ì‚¬ë„({similarity_score:.1%})ì˜ {document_type}ê°€ {similar_count}ê°œ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. í‘œì ˆ ì˜ì‹¬ë„ê°€ ë†’ì•„ ì¶”ê°€ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            elif suspicion_level == "MEDIUM":
                return f"ë†’ì€ ìœ ì‚¬ë„({similarity_score:.1%})ì˜ {document_type}ê°€ {similar_count}ê°œ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. í‘œì ˆ ì˜ì‹¬ë„ê°€ ë³´í†µ ìˆ˜ì¤€ì´ë¯€ë¡œ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            else:
                return f"ì ì • ìˆ˜ì¤€ì˜ ìœ ì‚¬ë„({similarity_score:.1%})ì…ë‹ˆë‹¤. ìœ ì‚¬í•œ {document_type} {similar_count}ê°œê°€ ë°œê²¬ë˜ì—ˆìœ¼ë‚˜ í‘œì ˆ ì˜ì‹¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤."