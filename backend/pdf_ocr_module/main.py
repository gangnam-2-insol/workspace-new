from __future__ import annotations

import uuid
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

from .ai_analyzer import analyze_text, analyze_text_with_vision, extract_keywords, summarize_text, extract_fields, clean_text
from .config import Settings
from .embedder import embed_texts, get_embedding
from .ocr_engine import ocr_images, ocr_images_with_quality
from .pdf_extractor import extract_text_with_layout
from .pdf_processor import save_pdf_pages_to_images, create_thumbnails
from .storage import save_document_to_mongo, save_to_db
from .utils import ensure_directories, write_json, file_sha256
from .vector_storage import upsert_embeddings, store_vector


def process_pdf(pdf_path: str | Path) -> Dict[str, Any]:
    settings = Settings()
    ensure_directories(settings)

    pdf_path = Path(pdf_path)
    if not pdf_path.exists():
        raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")

    # 0) ì¤‘ë³µ ë°©ì§€ í•´ì‹œ ê³„ì‚°
    doc_hash = file_sha256(pdf_path)

    # 1) ìš°ì„  ë‚´ì¥ í…ìŠ¤íŠ¸/ë ˆì´ì•„ì›ƒ ì¶”ì¶œ
    print("ğŸ“„ PDF ë‚´ì¥ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„...")
    layout = extract_text_with_layout(pdf_path)
    
    # ë‚´ì¥ í…ìŠ¤íŠ¸ í’ˆì§ˆ í‰ê°€
    embedded_text = layout.get("full_text", "").strip()
    embedded_text_length = len(embedded_text)
    print(f"ğŸ“Š ë‚´ì¥ í…ìŠ¤íŠ¸ ê¸¸ì´: {embedded_text_length} ë¬¸ì")
    
    # í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„í•œì§€ íŒë‹¨ (ìµœì†Œ 100ì ì´ìƒ)
    MIN_TEXT_LENGTH = 100
    has_sufficient_text = embedded_text_length >= MIN_TEXT_LENGTH
    
    if has_sufficient_text:
        print("âœ… ì¶©ë¶„í•œ ë‚´ì¥ í…ìŠ¤íŠ¸ ë°œê²¬ - OCR ìƒëµ")
        full_text = embedded_text
        page_texts = [embedded_text]  # ë‹¨ì¼ í˜ì´ì§€ë¡œ ì²˜ë¦¬
        ocr_outputs = []  # OCR ê²°ê³¼ ì—†ìŒ
        used_ocr = False
    else:
        print("âš ï¸ ë‚´ì¥ í…ìŠ¤íŠ¸ ë¶€ì¡± - OCR ì²˜ë¦¬ ì‹œì‘")
        # 2) PDF -> ì´ë¯¸ì§€
        page_image_dir = settings.images_dir / pdf_path.stem
        image_paths: List[Path] = save_pdf_pages_to_images(pdf_path, page_image_dir, settings)
        thumb_paths: List[Path] = create_thumbnails(image_paths)

        # 3) ì´ë¯¸ì§€ -> í…ìŠ¤íŠ¸ (OCR)
        ocr_outputs = ocr_images_with_quality(image_paths, settings)
        page_texts: List[str] = []
        
        # ë‚´ì¥ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ë¶€ì¡±í•˜ë©´ OCR ë³´ì™„
        for i in range(len(image_paths)):
            page_spans = next((p.get("spans", []) for p in layout.get("pages", []) if p.get("page") == i + 1), [])
            embedded_text = " ".join([s.get("text", "") for s in page_spans]).strip()
            ocr_text = ocr_outputs[i]["result"]["text"]
            
            # ë‚´ì¥ í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„í•˜ë©´ ì‚¬ìš©, ì•„ë‹ˆë©´ OCR ê²°ê³¼ ì‚¬ìš©
            chosen = embedded_text if len(embedded_text) >= max(50, len(ocr_text) * 0.5) else ocr_text
            page_texts.append(chosen)
        
        full_text: str = "\n\n".join(page_texts)
        used_ocr = True

    # 4) Vision APIë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ë¶„ì„ (ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸)
    if settings.index_generate_summary or settings.index_generate_keywords:
        try:
            if used_ocr:
                # OCRì„ ì‚¬ìš©í•œ ê²½ìš° Vision API í™œìš©
                analysis = analyze_text_with_vision(image_paths, full_text, settings)
                print("âœ… Vision API ë¶„ì„ ì™„ë£Œ (OCR ê¸°ë°˜)")
            else:
                # í…ìŠ¤íŠ¸ë§Œ ìˆëŠ” ê²½ìš° í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„
                analysis = analyze_text(full_text, settings)
                print("âœ… í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ë¶„ì„ ì‹¤íŒ¨, í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ í´ë°±: {e}")
            # ë¶„ì„ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ í´ë°±
            analysis = analyze_text(full_text, settings)
        
        _summary = analysis.get("summary", "") if settings.index_generate_summary else ""
        _keywords = analysis.get("keywords", []) if settings.index_generate_keywords else []
    else:
        analysis = {"summary": "", "keywords": [], "clean_text": full_text}
        _summary = ""
        _keywords = []

    # 5) í•„ë“œ ì¶”ì¶œ
    fields = extract_fields(full_text)
    
    # 6) MongoDB ì €ì¥
    document = {
        "doc_id": str(uuid.uuid4()),
        "doc_hash": doc_hash,
        "file_name": pdf_path.name,
        "num_pages": len(page_texts),
        "preview": [str(p) for p in thumb_paths] if used_ocr else [],
        "pages": [
            {
                "page": i + 1,
                "clean_text": analyze_text(t, settings).get("clean_text", t),
                "quality_score": float(ocr_outputs[i]["result"].get("quality") or 0.0) if used_ocr else 1.0,
                "trace": {
                    "attempts": ocr_outputs[i].get("attempts", []) if used_ocr else [],
                    "used_ocr": used_ocr,
                    "embedded_text_length": embedded_text_length,
                },
            }
            for i, t in enumerate(page_texts)
        ],
        "text": full_text,
        "fields": fields,
        "summary": analysis.get("summary") or _summary,
        "keywords": analysis.get("keywords", []) or _keywords,
        "processing_info": {
            "used_ocr": used_ocr,
            "embedded_text_length": embedded_text_length,
            "total_text_length": len(full_text),
            "processing_method": "ocr" if used_ocr else "text_extraction"
        },
        "created_at": datetime.now(),
        "updated_at": datetime.now(),
    }

    # MongoDBì— ì €ì¥
    inserted_id = save_document_to_mongo(document, settings)
    document["mongo_id"] = inserted_id

    # í˜ì´ì§€ ë‹¨ìœ„ ëª½ê³  ì €ì¥(ì›ë³¸ í…ìŠ¤íŠ¸+í´ë¦°): í•„ìš”ì‹œ ê²€ì¦ìš©
    for idx, page_text in enumerate(page_texts, start=1):
        save_to_db(pdf_path.name.lstrip('.'), idx, page_text, None, None, None, doc_hash=doc_hash)

    # 7) ê²°ê³¼ ì €ì¥ (ì„ íƒ)
    result_path = settings.results_dir / f"{pdf_path.stem}.json"
    write_json(result_path, {
        "mongo_id": inserted_id,
        **{k: v for k, v in document.items() if k != "pages" or len(v) <= 3},  # ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½ ì €ì¥
    })

    return {
        "mongo_id": inserted_id,
        "file_name": pdf_path.name,
        "num_pages": len(page_texts),
        "full_text": full_text,  # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ê°€
        "summary": analysis.get("summary") if settings.index_generate_summary else None,
        "keywords": analysis.get("keywords", []) if settings.index_generate_keywords else [],
        "doc_hash": doc_hash,
        "fields": fields,
        "vision_analysis": analysis.get("vision_analysis", {}),  # Vision ë¶„ì„ ê²°ê³¼ ì¶”ê°€
    }


