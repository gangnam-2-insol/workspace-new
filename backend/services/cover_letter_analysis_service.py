import os
import json
import logging
from typing import Dict, Any, List
from datetime import datetime
import openai
from openai import AsyncOpenAI

logger = logging.getLogger(__name__)

class CoverLetterAnalysisService:
    """ìì†Œì„œ ë¶„ì„ ì„œë¹„ìŠ¤ - 9ê°œ í‰ê°€ í•­ëª©"""
    
    def __init__(self):
        self.client = AsyncOpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        )
        
        # 9ê°œ í‰ê°€ í•­ëª© ì •ì˜
        self.evaluation_items = [
            "ì§ë¬´ ì í•©ì„± (Job Fit)",
            "ê¸°ìˆ  ìŠ¤íƒ ì¼ì¹˜ ì—¬ë¶€", 
            "ê²½í—˜í•œ í”„ë¡œì íŠ¸ ê´€ë ¨ì„±",
            "í•µì‹¬ ê¸°ìˆ  ì—­ëŸ‰ (Tech Competency)",
            "ê²½ë ¥ ë° ì„±ê³¼ (Experience & Impact)",
            "ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ (Problem-Solving)",
            "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜/í˜‘ì—… (Collaboration)",
            "ì„±ì¥ ê°€ëŠ¥ì„±/í•™ìŠµ ëŠ¥ë ¥ (Growth Potential)",
            "ìì†Œì„œ í‘œí˜„ë ¥/ë…¼ë¦¬ì„± (Clarity & Grammar)"
        ]
    
    async def analyze_cover_letter(self, cover_letter_text: str, job_description: str = "") -> Dict[str, Any]:
        """ìì†Œì„œ ë¶„ì„ ì‹¤í–‰"""
        try:
            logger.info("ğŸ” ìì†Œì„œ ë¶„ì„ ì‹œì‘...")
            
            # GPT-4oë¡œ ë¶„ì„ ì‹¤í–‰
            analysis_result = await self._analyze_with_gpt4o(cover_letter_text, job_description)
            
            # ê²°ê³¼ êµ¬ì¡°í™”
            structured_result = {
                "analysis_timestamp": datetime.now().isoformat(),
                "cover_letter_analysis": analysis_result,
                "overall_score": self._calculate_overall_score(analysis_result)
            }
            
            logger.info(f"âœ… ìì†Œì„œ ë¶„ì„ ì™„ë£Œ! ì¢…í•© ì ìˆ˜: {structured_result['overall_score']:.1f}/10ì ")
            return structured_result
            
        except Exception as e:
            logger.error(f"âŒ ìì†Œì„œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    async def _analyze_with_gpt4o(self, cover_letter_text: str, job_description: str) -> Dict[str, Any]:
        """GPT-4oë¥¼ ì‚¬ìš©í•œ ìì†Œì„œ ë¶„ì„"""
        try:
            # ë¶„ì„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_analysis_prompt(cover_letter_text, job_description)
            
            # GPT-4o API í˜¸ì¶œ
            response = await self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ 15ë…„ ê²½ë ¥ì˜ HR ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìì†Œì„œë¥¼ 9ê°œ í•­ëª©ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ê° í•­ëª©ë³„ë¡œ 0-10ì ì„ ë§¤ê¸°ê³  í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            # ì‘ë‹µ íŒŒì‹±
            analysis_text = response.choices[0].message.content
            return self._parse_analysis_response(analysis_text)
            
        except Exception as e:
            logger.error(f"GPT-4o ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._get_default_analysis()
    
    def _build_analysis_prompt(self, cover_letter_text: str, job_description: str) -> str:
        """ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        prompt = f"""
ë‹¤ìŒ ìì†Œì„œë¥¼ 9ê°œ í‰ê°€ í•­ëª©ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.

[ìì†Œì„œ ë‚´ìš©]
{cover_letter_text[:3000]}{'...' if len(cover_letter_text) > 3000 else ''}

{f'[ì±„ìš© ê³µê³  ë‚´ìš©]\n{job_description[:1000]}{"..." if len(job_description) > 1000 else ""}' if job_description else ''}

[í‰ê°€ í•­ëª© ë° ê¸°ì¤€]
1. ì§ë¬´ ì í•©ì„± (Job Fit): ì§€ì› ì§ë¬´ì™€ì˜ ì—°ê´€ì„± ë° ì í•©ì„±
2. ê¸°ìˆ  ìŠ¤íƒ ì¼ì¹˜ ì—¬ë¶€: JD ê¸°ìˆ ê³¼ ìì†Œì„œ ê¸°ìˆ  ìŠ¤íƒ ë¹„êµ
3. ê²½í—˜í•œ í”„ë¡œì íŠ¸ ê´€ë ¨ì„±: ì§ë¬´ì™€ì˜ ì—°ê´€ì„±
4. í•µì‹¬ ê¸°ìˆ  ì—­ëŸ‰ (Tech Competency): ê¸°ìˆ  ìŠ¤íƒì˜ ê¹Šì´ì™€ ë„“ì´
5. ê²½ë ¥ ë° ì„±ê³¼ (Experience & Impact): ì£¼ë„ì  ì—­í• ê³¼ ìˆ˜ì¹˜í™”ëœ ì„±ê³¼
6. ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ (Problem-Solving): êµ¬ì²´ì  ì‚¬ë¡€ì™€ êµ¬ì¡°í™”
7. ì»¤ë®¤ë‹ˆì¼€ì´ì…˜/í˜‘ì—… (Collaboration): íŒ€ì›Œí¬ì™€ í˜‘ì—… ë„êµ¬ ê²½í—˜
8. ì„±ì¥ ê°€ëŠ¥ì„±/í•™ìŠµ ëŠ¥ë ¥ (Growth Potential): ìƒˆë¡œìš´ ê¸°ìˆ  í•™ìŠµê³¼ ì ì‘ë ¥
9. ìì†Œì„œ í‘œí˜„ë ¥/ë…¼ë¦¬ì„± (Clarity & Grammar): ê¸€ì˜ í’ˆì§ˆê³¼ ë¬¸ë²•

[ì‘ë‹µ í˜•ì‹]
ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "motivation_relevance": {{
        "score": 8,
        "feedback": "ì§€ì› ë™ê¸°ê°€ ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ í‘œí˜„ë˜ì—ˆìŠµë‹ˆë‹¤."
    }},
    "problem_solving_STAR": {{
        "score": 7,
        "feedback": "STAR ê¸°ë²•ì„ í™œìš©í•œ ë¬¸ì œ í•´ê²° ì‚¬ë¡€ê°€ ì˜ ì •ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
    }},
    "quantitative_impact": {{
        "score": 6,
        "feedback": "ì¼ë¶€ ì •ëŸ‰ì  ì„±ê³¼ê°€ ì œì‹œë˜ì—ˆìœ¼ë‚˜ ë” êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    }},
    "job_understanding": {{
        "score": 9,
        "feedback": "ì§€ì› ì§ë¬´ì— ëŒ€í•œ ê¹Šì€ ì´í•´ì™€ ê´€ë ¨ ê²½í—˜ì´ ì˜ ë“œëŸ¬ë‚©ë‹ˆë‹¤."
    }},
    "unique_experience": {{
        "score": 8,
        "feedback": "ë‹¤ë¥¸ ì§€ì›ìì™€ ì°¨ë³„í™”ë˜ëŠ” ë…íŠ¹í•œ ê²½í—˜ì´ ì˜ í‘œí˜„ë˜ì—ˆìŠµë‹ˆë‹¤."
    }},
    "logical_flow": {{
        "score": 7,
        "feedback": "ì „ì²´ì ì¸ ë…¼ë¦¬ì  íë¦„ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
    }},
    "keyword_diversity": {{
        "score": 6,
        "feedback": "ê´€ë ¨ í‚¤ì›Œë“œê°€ ì ì ˆíˆ ì‚¬ìš©ë˜ì—ˆìœ¼ë‚˜ ë” ë‹¤ì–‘í•œ í‘œí˜„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    }},
    "sentence_readability": {{
        "score": 8,
        "feedback": "ë¬¸ì¥ì´ ëª…í™•í•˜ê³  ì½ê¸° ì‰½ê²Œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
    }},
    "typos_and_errors": {{
        "score": 9,
        "feedback": "ì˜¤íƒˆìë‚˜ ë¬¸ë²• ì˜¤ë¥˜ê°€ ê±°ì˜ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    }}
}}

ê° í•­ëª©ì€ 0-10ì ìœ¼ë¡œ í‰ê°€í•˜ê³ , êµ¬ì²´ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        return prompt
    
    def _parse_analysis_response(self, analysis_text: str) -> Dict[str, Any]:
        """GPT ì‘ë‹µ íŒŒì‹± ë° êµ¬ì¡°í™”"""
        try:
            # JSON ë¶€ë¶„ ì°¾ê¸°
            start_idx = analysis_text.find('{')
            end_idx = analysis_text.rfind('}') + 1
            
            if start_idx != -1 and end_idx != -1:
                json_str = analysis_text[start_idx:end_idx]
                parsed = json.loads(json_str)
                
                # ì ìˆ˜ ì •ê·œí™” (0-10 ë²”ìœ„)
                normalized_scores = {}
                for key, value in parsed.items():
                    if isinstance(value, dict) and 'score' in value:
                        score = value['score']
                        if isinstance(score, (int, float)):
                            normalized_scores[key] = {
                                'score': min(10, max(0, int(score))),
                                'feedback': value.get('feedback', 'í”¼ë“œë°±ì´ ì—†ìŠµë‹ˆë‹¤.')
                            }
                        else:
                            normalized_scores[key] = {
                                'score': 5,
                                'feedback': 'ì ìˆ˜ íŒŒì‹± ì˜¤ë¥˜'
                            }
                    else:
                        normalized_scores[key] = {
                            'score': 5,
                            'feedback': 'ê¸°ë³¸ í”¼ë“œë°±'
                        }
                
                return normalized_scores
            else:
                raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                
        except (json.JSONDecodeError, ValueError) as e:
            logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
            return self._get_default_analysis()
    
    def _get_default_analysis(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ë°˜í™˜"""
        return {
            "motivation_relevance": {"score": 7, "feedback": "ì§€ì› ë™ê¸°ì— ëŒ€í•œ ê¸°ë³¸ì ì¸ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."},
            "problem_solving_STAR": {"score": 7, "feedback": "STAR ê¸°ë²• í™œìš©ì— ëŒ€í•œ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."},
            "quantitative_impact": {"score": 7, "feedback": "ì •ëŸ‰ì  ì„±ê³¼ ì œì‹œì— ëŒ€í•œ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."},
            "job_understanding": {"score": 7, "feedback": "ì§ë¬´ ì´í•´ë„ì— ëŒ€í•œ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."},
            "unique_experience": {"score": 7, "feedback": "ì°¨ë³„í™” ê²½í—˜ì— ëŒ€í•œ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."},
            "logical_flow": {"score": 7, "feedback": "ë…¼ë¦¬ì  íë¦„ì— ëŒ€í•œ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."},
            "keyword_diversity": {"score": 7, "feedback": "í‚¤ì›Œë“œ ë‹¤ì–‘ì„±ì— ëŒ€í•œ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."},
            "sentence_readability": {"score": 7, "feedback": "ë¬¸ì¥ ê°€ë…ì„±ì— ëŒ€í•œ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."},
            "typos_and_errors": {"score": 7, "feedback": "ì˜¤íƒˆì ê²€í† ì— ëŒ€í•œ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."}
        }
    
    def _calculate_overall_score(self, analysis_result: Dict[str, Any]) -> float:
        """ì¢…í•© ì ìˆ˜ ê³„ì‚°"""
        try:
            scores = []
            for key, value in analysis_result.items():
                if isinstance(value, dict) and 'score' in value:
                    scores.append(value['score'])
            
            if scores:
                return round(sum(scores) / len(scores), 1)
            else:
                return 7.0
                
        except Exception as e:
            logger.error(f"ì¢…í•© ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 7.0
    
    def get_evaluation_summary(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """í‰ê°€ ê²°ê³¼ ìš”ì•½"""
        try:
            summary = {
                "overall_score": self._calculate_overall_score(analysis_result),
                "top_strengths": [],
                "improvement_areas": [],
                "score_distribution": {
                    "excellent": 0,  # 8-10ì 
                    "good": 0,       # 5-7ì 
                    "needs_improvement": 0  # 0-4ì 
                }
            }
            
            for key, value in analysis_result.items():
                if isinstance(value, dict) and 'score' in value:
                    score = value['score']
                    
                    # ì ìˆ˜ ë¶„í¬ ê³„ì‚°
                    if score >= 8:
                        summary["score_distribution"]["excellent"] += 1
                        summary["top_strengths"].append({
                            "item": key,
                            "score": score,
                            "feedback": value.get('feedback', '')
                        })
                    elif score >= 5:
                        summary["score_distribution"]["good"] += 1
                    else:
                        summary["score_distribution"]["needs_improvement"] += 1
                        summary["improvement_areas"].append({
                            "item": key,
                            "score": score,
                            "feedback": value.get('feedback', '')
                        })
            
            # ìƒìœ„ ê°•ì ê³¼ ê°œì„  ì˜ì—­ ì •ë ¬
            summary["top_strengths"].sort(key=lambda x: x["score"], reverse=True)
            summary["improvement_areas"].sort(key=lambda x: x["score"])
            
            return summary
            
        except Exception as e:
            logger.error(f"í‰ê°€ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"overall_score": 7.0, "error": str(e)}


